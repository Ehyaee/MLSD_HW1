{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c7a352f",
      "metadata": {
        "id": "1c7a352f"
      },
      "source": [
        "<div  style=\"border-bottom: 2px solid #5c5c5c33;\" dir=\"rtl\" >\n",
        "    <div  style=\"font-size: 30px;margin-bottom: 20px; text-align: center;\">بسم الله الرحمن الرحیم</div>\n",
        "    <br>\n",
        "    <div style=\"font-size:20px; padding-bottom: 20px;line-height: 2; text-align: center;\"> طراحی سامانه های یادگیری ماشین <br> تمرین اول</div>\n",
        "    <div style=\"font-size:17px; direction:rtl;padding-bottom: 15px;\">نام و نام خانوادگی : زینب احیائی</div>\n",
        "    <div style=\"font-size:17px; direction:rtl; padding-bottom: 15px;\">شماره دانشجویی : 400201061</div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# !pip install hazm \n",
        "from __future__ import unicode_literals\n",
        "from hazm import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "# !pip install tensorflow transformers bert-for-tf2\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.datasets import make_classification\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "KUnj1DVSKB17"
      },
      "id": "KUnj1DVSKB17",
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fd421973",
      "metadata": {
        "id": "fd421973"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h2 style=\"padding-bottom: 20px;\">آماده‌سازی داده</h2>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "        در این بخش ابتدا داده‌های خام مربوط به ۱۲۲۱ محصول از طریق خزش در وب سایت <a href=\"https://divar.ir/\">دیوار</a>\n",
        "     در دسته کالاهای دیجیتال و در زیر دسته‌های موبایل و تبلت، رایانه، کنسول و بازی ویدئویی و آنلاین  \n",
        "        و صوتی و تصویری  و از بین آگهی‌های شهر‌های تهران، مشهد، شیراز و اصفهان جمع آوری شده است.\n",
        "        این کار با استفاده از <a href=\"https://scrapy.org/\">scrapy</a>\n",
        "        و در دو مرحله انجام شده است.\n",
        "        در مرحله اول آدرس‌های این محصولات به دست آمده و در مرحله بعد اطلاعات محصول از داخل این صفحات استخراج شده است.\n",
        "        برای استخراج آدرس‌ها از spider ای با ساختار زیر استفاده شده است:\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4d07d49",
      "metadata": {
        "id": "d4d07d49"
      },
      "source": [
        "```\n",
        "import scrapy\n",
        "from scrapy.selector import Selector\n",
        "from selenium import webdriver\n",
        "import time\n",
        "\n",
        "class URLSpider(scrapy.Spider):\n",
        "    name = \"urlspider\"\n",
        "    allowed_domains = [\"divar.ir\"]\n",
        "    start_urls = [\"https://divar.ir/s/mashhad/mobile-tablet\"]\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.driver = webdriver.Chrome()\n",
        "        self.count = 0\n",
        "\n",
        "\n",
        "    def closed(self, reason):\n",
        "        self.driver.quit()\n",
        "\n",
        "\n",
        "    def parse(self, response):\n",
        "        self.driver.get(response.url)\n",
        "\n",
        "        # Scroll down and load more data\n",
        "        while True:\n",
        "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(2)\n",
        "            sel = Selector(text=self.driver.execute_script(\"return document.body.innerHTML;\"))\n",
        "\n",
        "            for post in sel.css('div.post-card-item-af972'):\n",
        "                self.count = self.count + 1\n",
        "                href = post.css('a:nth-child(1)::attr(href)').extract()\n",
        "\n",
        "                yield {\n",
        "                    'href': href,\n",
        "                }\n",
        "            \n",
        "            if self.count > 200 :\n",
        "                break\n",
        "\n",
        "        self.driver.quit()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7609e74c",
      "metadata": {
        "id": "7609e74c"
      },
      "source": [
        "<div dir=\"rtl\" style=\"font-size: 16px;line-height: 1.6\">\n",
        "      برای استخراج اطلاعات محصول نیز از spider ای با ساختار زیر استفاده شده است:\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64934c84",
      "metadata": {
        "id": "64934c84"
      },
      "source": [
        "```\n",
        "import json\n",
        "import time\n",
        "from scrapy import Spider, Request, Selector\n",
        "\n",
        "class DataSpider(Spider):\n",
        "    name = 'dataspider'\n",
        "   \n",
        "    def start_requests(self):\n",
        "        with open('/Users/zeinab/Desktop/MLSD_HW1/scrapy/divar/urls/mashhad-mobile-tablet.json', 'r') as f:\n",
        "            urls = json.load(f)\n",
        "        for url in urls:\n",
        "            time.sleep(1)\n",
        "            yield Request(url=\"https://divar.ir\" + url[\"href\"][0], callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        price = ''\n",
        "        for value in response.css('p.kt-unexpandable-row__value'):\n",
        "            if('تومان' in value.css(\"::text\").get().strip()):\n",
        "                price = value.css(\"::text\").get().strip()\n",
        "\n",
        "        img_div = response.css('div.kt-carousel__thumbnails')\n",
        "        img_count = len(img_div.css('img'))\n",
        "\n",
        "        yield {\n",
        "            'title' : response.css('div.kt-page-title__title::text').get(),\n",
        "            'desc' : response.css('p.kt-description-row__text::text').get(),\n",
        "            'brand' : response.css('a.kt-unexpandable-row__action::text').get(),\n",
        "            'image-count' : max(1, img_count),\n",
        "            'price' : price,\n",
        "            'city' : 'Mashhad',\n",
        "            'category' : 'mobile-tablet'\n",
        "        }\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08eeb28",
      "metadata": {
        "id": "e08eeb28"
      },
      "source": [
        "<div  dir=\"rtl\" style=\"font-size: 16px;line-height: 1.6;\">\n",
        "      در نهایت نتایج در یک فایل json با فرمتی مشابه زیر ذخیره شده است:\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0714db3d",
      "metadata": {
        "id": "0714db3d"
      },
      "source": [
        "```\n",
        "[\n",
        "    {\n",
        "    \"title\": \"سینما خانگی سامسونگ ۱۰۰۰ وات، ساخت اندونزی\",\n",
        "    \"desc\": \"سینما خانگی ۷ تیکه دارای ۴ باند یک ساب، یک DVD player ، یک باند کوچک رو میزی، حدود ۲ ساله استفاده نشده، بسیار تمیز\",\n",
        "    \"brand\": null,\n",
        "    \"image-count\": 4,\n",
        "    \"price\": \"۳٬۷۰۰٬۰۰۰ تومان\",\n",
        "    \"city\": \"Tehran\",\n",
        "    \"category\": \"video-audio-device\"\n",
        "  }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149effd6",
      "metadata": {
        "id": "149effd6"
      },
      "source": [
        "\n",
        "<div dir=\"rtl\">\n",
        "    <h3 style=\"padding-bottom: 20px; direction: rtl;\">تبدیل داده به ساختار جدولی</h3>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "   در این بخش داده‌ها به فرمت جدولی تبدیل شده و ساختار جدول آن در sql شرح داده می‌شود.\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97314e8",
      "metadata": {
        "id": "d97314e8"
      },
      "outputs": [],
      "source": [
        "# Open the JSON file\n",
        "with open('data/data.json', 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# Open the CSV file and write headers\n",
        "with open('data/data.csv', 'w', newline='') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow(['title', 'desc', 'brand', 'image-count', 'price', 'category', 'city'])\n",
        "\n",
        "    # Write data rows to CSV file\n",
        "    for item in data:\n",
        "        writer.writerow([item['title'], item['desc'],\n",
        "                         item['brand'], item['image-count'], \n",
        "                         item['price'], item['category'], item['city']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb9aca3",
      "metadata": {
        "id": "6cb9aca3"
      },
      "source": [
        "<div dir=\"rtl\" style=\"font-size: 16px;line-height: 1.6;\">\n",
        "  حال می توان داده را در جدولی مشابه جدول زیر در دیتابیس ذخیره کرد.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b49d0f8",
      "metadata": {
        "id": "6b49d0f8"
      },
      "source": [
        "  ```\n",
        "  CREATE TABLE tblDivar (\n",
        "    fldID BIGINT identity(1, 1),\n",
        "    fldTitle NVARCHAR(250),\n",
        "    fldDesc NVARCHAR(MAX),\n",
        "    fldBrand NVARCHAR(250),\n",
        "    fldImageCount INT, \n",
        "    fldPrice NVARCHAR(250),\n",
        "    fldCategory NVARCHAR(250),\n",
        "    fldCity NVARCHAR(250)\n",
        ");\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0422dd78",
      "metadata": {
        "id": "0422dd78"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h3 style=\"padding-bottom: 20px; direction: rtl;\">کنترل نسخه</h3>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "   برای کنترل نسخه داده از ابزار dvc استفاده شده است و. از این \n",
        "        <a href=\"https://github.com/Ehyaee/MLSD_HW1\">لینک گیتهاب</a>\n",
        "        و این \n",
        "        <a href=\"https://drive.google.com/drive/folders/1tSGQp5h-9Yie5EdEeVHwE9-51CNHzxJe?usp=sharing\">لینک گوگل درایو </a>\n",
        "        استفاده شده است.\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883de6ad",
      "metadata": {
        "id": "883de6ad"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h2 style=\"padding-bottom: 20px;\">تحلیل اکتشافی داده</h2>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "      در این بخش به بررسی بیشتر داده می‌پردازیم.\n",
        "    </div>\n",
        "    <h3 style=\"padding-bottom: 20px;\">تحلیل اکتشافی داده</h3>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "e776b9ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "e776b9ef",
        "outputId": "23884485-1c0f-46b7-dfdc-9141afe14f29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        title  \\\n",
              "0  سینما خانگی سامسونگ ۱۰۰۰ وات، ساخت اندونزی   \n",
              "1                              اسپیکر بلوتوثی   \n",
              "2                       ال سی دی سونی 55 اینج   \n",
              "3                   تلویزیون شهاب ٢١ در حد نو   \n",
              "4                                         NaN   \n",
              "\n",
              "                                                desc brand  image-count  \\\n",
              "0  سینما خانگی ۷ تیکه دارای ۴ باند یک ساب، یک DVD...   NaN            4   \n",
              "1  اتصال بی‌سیم و باسیم\\nجک ۳.۵ میلی‌متری صدا، بل...   NaN            1   \n",
              "2  Sony 55 inch \\nفقط روی صفحه خط سیاه افتاده و م...   NaN            1   \n",
              "3                      ٢١ اینج\\nکار نکرده و در حد نو   NaN            2   \n",
              "4                                                NaN   NaN            1   \n",
              "\n",
              "                     price            category    city  \n",
              "0          ۳٬۷۰۰٬۰۰۰ تومان  video-audio-device  Tehran  \n",
              "1  ۱٬۴۰۰٬۰۰۰ تومان (مقطوع)  video-audio-device  Tehran  \n",
              "2  ۹٬۰۰۰٬۰۰۰ تومان (مقطوع)  video-audio-device  Tehran  \n",
              "3            ۶۵۰٬۰۰۰ تومان  video-audio-device  Tehran  \n",
              "4                      NaN  video-audio-device  Tehran  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67cbba97-8059-4272-9a30-93339a3361b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>desc</th>\n",
              "      <th>brand</th>\n",
              "      <th>image-count</th>\n",
              "      <th>price</th>\n",
              "      <th>category</th>\n",
              "      <th>city</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>سینما خانگی سامسونگ ۱۰۰۰ وات، ساخت اندونزی</td>\n",
              "      <td>سینما خانگی ۷ تیکه دارای ۴ باند یک ساب، یک DVD...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>۳٬۷۰۰٬۰۰۰ تومان</td>\n",
              "      <td>video-audio-device</td>\n",
              "      <td>Tehran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>اسپیکر بلوتوثی</td>\n",
              "      <td>اتصال بی‌سیم و باسیم\\nجک ۳.۵ میلی‌متری صدا، بل...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>۱٬۴۰۰٬۰۰۰ تومان (مقطوع)</td>\n",
              "      <td>video-audio-device</td>\n",
              "      <td>Tehran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ال سی دی سونی 55 اینج</td>\n",
              "      <td>Sony 55 inch \\nفقط روی صفحه خط سیاه افتاده و م...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>۹٬۰۰۰٬۰۰۰ تومان (مقطوع)</td>\n",
              "      <td>video-audio-device</td>\n",
              "      <td>Tehran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>تلویزیون شهاب ٢١ در حد نو</td>\n",
              "      <td>٢١ اینج\\nکار نکرده و در حد نو</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>۶۵۰٬۰۰۰ تومان</td>\n",
              "      <td>video-audio-device</td>\n",
              "      <td>Tehran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>video-audio-device</td>\n",
              "      <td>Tehran</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67cbba97-8059-4272-9a30-93339a3361b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67cbba97-8059-4272-9a30-93339a3361b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67cbba97-8059-4272-9a30-93339a3361b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "df = pd.read_csv(\"data.csv\")\n",
        "# df = pd.read_csv(\"data/data.csv\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "4307aefe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4307aefe",
        "outputId": "d3d5cdae-721d-4267-d04b-075de65b24e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1221 entries, 0 to 1220\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   title        1166 non-null   object\n",
            " 1   desc         1166 non-null   object\n",
            " 2   brand        199 non-null    object\n",
            " 3   image-count  1221 non-null   int64 \n",
            " 4   price        1164 non-null   object\n",
            " 5   category     1221 non-null   object\n",
            " 6   city         1221 non-null   object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 66.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "d13f3126",
      "metadata": {
        "id": "d13f3126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "d8922a4c-5197-4316-af74-0bb5be5eed6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='category', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(x='category', data=df, palette='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "1f2018b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "1f2018b5",
        "outputId": "d8260e26-bafc-4e9f-f5b9-dbb40097d8f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='city', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(x='city', data=df, palette='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "02d2cffe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02d2cffe",
        "outputId": "cfcd78db-5ae6-408b-e1ad-28154d4c0805"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title            55\n",
              "desc             55\n",
              "brand          1022\n",
              "image-count       0\n",
              "price            57\n",
              "category          0\n",
              "city              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d80cd59",
      "metadata": {
        "id": "8d80cd59"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h3 style=\"padding-bottom: 20px;\">پاک‌سازی داده</h3>\n",
        "    <h4>حذف سطر های با عنوان و قیمت null</h4>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "7025bd91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7025bd91",
        "outputId": "8cb65463-1c35-4dae-8076-7d76a82817d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title            0\n",
              "desc             0\n",
              "brand          965\n",
              "image-count      0\n",
              "price            0\n",
              "category         0\n",
              "city             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "df = df.dropna(subset=['title', 'price'])\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c3ed9d",
      "metadata": {
        "id": "18c3ed9d"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h4 style=\"padding-bottom: 20px;\">حذف unicode ها</h4>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "        در متن عناوین و توضیحات \n",
        "        تعدادی\n",
        "        unicode  وجود دارد.\n",
        "        به عنوان اولین مرحله این\n",
        "        unicode ها حذف می‌شود.\n",
        "   </div> \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "6edbf2fa",
      "metadata": {
        "id": "6edbf2fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d61b9a-1603-437b-a2d3-0ec96630b013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-116-e13b319793e2>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['title'] = df['title'].apply(lambda x: remove_unicode(x))\n",
            "<ipython-input-116-e13b319793e2>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['desc'] = df['desc'].apply(lambda x: remove_unicode(x))\n"
          ]
        }
      ],
      "source": [
        "def remove_unicode(text):\n",
        "    # regular expression pattern to match Unicode characters\n",
        "    pattern = r'[^\\u0600-\\u06FF\\u0660-\\u0669\\u06F0-\\u06F9\\u0020\\u002E\\u002C\\u061B\\u003A\\u002D\\u002F\\u0028\\u0029\\u005B\\u005D\\u007B\\u007D\\u00AB\\u00BB\\u2018\\u2019\\u201C\\u201D\\u00A0\\u200C\\u200F]+'\n",
        "    \n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    \n",
        "    # remove Unicode characters using re.sub()\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    \n",
        "    return cleaned_text\n",
        "\n",
        "# remove unicodes \n",
        "df['title'] = df['title'].apply(lambda x: remove_unicode(x))\n",
        "df['desc'] = df['desc'].apply(lambda x: remove_unicode(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0f9d06b",
      "metadata": {
        "id": "f0f9d06b"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h4 style=\"padding-bottom: 20px;\">تبدیل قیمت به مقدار عددی</h4>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "cb38a8f6",
      "metadata": {
        "id": "cb38a8f6"
      },
      "outputs": [],
      "source": [
        "def get_numeric_price(text):\n",
        "    number_str = ''.join(filter(str.isdigit, text))\n",
        "    return int(number_str)\n",
        "\n",
        "df['price'] = df['price'].apply(lambda x: get_numeric_price(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f841e35",
      "metadata": {
        "id": "8f841e35"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h3 style=\"padding-bottom: 20px;\">کدگذاری داده</h3>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "       در این بخش داده‌های غیر‌عددی به داده‌های عددی تبدیل می‌گردند.\n",
        "   </div> \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "ac0c7423",
      "metadata": {
        "id": "ac0c7423"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "df['brand'] = le.fit_transform(df['brand'].values)\n",
        "df['category'] = le.fit_transform(df['category'].values)\n",
        "df['city'] = le.fit_transform(df['city'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "e34ef7c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e34ef7c0",
        "outputId": "8f03e0e9-b012-4690-8748-82e09a07e741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1164 entries, 0 to 1220\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   title        1164 non-null   object\n",
            " 1   desc         1164 non-null   object\n",
            " 2   brand        1164 non-null   int64 \n",
            " 3   image-count  1164 non-null   int64 \n",
            " 4   price        1164 non-null   int64 \n",
            " 5   category     1164 non-null   int64 \n",
            " 6   city         1164 non-null   int64 \n",
            "dtypes: int64(5), object(2)\n",
            "memory usage: 72.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9711d121",
      "metadata": {
        "id": "9711d121"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h3 style=\"padding-bottom: 20px;\">تولید بازنمایی متنی</h3>\n",
        "    <h3 style=\"padding-bottom: 20px;\">TF-IDF</h3>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "    در این بخش بازنمایی مناسب برای ستون‌های title و desc به سه روش تولید می‌شود.\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['title'] + ' ' + df['desc']\n",
        "df.drop(['title', 'desc'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "qbL5QwfSGfSt"
      },
      "id": "qbL5QwfSGfSt",
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "34f37f6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34f37f6b",
        "outputId": "61506832-d965-47a4-e537-cd3941e10d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['آید', 'توان', 'تواند', 'توانند', 'رسد', 'رود', 'سال', 'نمی', 'های', 'گوید', 'گویند'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the title column using Hazm\n",
        "stemmer = Stemmer()\n",
        "normalizer = Normalizer()\n",
        "df['preprocessed'] = df['text'].apply(lambda x: ' '.join([stemmer.stem(w) for w in word_tokenize(normalizer.normalize(x))]))\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords_list(), ngram_range=(1, 2))\n",
        "\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed'])\n",
        "\n",
        "feature_names = column_names = [f\"text_vector_{i}\" for i in range(len(tfidf_matrix.toarray()[0]))]\n",
        "\n",
        "temp_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "temp_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df.drop('preprocessed', axis=1, inplace=True)\n",
        "tfidf_df = pd.concat([df, temp_df], axis=1)\n",
        "tfidf_df.drop('text', axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "ogMEQ0oNG0z4",
        "outputId": "2ab12788-440a-4e28-b3fe-9df2be85459c"
      },
      "id": "ogMEQ0oNG0z4",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      brand  image-count    price  category  city  text_vector_0  \\\n",
              "0        12            4  3700000         3     3            0.0   \n",
              "1        12            1  1400000         3     3            0.0   \n",
              "2        12            1  9000000         3     3            0.0   \n",
              "3        12            2   650000         3     3            0.0   \n",
              "4        12            2  4200000         3     3            0.0   \n",
              "...     ...          ...      ...       ...   ...            ...   \n",
              "1159     12            3    45000         2     1            0.0   \n",
              "1160     12            2   550000         2     1            0.0   \n",
              "1161     12            1    55000         2     1            0.0   \n",
              "1162     12            1    10000         2     1            0.0   \n",
              "1163     12            1   155000         2     1            0.0   \n",
              "\n",
              "      text_vector_1  text_vector_2  text_vector_3  text_vector_4  ...  \\\n",
              "0               0.0            0.0            0.0            0.0  ...   \n",
              "1               0.0            0.0            0.0            0.0  ...   \n",
              "2               0.0            0.0            0.0            0.0  ...   \n",
              "3               0.0            0.0            0.0            0.0  ...   \n",
              "4               0.0            0.0            0.0            0.0  ...   \n",
              "...             ...            ...            ...            ...  ...   \n",
              "1159            0.0            0.0            0.0            0.0  ...   \n",
              "1160            0.0            0.0            0.0            0.0  ...   \n",
              "1161            0.0            0.0            0.0            0.0  ...   \n",
              "1162            0.0            0.0            0.0            0.0  ...   \n",
              "1163            0.0            0.0            0.0            0.0  ...   \n",
              "\n",
              "      text_vector_23539  text_vector_23540  text_vector_23541  \\\n",
              "0                   0.0                0.0                0.0   \n",
              "1                   0.0                0.0                0.0   \n",
              "2                   0.0                0.0                0.0   \n",
              "3                   0.0                0.0                0.0   \n",
              "4                   0.0                0.0                0.0   \n",
              "...                 ...                ...                ...   \n",
              "1159                0.0                0.0                0.0   \n",
              "1160                0.0                0.0                0.0   \n",
              "1161                0.0                0.0                0.0   \n",
              "1162                0.0                0.0                0.0   \n",
              "1163                0.0                0.0                0.0   \n",
              "\n",
              "      text_vector_23542  text_vector_23543  text_vector_23544  \\\n",
              "0                   0.0                0.0                0.0   \n",
              "1                   0.0                0.0                0.0   \n",
              "2                   0.0                0.0                0.0   \n",
              "3                   0.0                0.0                0.0   \n",
              "4                   0.0                0.0                0.0   \n",
              "...                 ...                ...                ...   \n",
              "1159                0.0                0.0                0.0   \n",
              "1160                0.0                0.0                0.0   \n",
              "1161                0.0                0.0                0.0   \n",
              "1162                0.0                0.0                0.0   \n",
              "1163                0.0                0.0                0.0   \n",
              "\n",
              "      text_vector_23545  text_vector_23546  text_vector_23547  \\\n",
              "0                   0.0                0.0                0.0   \n",
              "1                   0.0                0.0                0.0   \n",
              "2                   0.0                0.0                0.0   \n",
              "3                   0.0                0.0                0.0   \n",
              "4                   0.0                0.0                0.0   \n",
              "...                 ...                ...                ...   \n",
              "1159                0.0                0.0                0.0   \n",
              "1160                0.0                0.0                0.0   \n",
              "1161                0.0                0.0                0.0   \n",
              "1162                0.0                0.0                0.0   \n",
              "1163                0.0                0.0                0.0   \n",
              "\n",
              "      text_vector_23548  \n",
              "0                   0.0  \n",
              "1                   0.0  \n",
              "2                   0.0  \n",
              "3                   0.0  \n",
              "4                   0.0  \n",
              "...                 ...  \n",
              "1159                0.0  \n",
              "1160                0.0  \n",
              "1161                0.0  \n",
              "1162                0.0  \n",
              "1163                0.0  \n",
              "\n",
              "[1164 rows x 23554 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-884ca7da-6e51-4f14-b38f-786d6a29c25e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>image-count</th>\n",
              "      <th>price</th>\n",
              "      <th>category</th>\n",
              "      <th>city</th>\n",
              "      <th>text_vector_0</th>\n",
              "      <th>text_vector_1</th>\n",
              "      <th>text_vector_2</th>\n",
              "      <th>text_vector_3</th>\n",
              "      <th>text_vector_4</th>\n",
              "      <th>...</th>\n",
              "      <th>text_vector_23539</th>\n",
              "      <th>text_vector_23540</th>\n",
              "      <th>text_vector_23541</th>\n",
              "      <th>text_vector_23542</th>\n",
              "      <th>text_vector_23543</th>\n",
              "      <th>text_vector_23544</th>\n",
              "      <th>text_vector_23545</th>\n",
              "      <th>text_vector_23546</th>\n",
              "      <th>text_vector_23547</th>\n",
              "      <th>text_vector_23548</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>3700000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1400000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>9000000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>650000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>4200000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>45000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>550000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1161</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>55000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>10000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>155000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1164 rows × 23554 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-884ca7da-6e51-4f14-b38f-786d6a29c25e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-884ca7da-6e51-4f14-b38f-786d6a29c25e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-884ca7da-6e51-4f14-b38f-786d6a29c25e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3e0792",
      "metadata": {
        "id": "fc3e0792"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "    <h3 dir=\"rtl\" style=\"padding-bottom: 20px\">Pre-trained BERT</h3>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "    در این بخش به دلیل محدود بودن RAM در دسترس در colab پردازش تنها بر روی ۱۰ نمونه از داده‌های کل صورت می‌گیرد.\n",
        " </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained BERT model and tokenizer for Persian text\n",
        "model_name = 'HooshvareLab/bert-fa-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcIY5boBDjAl",
        "outputId": "435e4917-cf96-4d5d-ce83-2ac9b5a6f141"
      },
      "id": "DcIY5boBDjAl",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df.iloc[0:10,:]['category']\n",
        "X = df.loc[:, df.columns != 'category'].iloc[0:10,:]\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "bert_train_data, bert_val_data, bert_train_labels, bert_val_labels = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the input sequences and get the BERT embeddings\n",
        "bert_train_encodings = tokenizer(list(bert_train_data['text']), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "bert_val_encodings = tokenizer(list(bert_val_data['text']), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "bert_train_embeddings = bert_model(**bert_train_encodings)[0][:, 0, :]\n",
        "bert_val_embeddings = bert_model(**bert_val_encodings)[0][:, 0, :]\n"
      ],
      "metadata": {
        "id": "YKFZ7vEPHXYx"
      },
      "id": "YKFZ7vEPHXYx",
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = column_names = [f\"text_vector_{i}\" for i in range(len(bert_train_embeddings[0]))]\n",
        "temp_df = pd.DataFrame(bert_train_embeddings.detach().numpy(), columns=feature_names)\n",
        "\n",
        "bert_train_data.reset_index(drop=True, inplace=True)\n",
        "temp_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "bert_df = pd.concat([bert_train_data, temp_df], axis=1)\n",
        "bert_df.drop('text', axis=1, inplace=True)\n",
        "\n",
        "temp_df = pd.DataFrame(bert_val_embeddings.detach().numpy(), columns=feature_names)\n",
        "\n",
        "bert_val_data.reset_index(drop=True, inplace=True)\n",
        "temp_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "bert_df_test = pd.concat([bert_val_data, temp_df], axis=1)\n",
        "bert_df_test.drop('text', axis=1, inplace=True)\n",
        "\n",
        "bert_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "HGXCowcONxIW",
        "outputId": "266f06fe-1fba-4de7-cb8a-3fc2bcb6c252"
      },
      "id": "HGXCowcONxIW",
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   brand  image-count     price  city  text_vector_0  text_vector_1  \\\n",
              "0     12            2   3000000     3      -0.336082       0.200147   \n",
              "1     12            4   3700000     3       0.229775       0.577012   \n",
              "2     12            6   6350000     3      -0.214394      -0.351248   \n",
              "3     12            1   9000000     3       1.051590       0.352655   \n",
              "4     12            1  16300000     3       0.820665       1.264083   \n",
              "5     12            2   4200000     3       0.325233       0.018698   \n",
              "6     12            2    650000     3       1.345464      -0.691870   \n",
              "7     12            2    500000     3       0.319775       0.484986   \n",
              "\n",
              "   text_vector_2  text_vector_3  text_vector_4  text_vector_5  ...  \\\n",
              "0       1.053138      -0.043427       0.338867       1.351218  ...   \n",
              "1      -0.005407       0.169216      -0.142544       0.834574  ...   \n",
              "2       1.478818       0.772265       0.022562      -0.069026  ...   \n",
              "3       1.603401       0.132107      -0.118267       0.703873  ...   \n",
              "4       1.489563       0.645373       0.102532       0.604402  ...   \n",
              "5       1.624685       0.372218      -0.308477       0.126869  ...   \n",
              "6       1.606326       0.029029      -1.145691       0.064277  ...   \n",
              "7       0.849790      -0.224354       0.304685       0.805175  ...   \n",
              "\n",
              "   text_vector_758  text_vector_759  text_vector_760  text_vector_761  \\\n",
              "0         1.343394        -0.853243         0.272209         0.463359   \n",
              "1         1.144959        -0.212640        -0.074677         0.404581   \n",
              "2         0.554462        -0.405687        -0.059943         0.441306   \n",
              "3         1.253296         0.444773         0.412712        -0.633503   \n",
              "4         0.991750        -0.178065         0.580687         0.125826   \n",
              "5         0.739976         0.790584         0.737448        -0.473248   \n",
              "6        -0.168275         1.874840         0.202324         0.346616   \n",
              "7         0.734505         0.947874         0.222957        -0.547453   \n",
              "\n",
              "   text_vector_762  text_vector_763  text_vector_764  text_vector_765  \\\n",
              "0        -0.664118         0.041435         0.168871         0.732924   \n",
              "1         0.746716         0.606350         1.103523         0.515309   \n",
              "2        -1.221554         0.326375        -0.218121         1.210317   \n",
              "3        -0.113932         0.076875        -0.161759        -0.152605   \n",
              "4        -0.234057         1.184576        -0.135967         0.457605   \n",
              "5         0.242386         1.206023         0.709999         1.061233   \n",
              "6         0.799792         0.341189         0.648042        -0.678840   \n",
              "7        -1.064314         1.185591        -1.146926        -0.686741   \n",
              "\n",
              "   text_vector_766  text_vector_767  \n",
              "0         0.397439        -0.420487  \n",
              "1        -0.158027        -0.742577  \n",
              "2         0.062439        -0.641854  \n",
              "3         0.576430        -1.354515  \n",
              "4        -0.568547        -0.435075  \n",
              "5        -0.603628        -0.952310  \n",
              "6         0.260010        -1.400522  \n",
              "7         0.085195        -1.166368  \n",
              "\n",
              "[8 rows x 772 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51668bce-852c-4d3a-b9c8-a816a8939f03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>image-count</th>\n",
              "      <th>price</th>\n",
              "      <th>city</th>\n",
              "      <th>text_vector_0</th>\n",
              "      <th>text_vector_1</th>\n",
              "      <th>text_vector_2</th>\n",
              "      <th>text_vector_3</th>\n",
              "      <th>text_vector_4</th>\n",
              "      <th>text_vector_5</th>\n",
              "      <th>...</th>\n",
              "      <th>text_vector_758</th>\n",
              "      <th>text_vector_759</th>\n",
              "      <th>text_vector_760</th>\n",
              "      <th>text_vector_761</th>\n",
              "      <th>text_vector_762</th>\n",
              "      <th>text_vector_763</th>\n",
              "      <th>text_vector_764</th>\n",
              "      <th>text_vector_765</th>\n",
              "      <th>text_vector_766</th>\n",
              "      <th>text_vector_767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>3000000</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.336082</td>\n",
              "      <td>0.200147</td>\n",
              "      <td>1.053138</td>\n",
              "      <td>-0.043427</td>\n",
              "      <td>0.338867</td>\n",
              "      <td>1.351218</td>\n",
              "      <td>...</td>\n",
              "      <td>1.343394</td>\n",
              "      <td>-0.853243</td>\n",
              "      <td>0.272209</td>\n",
              "      <td>0.463359</td>\n",
              "      <td>-0.664118</td>\n",
              "      <td>0.041435</td>\n",
              "      <td>0.168871</td>\n",
              "      <td>0.732924</td>\n",
              "      <td>0.397439</td>\n",
              "      <td>-0.420487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>3700000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.229775</td>\n",
              "      <td>0.577012</td>\n",
              "      <td>-0.005407</td>\n",
              "      <td>0.169216</td>\n",
              "      <td>-0.142544</td>\n",
              "      <td>0.834574</td>\n",
              "      <td>...</td>\n",
              "      <td>1.144959</td>\n",
              "      <td>-0.212640</td>\n",
              "      <td>-0.074677</td>\n",
              "      <td>0.404581</td>\n",
              "      <td>0.746716</td>\n",
              "      <td>0.606350</td>\n",
              "      <td>1.103523</td>\n",
              "      <td>0.515309</td>\n",
              "      <td>-0.158027</td>\n",
              "      <td>-0.742577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>6350000</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.214394</td>\n",
              "      <td>-0.351248</td>\n",
              "      <td>1.478818</td>\n",
              "      <td>0.772265</td>\n",
              "      <td>0.022562</td>\n",
              "      <td>-0.069026</td>\n",
              "      <td>...</td>\n",
              "      <td>0.554462</td>\n",
              "      <td>-0.405687</td>\n",
              "      <td>-0.059943</td>\n",
              "      <td>0.441306</td>\n",
              "      <td>-1.221554</td>\n",
              "      <td>0.326375</td>\n",
              "      <td>-0.218121</td>\n",
              "      <td>1.210317</td>\n",
              "      <td>0.062439</td>\n",
              "      <td>-0.641854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>9000000</td>\n",
              "      <td>3</td>\n",
              "      <td>1.051590</td>\n",
              "      <td>0.352655</td>\n",
              "      <td>1.603401</td>\n",
              "      <td>0.132107</td>\n",
              "      <td>-0.118267</td>\n",
              "      <td>0.703873</td>\n",
              "      <td>...</td>\n",
              "      <td>1.253296</td>\n",
              "      <td>0.444773</td>\n",
              "      <td>0.412712</td>\n",
              "      <td>-0.633503</td>\n",
              "      <td>-0.113932</td>\n",
              "      <td>0.076875</td>\n",
              "      <td>-0.161759</td>\n",
              "      <td>-0.152605</td>\n",
              "      <td>0.576430</td>\n",
              "      <td>-1.354515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>16300000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.820665</td>\n",
              "      <td>1.264083</td>\n",
              "      <td>1.489563</td>\n",
              "      <td>0.645373</td>\n",
              "      <td>0.102532</td>\n",
              "      <td>0.604402</td>\n",
              "      <td>...</td>\n",
              "      <td>0.991750</td>\n",
              "      <td>-0.178065</td>\n",
              "      <td>0.580687</td>\n",
              "      <td>0.125826</td>\n",
              "      <td>-0.234057</td>\n",
              "      <td>1.184576</td>\n",
              "      <td>-0.135967</td>\n",
              "      <td>0.457605</td>\n",
              "      <td>-0.568547</td>\n",
              "      <td>-0.435075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>4200000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.325233</td>\n",
              "      <td>0.018698</td>\n",
              "      <td>1.624685</td>\n",
              "      <td>0.372218</td>\n",
              "      <td>-0.308477</td>\n",
              "      <td>0.126869</td>\n",
              "      <td>...</td>\n",
              "      <td>0.739976</td>\n",
              "      <td>0.790584</td>\n",
              "      <td>0.737448</td>\n",
              "      <td>-0.473248</td>\n",
              "      <td>0.242386</td>\n",
              "      <td>1.206023</td>\n",
              "      <td>0.709999</td>\n",
              "      <td>1.061233</td>\n",
              "      <td>-0.603628</td>\n",
              "      <td>-0.952310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>650000</td>\n",
              "      <td>3</td>\n",
              "      <td>1.345464</td>\n",
              "      <td>-0.691870</td>\n",
              "      <td>1.606326</td>\n",
              "      <td>0.029029</td>\n",
              "      <td>-1.145691</td>\n",
              "      <td>0.064277</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.168275</td>\n",
              "      <td>1.874840</td>\n",
              "      <td>0.202324</td>\n",
              "      <td>0.346616</td>\n",
              "      <td>0.799792</td>\n",
              "      <td>0.341189</td>\n",
              "      <td>0.648042</td>\n",
              "      <td>-0.678840</td>\n",
              "      <td>0.260010</td>\n",
              "      <td>-1.400522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>500000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.319775</td>\n",
              "      <td>0.484986</td>\n",
              "      <td>0.849790</td>\n",
              "      <td>-0.224354</td>\n",
              "      <td>0.304685</td>\n",
              "      <td>0.805175</td>\n",
              "      <td>...</td>\n",
              "      <td>0.734505</td>\n",
              "      <td>0.947874</td>\n",
              "      <td>0.222957</td>\n",
              "      <td>-0.547453</td>\n",
              "      <td>-1.064314</td>\n",
              "      <td>1.185591</td>\n",
              "      <td>-1.146926</td>\n",
              "      <td>-0.686741</td>\n",
              "      <td>0.085195</td>\n",
              "      <td>-1.166368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 772 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51668bce-852c-4d3a-b9c8-a816a8939f03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51668bce-852c-4d3a-b9c8-a816a8939f03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51668bce-852c-4d3a-b9c8-a816a8939f03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h3 dir=\"rtl\" style=\"padding-bottom: 20px\">Bag of words</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "J7T8GCEqSva6"
      },
      "id": "J7T8GCEqSva6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text\n",
        "lemmatizer = Lemmatizer()\n",
        "stopwords = stopwords_list()\n",
        "df['text'] = df['text'].apply(normalizer.normalize)\n",
        "df['text'] = df['text'].apply(word_tokenize)\n",
        "df['text'] = df['text'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens if token not in stopwords])\n",
        "df['text'] = df['text'].apply(' '.join)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "bow_train_df = df.sample(frac=0.8, random_state=42)\n",
        "bow_test_df = df.drop(bow_train_df.index)\n",
        "\n",
        "# Create the bag-of-words representation\n",
        "vectorizer = CountVectorizer()\n",
        "bow_train_features = vectorizer.fit_transform(bow_train_df['text'])\n",
        "bow_test_features = vectorizer.transform(bow_test_df['text'])\n",
        "\n",
        "feature_names = column_names = [f\"text_vector_{i}\" for i in range(bow_train_features[0].shape[1])]\n",
        "\n",
        "temp_df = pd.DataFrame(bow_train_features.toarray(), columns=feature_names)\n",
        "\n",
        "bow_train_df.reset_index(drop=True, inplace=True)\n",
        "temp_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "bow_df = pd.concat([bow_train_df, temp_df], axis=1)\n",
        "bow_df.drop('text', axis=1, inplace=True)\n",
        "\n",
        "temp_df = pd.DataFrame(bow_test_features.toarray(), columns=feature_names)\n",
        "\n",
        "bow_test_df.reset_index(drop=True, inplace=True)\n",
        "temp_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "bow_df_test = pd.concat([bow_test_df, temp_df], axis=1)\n",
        "bow_df_test.drop('text', axis=1, inplace=True)\n",
        "\n",
        "bow_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "FQof73a6V7jh",
        "outputId": "7d510a31-e928-41f4-8fb3-fa1ae28bec13"
      },
      "id": "FQof73a6V7jh",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     brand  image-count     price  category  city  text_vector_0  \\\n",
              "0       12            4    400000         1     1              0   \n",
              "1       12            3  45000000         3     2              0   \n",
              "2       12            5  13500000         1     1              0   \n",
              "3       12            2    700000         1     3              0   \n",
              "4       12            1  15950000         1     1              0   \n",
              "..     ...          ...       ...       ...   ...            ...   \n",
              "926     12            5   1350000         1     3              0   \n",
              "927     12            1    850000         2     2              0   \n",
              "928     12            1   9500000         2     3              0   \n",
              "929     12            3     90000         2     3              0   \n",
              "930      1            4  11500000         0     3              0   \n",
              "\n",
              "     text_vector_1  text_vector_2  text_vector_3  text_vector_4  ...  \\\n",
              "0                0              0              0              0  ...   \n",
              "1                0              0              0              0  ...   \n",
              "2                0              0              0              0  ...   \n",
              "3                0              0              0              0  ...   \n",
              "4                0              0              0              0  ...   \n",
              "..             ...            ...            ...            ...  ...   \n",
              "926              0              0              0              0  ...   \n",
              "927              0              0              0              0  ...   \n",
              "928              0              0              0              0  ...   \n",
              "929              0              0              0              0  ...   \n",
              "930              0              0              0              0  ...   \n",
              "\n",
              "     text_vector_3733  text_vector_3734  text_vector_3735  text_vector_3736  \\\n",
              "0                   0                 0                 0                 0   \n",
              "1                   0                 0                 0                 0   \n",
              "2                   0                 0                 0                 0   \n",
              "3                   0                 0                 0                 0   \n",
              "4                   0                 0                 0                 0   \n",
              "..                ...               ...               ...               ...   \n",
              "926                 0                 0                 0                 0   \n",
              "927                 0                 0                 0                 0   \n",
              "928                 0                 0                 0                 0   \n",
              "929                 0                 0                 0                 0   \n",
              "930                 0                 0                 0                 0   \n",
              "\n",
              "     text_vector_3737  text_vector_3738  text_vector_3739  text_vector_3740  \\\n",
              "0                   0                 0                 0                 0   \n",
              "1                   0                 0                 0                 0   \n",
              "2                   0                 0                 0                 0   \n",
              "3                   0                 0                 0                 0   \n",
              "4                   0                 0                 0                 0   \n",
              "..                ...               ...               ...               ...   \n",
              "926                 0                 0                 0                 0   \n",
              "927                 0                 0                 0                 0   \n",
              "928                 0                 0                 0                 0   \n",
              "929                 0                 0                 0                 0   \n",
              "930                 0                 0                 0                 0   \n",
              "\n",
              "     text_vector_3741  text_vector_3742  \n",
              "0                   0                 0  \n",
              "1                   0                 0  \n",
              "2                   0                 0  \n",
              "3                   0                 0  \n",
              "4                   0                 0  \n",
              "..                ...               ...  \n",
              "926                 0                 0  \n",
              "927                 0                 0  \n",
              "928                 0                 0  \n",
              "929                 0                 0  \n",
              "930                 0                 0  \n",
              "\n",
              "[931 rows x 3748 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-115f2dde-b0d0-41d2-b726-d12c7e427eda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>image-count</th>\n",
              "      <th>price</th>\n",
              "      <th>category</th>\n",
              "      <th>city</th>\n",
              "      <th>text_vector_0</th>\n",
              "      <th>text_vector_1</th>\n",
              "      <th>text_vector_2</th>\n",
              "      <th>text_vector_3</th>\n",
              "      <th>text_vector_4</th>\n",
              "      <th>...</th>\n",
              "      <th>text_vector_3733</th>\n",
              "      <th>text_vector_3734</th>\n",
              "      <th>text_vector_3735</th>\n",
              "      <th>text_vector_3736</th>\n",
              "      <th>text_vector_3737</th>\n",
              "      <th>text_vector_3738</th>\n",
              "      <th>text_vector_3739</th>\n",
              "      <th>text_vector_3740</th>\n",
              "      <th>text_vector_3741</th>\n",
              "      <th>text_vector_3742</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>400000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>45000000</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>13500000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>700000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>15950000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1350000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>850000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>9500000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>90000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>11500000</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>931 rows × 3748 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-115f2dde-b0d0-41d2-b726-d12c7e427eda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-115f2dde-b0d0-41d2-b726-d12c7e427eda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-115f2dde-b0d0-41d2-b726-d12c7e427eda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h3 style=\"padding-bottom: 20px;\">مهندسی ویژگی</h3>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "    در این بخش PCA بر روی bert_df و انتخاب ویژگی به صورت انسانی بر روی tfidf_df اعمال می‌شود.\n",
        "    </div>\n",
        "</div>"
      ],
      "metadata": {
        "id": "zzLfdkr5XSAM"
      },
      "id": "zzLfdkr5XSAM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"padding-bottom: 20px;\" dir=\"rtl\">PCA</h3>\n"
      ],
      "metadata": {
        "id": "ZuhI6QtKXuJ8"
      },
      "id": "ZuhI6QtKXuJ8"
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "ba75ff72",
      "metadata": {
        "id": "ba75ff72"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "\n",
        "X_train_bert = bert_df.loc[:, bert_df.columns != 'category']\n",
        "X_test_bert = bert_df_test.loc[:, bert_df_test.columns != 'category']\n",
        "# bert_train_labels, bert_val_labels\n",
        "\n",
        "X_train_bert_pca = pca.fit_transform(X_train_bert)\n",
        "X_test_bert_pca = pca.fit_transform(X_test_bert)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"padding-bottom: 20px;\" dir=\"rtl\">انتخاب انسانی بازنمایی عنوان و توضیحات به عنوان تک ویژگی</h3>\n"
      ],
      "metadata": {
        "id": "87PYevmzdFsX"
      },
      "id": "87PYevmzdFsX"
    },
    {
      "cell_type": "code",
      "source": [
        "y = tfidf_df.loc[:, ['category']]\n",
        "X = tfidf_df.drop(['brand', 'image-count', 'price', 'city', 'category'], axis=1)\n",
        "\n",
        "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "C9yDJfvHdSt0",
        "outputId": "0ef4ee51-962e-4bf7-f2c6-a179eb074fb6"
      },
      "id": "C9yDJfvHdSt0",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      text_vector_0  text_vector_1  text_vector_2  text_vector_3  \\\n",
              "290             0.0            0.0            0.0            0.0   \n",
              "903             0.0            0.0            0.0            0.0   \n",
              "543             0.0            0.0            0.0            0.0   \n",
              "730             0.0            0.0            0.0            0.0   \n",
              "717             0.0            0.0            0.0            0.0   \n",
              "...             ...            ...            ...            ...   \n",
              "1044            0.0            0.0            0.0            0.0   \n",
              "1095            0.0            0.0            0.0            0.0   \n",
              "1130            0.0            0.0            0.0            0.0   \n",
              "860             0.0            0.0            0.0            0.0   \n",
              "1126            0.0            0.0            0.0            0.0   \n",
              "\n",
              "      text_vector_4  text_vector_5  text_vector_6  text_vector_7  \\\n",
              "290             0.0            0.0            0.0            0.0   \n",
              "903             0.0            0.0            0.0            0.0   \n",
              "543             0.0            0.0            0.0            0.0   \n",
              "730             0.0            0.0            0.0            0.0   \n",
              "717             0.0            0.0            0.0            0.0   \n",
              "...             ...            ...            ...            ...   \n",
              "1044            0.0            0.0            0.0            0.0   \n",
              "1095            0.0            0.0            0.0            0.0   \n",
              "1130            0.0            0.0            0.0            0.0   \n",
              "860             0.0            0.0            0.0            0.0   \n",
              "1126            0.0            0.0            0.0            0.0   \n",
              "\n",
              "      text_vector_8  text_vector_9  ...  text_vector_23539  text_vector_23540  \\\n",
              "290             0.0            0.0  ...                0.0                0.0   \n",
              "903             0.0            0.0  ...                0.0                0.0   \n",
              "543             0.0            0.0  ...                0.0                0.0   \n",
              "730             0.0            0.0  ...                0.0                0.0   \n",
              "717             0.0            0.0  ...                0.0                0.0   \n",
              "...             ...            ...  ...                ...                ...   \n",
              "1044            0.0            0.0  ...                0.0                0.0   \n",
              "1095            0.0            0.0  ...                0.0                0.0   \n",
              "1130            0.0            0.0  ...                0.0                0.0   \n",
              "860             0.0            0.0  ...                0.0                0.0   \n",
              "1126            0.0            0.0  ...                0.0                0.0   \n",
              "\n",
              "      text_vector_23541  text_vector_23542  text_vector_23543  \\\n",
              "290                 0.0                0.0                0.0   \n",
              "903                 0.0                0.0                0.0   \n",
              "543                 0.0                0.0                0.0   \n",
              "730                 0.0                0.0                0.0   \n",
              "717                 0.0                0.0                0.0   \n",
              "...                 ...                ...                ...   \n",
              "1044                0.0                0.0                0.0   \n",
              "1095                0.0                0.0                0.0   \n",
              "1130                0.0                0.0                0.0   \n",
              "860                 0.0                0.0                0.0   \n",
              "1126                0.0                0.0                0.0   \n",
              "\n",
              "      text_vector_23544  text_vector_23545  text_vector_23546  \\\n",
              "290                 0.0                0.0                0.0   \n",
              "903                 0.0                0.0                0.0   \n",
              "543                 0.0                0.0                0.0   \n",
              "730                 0.0                0.0                0.0   \n",
              "717                 0.0                0.0                0.0   \n",
              "...                 ...                ...                ...   \n",
              "1044                0.0                0.0                0.0   \n",
              "1095                0.0                0.0                0.0   \n",
              "1130                0.0                0.0                0.0   \n",
              "860                 0.0                0.0                0.0   \n",
              "1126                0.0                0.0                0.0   \n",
              "\n",
              "      text_vector_23547  text_vector_23548  \n",
              "290                 0.0                0.0  \n",
              "903                 0.0                0.0  \n",
              "543                 0.0                0.0  \n",
              "730                 0.0                0.0  \n",
              "717                 0.0                0.0  \n",
              "...                 ...                ...  \n",
              "1044                0.0                0.0  \n",
              "1095                0.0                0.0  \n",
              "1130                0.0                0.0  \n",
              "860                 0.0                0.0  \n",
              "1126                0.0                0.0  \n",
              "\n",
              "[931 rows x 23549 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2a4f78f-9ddc-4da5-af9a-4475b86d0426\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_vector_0</th>\n",
              "      <th>text_vector_1</th>\n",
              "      <th>text_vector_2</th>\n",
              "      <th>text_vector_3</th>\n",
              "      <th>text_vector_4</th>\n",
              "      <th>text_vector_5</th>\n",
              "      <th>text_vector_6</th>\n",
              "      <th>text_vector_7</th>\n",
              "      <th>text_vector_8</th>\n",
              "      <th>text_vector_9</th>\n",
              "      <th>...</th>\n",
              "      <th>text_vector_23539</th>\n",
              "      <th>text_vector_23540</th>\n",
              "      <th>text_vector_23541</th>\n",
              "      <th>text_vector_23542</th>\n",
              "      <th>text_vector_23543</th>\n",
              "      <th>text_vector_23544</th>\n",
              "      <th>text_vector_23545</th>\n",
              "      <th>text_vector_23546</th>\n",
              "      <th>text_vector_23547</th>\n",
              "      <th>text_vector_23548</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>931 rows × 23549 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2a4f78f-9ddc-4da5-af9a-4475b86d0426')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2a4f78f-9ddc-4da5-af9a-4475b86d0426 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2a4f78f-9ddc-4da5-af9a-4475b86d0426');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "    <h3 style=\"padding-bottom: 20px;\">ناهمگنی توزیع داده</h3>\n",
        "    <div style=\"font-size: 16px;line-height: 1.6;\">\n",
        "در این بخش بر روی داد‌ها با ترکیب زیر مدل آموزش داده می‌شود:\n",
        "\n",
        " * bert + pca \n",
        " * tf-idf + undersampling\n",
        " * bow + weighted loss \n",
        "    </div>\n",
        "</div>"
      ],
      "metadata": {
        "id": "V_4jqfNIfRnE"
      },
      "id": "V_4jqfNIfRnE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"padding-bottom: 20px;\" dir=\"rtl\">Bert + PCA</h3>\n"
      ],
      "metadata": {
        "id": "0xnWRGP0gsvy"
      },
      "id": "0xnWRGP0gsvy"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define the network architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train(model, optimizer, criterion, train_loader, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 2 == 1:  # Print every 100 mini-batches\n",
        "                print('[epoch : %d, i : %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X_train_bert.values, dtype=torch.float32)\n",
        "y = torch.tensor(bert_train_labels.values, dtype=torch.long)\n",
        "train_dataset = TensorDataset(X, y)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Initialize the network and optimizer\n",
        "model = MLP(X_train_bert.shape[1], 20, 4)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the network\n",
        "train(model, optimizer, criterion, train_loader, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXWkPq24ggrb",
        "outputId": "47e457ee-e48d-46f0-fe26-9029aadd93b0"
      },
      "id": "XXWkPq24ggrb",
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch : 1, i :     2] loss: 88.117\n",
            "[epoch : 1, i :     4] loss: 0.000\n",
            "[epoch : 2, i :     2] loss: 0.000\n",
            "[epoch : 2, i :     4] loss: 0.000\n",
            "[epoch : 3, i :     2] loss: 0.000\n",
            "[epoch : 3, i :     4] loss: 0.000\n",
            "[epoch : 4, i :     2] loss: 0.000\n",
            "[epoch : 4, i :     4] loss: 0.000\n",
            "[epoch : 5, i :     2] loss: 0.000\n",
            "[epoch : 5, i :     4] loss: 0.000\n",
            "[epoch : 6, i :     2] loss: 0.000\n",
            "[epoch : 6, i :     4] loss: 0.000\n",
            "[epoch : 7, i :     2] loss: 0.000\n",
            "[epoch : 7, i :     4] loss: 0.000\n",
            "[epoch : 8, i :     2] loss: 0.000\n",
            "[epoch : 8, i :     4] loss: 0.000\n",
            "[epoch : 9, i :     2] loss: 0.000\n",
            "[epoch : 9, i :     4] loss: 0.000\n",
            "[epoch : 10, i :     2] loss: 0.000\n",
            "[epoch : 10, i :     4] loss: 0.000\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"padding-bottom: 20px;\" dir=\"rtl\">tf-idf + randodm undersampling</h3>\n"
      ],
      "metadata": {
        "id": "CF8MGUlngwB0"
      },
      "id": "CF8MGUlngwB0"
    },
    {
      "cell_type": "code",
      "source": [
        "rus = RandomUnderSampler(sampling_strategy='not minority', random_state=42)\n",
        "\n",
        "X_resampled, y_resampled = rus.fit_resample(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "df_balanced = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "# shuffle the rows of the new dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42)\n",
        "\n",
        "df_balanced"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "hNcPQJJsgwSk",
        "outputId": "e2ee6778-48fc-44e1-c764-5ed5a887d50f"
      },
      "id": "hNcPQJJsgwSk",
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     text_vector_0  text_vector_1  text_vector_2  text_vector_3  \\\n",
              "674            0.0            0.0            0.0            0.0   \n",
              "314            0.0            0.0            0.0            0.0   \n",
              "611            0.0            0.0            0.0            0.0   \n",
              "431            0.0            0.0            0.0            0.0   \n",
              "552            0.0            0.0            0.0            0.0   \n",
              "..             ...            ...            ...            ...   \n",
              "71             0.0            0.0            0.0            0.0   \n",
              "106            0.0            0.0            0.0            0.0   \n",
              "270            0.0            0.0            0.0            0.0   \n",
              "435            0.0            0.0            0.0            0.0   \n",
              "102            0.0            0.0            0.0            0.0   \n",
              "\n",
              "     text_vector_4  text_vector_5  text_vector_6  text_vector_7  \\\n",
              "674            0.0            0.0            0.0            0.0   \n",
              "314            0.0            0.0            0.0            0.0   \n",
              "611            0.0            0.0            0.0            0.0   \n",
              "431            0.0            0.0            0.0            0.0   \n",
              "552            0.0            0.0            0.0            0.0   \n",
              "..             ...            ...            ...            ...   \n",
              "71             0.0            0.0            0.0            0.0   \n",
              "106            0.0            0.0            0.0            0.0   \n",
              "270            0.0            0.0            0.0            0.0   \n",
              "435            0.0            0.0            0.0            0.0   \n",
              "102            0.0            0.0            0.0            0.0   \n",
              "\n",
              "     text_vector_8  text_vector_9  ...  text_vector_23540  text_vector_23541  \\\n",
              "674            0.0            0.0  ...                0.0                0.0   \n",
              "314            0.0            0.0  ...                0.0                0.0   \n",
              "611            0.0            0.0  ...                0.0                0.0   \n",
              "431            0.0            0.0  ...                0.0                0.0   \n",
              "552            0.0            0.0  ...                0.0                0.0   \n",
              "..             ...            ...  ...                ...                ...   \n",
              "71             0.0            0.0  ...                0.0                0.0   \n",
              "106            0.0            0.0  ...                0.0                0.0   \n",
              "270            0.0            0.0  ...                0.0                0.0   \n",
              "435            0.0            0.0  ...                0.0                0.0   \n",
              "102            0.0            0.0  ...                0.0                0.0   \n",
              "\n",
              "     text_vector_23542  text_vector_23543  text_vector_23544  \\\n",
              "674                0.0                0.0                0.0   \n",
              "314                0.0                0.0                0.0   \n",
              "611                0.0                0.0                0.0   \n",
              "431                0.0                0.0                0.0   \n",
              "552                0.0                0.0                0.0   \n",
              "..                 ...                ...                ...   \n",
              "71                 0.0                0.0                0.0   \n",
              "106                0.0                0.0                0.0   \n",
              "270                0.0                0.0                0.0   \n",
              "435                0.0                0.0                0.0   \n",
              "102                0.0                0.0                0.0   \n",
              "\n",
              "     text_vector_23545  text_vector_23546  text_vector_23547  \\\n",
              "674                0.0                0.0                0.0   \n",
              "314                0.0                0.0                0.0   \n",
              "611                0.0                0.0                0.0   \n",
              "431                0.0                0.0                0.0   \n",
              "552                0.0                0.0                0.0   \n",
              "..                 ...                ...                ...   \n",
              "71                 0.0                0.0                0.0   \n",
              "106                0.0                0.0                0.0   \n",
              "270                0.0                0.0                0.0   \n",
              "435                0.0                0.0                0.0   \n",
              "102                0.0                0.0                0.0   \n",
              "\n",
              "     text_vector_23548  category  \n",
              "674                0.0         3  \n",
              "314                0.0         1  \n",
              "611                0.0         3  \n",
              "431                0.0         2  \n",
              "552                0.0         3  \n",
              "..                 ...       ...  \n",
              "71                 0.0         0  \n",
              "106                0.0         0  \n",
              "270                0.0         1  \n",
              "435                0.0         2  \n",
              "102                0.0         0  \n",
              "\n",
              "[696 rows x 23550 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3afef311-0995-4da4-8a2f-0650f1371eae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_vector_0</th>\n",
              "      <th>text_vector_1</th>\n",
              "      <th>text_vector_2</th>\n",
              "      <th>text_vector_3</th>\n",
              "      <th>text_vector_4</th>\n",
              "      <th>text_vector_5</th>\n",
              "      <th>text_vector_6</th>\n",
              "      <th>text_vector_7</th>\n",
              "      <th>text_vector_8</th>\n",
              "      <th>text_vector_9</th>\n",
              "      <th>...</th>\n",
              "      <th>text_vector_23540</th>\n",
              "      <th>text_vector_23541</th>\n",
              "      <th>text_vector_23542</th>\n",
              "      <th>text_vector_23543</th>\n",
              "      <th>text_vector_23544</th>\n",
              "      <th>text_vector_23545</th>\n",
              "      <th>text_vector_23546</th>\n",
              "      <th>text_vector_23547</th>\n",
              "      <th>text_vector_23548</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>674</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>696 rows × 23550 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3afef311-0995-4da4-8a2f-0650f1371eae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3afef311-0995-4da4-8a2f-0650f1371eae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3afef311-0995-4da4-8a2f-0650f1371eae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X_train_tfidf.values, dtype=torch.float32)\n",
        "y = torch.tensor([y[0] for y in y_train_tfidf.values], dtype=torch.long)\n",
        "train_dataset = TensorDataset(X, y)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Initialize the network and optimizer\n",
        "model = MLP(X_train_tfidf.shape[1], 20, 4)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the network\n",
        "train(model, optimizer, criterion, train_loader, 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "765whF5KtKhZ",
        "outputId": "70138e3a-3fa3-4f9c-fc73-23e0e26b7b90"
      },
      "id": "765whF5KtKhZ",
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch : 1, i :     2] loss: 0.031\n",
            "[epoch : 1, i :     4] loss: 0.028\n",
            "[epoch : 1, i :     6] loss: 0.030\n",
            "[epoch : 1, i :     8] loss: 0.027\n",
            "[epoch : 1, i :    10] loss: 0.027\n",
            "[epoch : 1, i :    12] loss: 0.028\n",
            "[epoch : 1, i :    14] loss: 0.027\n",
            "[epoch : 1, i :    16] loss: 0.028\n",
            "[epoch : 1, i :    18] loss: 0.028\n",
            "[epoch : 1, i :    20] loss: 0.026\n",
            "[epoch : 1, i :    22] loss: 0.028\n",
            "[epoch : 1, i :    24] loss: 0.028\n",
            "[epoch : 1, i :    26] loss: 0.028\n",
            "[epoch : 1, i :    28] loss: 0.028\n",
            "[epoch : 1, i :    30] loss: 0.028\n",
            "[epoch : 1, i :    32] loss: 0.026\n",
            "[epoch : 1, i :    34] loss: 0.027\n",
            "[epoch : 1, i :    36] loss: 0.028\n",
            "[epoch : 1, i :    38] loss: 0.026\n",
            "[epoch : 1, i :    40] loss: 0.028\n",
            "[epoch : 1, i :    42] loss: 0.024\n",
            "[epoch : 1, i :    44] loss: 0.026\n",
            "[epoch : 1, i :    46] loss: 0.025\n",
            "[epoch : 1, i :    48] loss: 0.028\n",
            "[epoch : 1, i :    50] loss: 0.027\n",
            "[epoch : 1, i :    52] loss: 0.025\n",
            "[epoch : 1, i :    54] loss: 0.025\n",
            "[epoch : 1, i :    56] loss: 0.032\n",
            "[epoch : 1, i :    58] loss: 0.025\n",
            "[epoch : 1, i :    60] loss: 0.024\n",
            "[epoch : 1, i :    62] loss: 0.028\n",
            "[epoch : 1, i :    64] loss: 0.025\n",
            "[epoch : 1, i :    66] loss: 0.024\n",
            "[epoch : 1, i :    68] loss: 0.023\n",
            "[epoch : 1, i :    70] loss: 0.021\n",
            "[epoch : 1, i :    72] loss: 0.020\n",
            "[epoch : 1, i :    74] loss: 0.026\n",
            "[epoch : 1, i :    76] loss: 0.028\n",
            "[epoch : 1, i :    78] loss: 0.026\n",
            "[epoch : 1, i :    80] loss: 0.024\n",
            "[epoch : 1, i :    82] loss: 0.024\n",
            "[epoch : 1, i :    84] loss: 0.025\n",
            "[epoch : 1, i :    86] loss: 0.024\n",
            "[epoch : 1, i :    88] loss: 0.018\n",
            "[epoch : 1, i :    90] loss: 0.025\n",
            "[epoch : 1, i :    92] loss: 0.025\n",
            "[epoch : 1, i :    94] loss: 0.022\n",
            "[epoch : 1, i :    96] loss: 0.024\n",
            "[epoch : 1, i :    98] loss: 0.021\n",
            "[epoch : 1, i :   100] loss: 0.018\n",
            "[epoch : 1, i :   102] loss: 0.014\n",
            "[epoch : 1, i :   104] loss: 0.021\n",
            "[epoch : 1, i :   106] loss: 0.024\n",
            "[epoch : 1, i :   108] loss: 0.018\n",
            "[epoch : 1, i :   110] loss: 0.018\n",
            "[epoch : 1, i :   112] loss: 0.011\n",
            "[epoch : 1, i :   114] loss: 0.016\n",
            "[epoch : 1, i :   116] loss: 0.016\n",
            "[epoch : 1, i :   118] loss: 0.027\n",
            "[epoch : 1, i :   120] loss: 0.016\n",
            "[epoch : 1, i :   122] loss: 0.013\n",
            "[epoch : 1, i :   124] loss: 0.022\n",
            "[epoch : 1, i :   126] loss: 0.017\n",
            "[epoch : 1, i :   128] loss: 0.015\n",
            "[epoch : 1, i :   130] loss: 0.017\n",
            "[epoch : 1, i :   132] loss: 0.011\n",
            "[epoch : 1, i :   134] loss: 0.011\n",
            "[epoch : 1, i :   136] loss: 0.015\n",
            "[epoch : 1, i :   138] loss: 0.008\n",
            "[epoch : 1, i :   140] loss: 0.005\n",
            "[epoch : 1, i :   142] loss: 0.010\n",
            "[epoch : 1, i :   144] loss: 0.012\n",
            "[epoch : 1, i :   146] loss: 0.009\n",
            "[epoch : 1, i :   148] loss: 0.034\n",
            "[epoch : 1, i :   150] loss: 0.015\n",
            "[epoch : 1, i :   152] loss: 0.005\n",
            "[epoch : 1, i :   154] loss: 0.022\n",
            "[epoch : 1, i :   156] loss: 0.012\n",
            "[epoch : 1, i :   158] loss: 0.019\n",
            "[epoch : 1, i :   160] loss: 0.011\n",
            "[epoch : 1, i :   162] loss: 0.013\n",
            "[epoch : 1, i :   164] loss: 0.009\n",
            "[epoch : 1, i :   166] loss: 0.008\n",
            "[epoch : 1, i :   168] loss: 0.008\n",
            "[epoch : 1, i :   170] loss: 0.020\n",
            "[epoch : 1, i :   172] loss: 0.013\n",
            "[epoch : 1, i :   174] loss: 0.008\n",
            "[epoch : 1, i :   176] loss: 0.016\n",
            "[epoch : 1, i :   178] loss: 0.011\n",
            "[epoch : 1, i :   180] loss: 0.014\n",
            "[epoch : 1, i :   182] loss: 0.022\n",
            "[epoch : 1, i :   184] loss: 0.022\n",
            "[epoch : 1, i :   186] loss: 0.022\n",
            "[epoch : 1, i :   188] loss: 0.017\n",
            "[epoch : 1, i :   190] loss: 0.018\n",
            "[epoch : 1, i :   192] loss: 0.030\n",
            "[epoch : 1, i :   194] loss: 0.012\n",
            "[epoch : 1, i :   196] loss: 0.019\n",
            "[epoch : 1, i :   198] loss: 0.019\n",
            "[epoch : 1, i :   200] loss: 0.003\n",
            "[epoch : 1, i :   202] loss: 0.008\n",
            "[epoch : 1, i :   204] loss: 0.020\n",
            "[epoch : 1, i :   206] loss: 0.009\n",
            "[epoch : 1, i :   208] loss: 0.010\n",
            "[epoch : 1, i :   210] loss: 0.010\n",
            "[epoch : 1, i :   212] loss: 0.006\n",
            "[epoch : 1, i :   214] loss: 0.005\n",
            "[epoch : 1, i :   216] loss: 0.006\n",
            "[epoch : 1, i :   218] loss: 0.008\n",
            "[epoch : 1, i :   220] loss: 0.009\n",
            "[epoch : 1, i :   222] loss: 0.003\n",
            "[epoch : 1, i :   224] loss: 0.008\n",
            "[epoch : 1, i :   226] loss: 0.006\n",
            "[epoch : 1, i :   228] loss: 0.003\n",
            "[epoch : 1, i :   230] loss: 0.011\n",
            "[epoch : 1, i :   232] loss: 0.017\n",
            "[epoch : 1, i :   234] loss: 0.009\n",
            "[epoch : 1, i :   236] loss: 0.001\n",
            "[epoch : 1, i :   238] loss: 0.009\n",
            "[epoch : 1, i :   240] loss: 0.008\n",
            "[epoch : 1, i :   242] loss: 0.004\n",
            "[epoch : 1, i :   244] loss: 0.014\n",
            "[epoch : 1, i :   246] loss: 0.013\n",
            "[epoch : 1, i :   248] loss: 0.003\n",
            "[epoch : 1, i :   250] loss: 0.004\n",
            "[epoch : 1, i :   252] loss: 0.006\n",
            "[epoch : 1, i :   254] loss: 0.006\n",
            "[epoch : 1, i :   256] loss: 0.016\n",
            "[epoch : 1, i :   258] loss: 0.007\n",
            "[epoch : 1, i :   260] loss: 0.004\n",
            "[epoch : 1, i :   262] loss: 0.013\n",
            "[epoch : 1, i :   264] loss: 0.016\n",
            "[epoch : 1, i :   266] loss: 0.006\n",
            "[epoch : 1, i :   268] loss: 0.012\n",
            "[epoch : 1, i :   270] loss: 0.014\n",
            "[epoch : 1, i :   272] loss: 0.003\n",
            "[epoch : 1, i :   274] loss: 0.016\n",
            "[epoch : 1, i :   276] loss: 0.006\n",
            "[epoch : 1, i :   278] loss: 0.020\n",
            "[epoch : 1, i :   280] loss: 0.003\n",
            "[epoch : 1, i :   282] loss: 0.007\n",
            "[epoch : 1, i :   284] loss: 0.012\n",
            "[epoch : 1, i :   286] loss: 0.020\n",
            "[epoch : 1, i :   288] loss: 0.006\n",
            "[epoch : 1, i :   290] loss: 0.004\n",
            "[epoch : 1, i :   292] loss: 0.014\n",
            "[epoch : 1, i :   294] loss: 0.003\n",
            "[epoch : 1, i :   296] loss: 0.005\n",
            "[epoch : 1, i :   298] loss: 0.013\n",
            "[epoch : 1, i :   300] loss: 0.007\n",
            "[epoch : 1, i :   302] loss: 0.005\n",
            "[epoch : 1, i :   304] loss: 0.005\n",
            "[epoch : 1, i :   306] loss: 0.020\n",
            "[epoch : 1, i :   308] loss: 0.001\n",
            "[epoch : 1, i :   310] loss: 0.003\n",
            "[epoch : 1, i :   312] loss: 0.006\n",
            "[epoch : 1, i :   314] loss: 0.013\n",
            "[epoch : 1, i :   316] loss: 0.004\n",
            "[epoch : 1, i :   318] loss: 0.016\n",
            "[epoch : 1, i :   320] loss: 0.008\n",
            "[epoch : 1, i :   322] loss: 0.001\n",
            "[epoch : 1, i :   324] loss: 0.012\n",
            "[epoch : 1, i :   326] loss: 0.007\n",
            "[epoch : 1, i :   328] loss: 0.008\n",
            "[epoch : 1, i :   330] loss: 0.007\n",
            "[epoch : 1, i :   332] loss: 0.000\n",
            "[epoch : 1, i :   334] loss: 0.010\n",
            "[epoch : 1, i :   336] loss: 0.015\n",
            "[epoch : 1, i :   338] loss: 0.008\n",
            "[epoch : 1, i :   340] loss: 0.003\n",
            "[epoch : 1, i :   342] loss: 0.001\n",
            "[epoch : 1, i :   344] loss: 0.004\n",
            "[epoch : 1, i :   346] loss: 0.001\n",
            "[epoch : 1, i :   348] loss: 0.021\n",
            "[epoch : 1, i :   350] loss: 0.017\n",
            "[epoch : 1, i :   352] loss: 0.009\n",
            "[epoch : 1, i :   354] loss: 0.007\n",
            "[epoch : 1, i :   356] loss: 0.002\n",
            "[epoch : 1, i :   358] loss: 0.005\n",
            "[epoch : 1, i :   360] loss: 0.003\n",
            "[epoch : 1, i :   362] loss: 0.003\n",
            "[epoch : 1, i :   364] loss: 0.005\n",
            "[epoch : 1, i :   366] loss: 0.010\n",
            "[epoch : 1, i :   368] loss: 0.010\n",
            "[epoch : 1, i :   370] loss: 0.004\n",
            "[epoch : 1, i :   372] loss: 0.001\n",
            "[epoch : 1, i :   374] loss: 0.002\n",
            "[epoch : 1, i :   376] loss: 0.012\n",
            "[epoch : 1, i :   378] loss: 0.009\n",
            "[epoch : 1, i :   380] loss: 0.003\n",
            "[epoch : 1, i :   382] loss: 0.003\n",
            "[epoch : 1, i :   384] loss: 0.018\n",
            "[epoch : 1, i :   386] loss: 0.005\n",
            "[epoch : 1, i :   388] loss: 0.004\n",
            "[epoch : 1, i :   390] loss: 0.002\n",
            "[epoch : 1, i :   392] loss: 0.006\n",
            "[epoch : 1, i :   394] loss: 0.016\n",
            "[epoch : 1, i :   396] loss: 0.001\n",
            "[epoch : 1, i :   398] loss: 0.004\n",
            "[epoch : 1, i :   400] loss: 0.005\n",
            "[epoch : 1, i :   402] loss: 0.006\n",
            "[epoch : 1, i :   404] loss: 0.010\n",
            "[epoch : 1, i :   406] loss: 0.003\n",
            "[epoch : 1, i :   408] loss: 0.002\n",
            "[epoch : 1, i :   410] loss: 0.002\n",
            "[epoch : 1, i :   412] loss: 0.009\n",
            "[epoch : 1, i :   414] loss: 0.017\n",
            "[epoch : 1, i :   416] loss: 0.028\n",
            "[epoch : 1, i :   418] loss: 0.028\n",
            "[epoch : 1, i :   420] loss: 0.002\n",
            "[epoch : 1, i :   422] loss: 0.002\n",
            "[epoch : 1, i :   424] loss: 0.008\n",
            "[epoch : 1, i :   426] loss: 0.001\n",
            "[epoch : 1, i :   428] loss: 0.007\n",
            "[epoch : 1, i :   430] loss: 0.001\n",
            "[epoch : 1, i :   432] loss: 0.000\n",
            "[epoch : 1, i :   434] loss: 0.004\n",
            "[epoch : 1, i :   436] loss: 0.005\n",
            "[epoch : 1, i :   438] loss: 0.001\n",
            "[epoch : 1, i :   440] loss: 0.000\n",
            "[epoch : 1, i :   442] loss: 0.000\n",
            "[epoch : 1, i :   444] loss: 0.002\n",
            "[epoch : 1, i :   446] loss: 0.003\n",
            "[epoch : 1, i :   448] loss: 0.005\n",
            "[epoch : 1, i :   450] loss: 0.005\n",
            "[epoch : 1, i :   452] loss: 0.001\n",
            "[epoch : 1, i :   454] loss: 0.008\n",
            "[epoch : 1, i :   456] loss: 0.000\n",
            "[epoch : 1, i :   458] loss: 0.026\n",
            "[epoch : 1, i :   460] loss: 0.001\n",
            "[epoch : 1, i :   462] loss: 0.002\n",
            "[epoch : 1, i :   464] loss: 0.000\n",
            "[epoch : 1, i :   466] loss: 0.003\n",
            "[epoch : 2, i :     2] loss: 0.000\n",
            "[epoch : 2, i :     4] loss: 0.002\n",
            "[epoch : 2, i :     6] loss: 0.000\n",
            "[epoch : 2, i :     8] loss: 0.000\n",
            "[epoch : 2, i :    10] loss: 0.000\n",
            "[epoch : 2, i :    12] loss: 0.000\n",
            "[epoch : 2, i :    14] loss: 0.000\n",
            "[epoch : 2, i :    16] loss: 0.001\n",
            "[epoch : 2, i :    18] loss: 0.000\n",
            "[epoch : 2, i :    20] loss: 0.000\n",
            "[epoch : 2, i :    22] loss: 0.000\n",
            "[epoch : 2, i :    24] loss: 0.000\n",
            "[epoch : 2, i :    26] loss: 0.000\n",
            "[epoch : 2, i :    28] loss: 0.000\n",
            "[epoch : 2, i :    30] loss: 0.007\n",
            "[epoch : 2, i :    32] loss: 0.004\n",
            "[epoch : 2, i :    34] loss: 0.000\n",
            "[epoch : 2, i :    36] loss: 0.000\n",
            "[epoch : 2, i :    38] loss: 0.001\n",
            "[epoch : 2, i :    40] loss: 0.000\n",
            "[epoch : 2, i :    42] loss: 0.000\n",
            "[epoch : 2, i :    44] loss: 0.000\n",
            "[epoch : 2, i :    46] loss: 0.001\n",
            "[epoch : 2, i :    48] loss: 0.000\n",
            "[epoch : 2, i :    50] loss: 0.000\n",
            "[epoch : 2, i :    52] loss: 0.000\n",
            "[epoch : 2, i :    54] loss: 0.000\n",
            "[epoch : 2, i :    56] loss: 0.000\n",
            "[epoch : 2, i :    58] loss: 0.000\n",
            "[epoch : 2, i :    60] loss: 0.003\n",
            "[epoch : 2, i :    62] loss: 0.000\n",
            "[epoch : 2, i :    64] loss: 0.000\n",
            "[epoch : 2, i :    66] loss: 0.001\n",
            "[epoch : 2, i :    68] loss: 0.000\n",
            "[epoch : 2, i :    70] loss: 0.000\n",
            "[epoch : 2, i :    72] loss: 0.000\n",
            "[epoch : 2, i :    74] loss: 0.000\n",
            "[epoch : 2, i :    76] loss: 0.000\n",
            "[epoch : 2, i :    78] loss: 0.000\n",
            "[epoch : 2, i :    80] loss: 0.000\n",
            "[epoch : 2, i :    82] loss: 0.000\n",
            "[epoch : 2, i :    84] loss: 0.000\n",
            "[epoch : 2, i :    86] loss: 0.000\n",
            "[epoch : 2, i :    88] loss: 0.000\n",
            "[epoch : 2, i :    90] loss: 0.000\n",
            "[epoch : 2, i :    92] loss: 0.000\n",
            "[epoch : 2, i :    94] loss: 0.001\n",
            "[epoch : 2, i :    96] loss: 0.004\n",
            "[epoch : 2, i :    98] loss: 0.000\n",
            "[epoch : 2, i :   100] loss: 0.000\n",
            "[epoch : 2, i :   102] loss: 0.000\n",
            "[epoch : 2, i :   104] loss: 0.000\n",
            "[epoch : 2, i :   106] loss: 0.000\n",
            "[epoch : 2, i :   108] loss: 0.000\n",
            "[epoch : 2, i :   110] loss: 0.000\n",
            "[epoch : 2, i :   112] loss: 0.000\n",
            "[epoch : 2, i :   114] loss: 0.000\n",
            "[epoch : 2, i :   116] loss: 0.000\n",
            "[epoch : 2, i :   118] loss: 0.000\n",
            "[epoch : 2, i :   120] loss: 0.000\n",
            "[epoch : 2, i :   122] loss: 0.000\n",
            "[epoch : 2, i :   124] loss: 0.001\n",
            "[epoch : 2, i :   126] loss: 0.000\n",
            "[epoch : 2, i :   128] loss: 0.000\n",
            "[epoch : 2, i :   130] loss: 0.000\n",
            "[epoch : 2, i :   132] loss: 0.000\n",
            "[epoch : 2, i :   134] loss: 0.000\n",
            "[epoch : 2, i :   136] loss: 0.000\n",
            "[epoch : 2, i :   138] loss: 0.000\n",
            "[epoch : 2, i :   140] loss: 0.000\n",
            "[epoch : 2, i :   142] loss: 0.003\n",
            "[epoch : 2, i :   144] loss: 0.000\n",
            "[epoch : 2, i :   146] loss: 0.000\n",
            "[epoch : 2, i :   148] loss: 0.000\n",
            "[epoch : 2, i :   150] loss: 0.000\n",
            "[epoch : 2, i :   152] loss: 0.000\n",
            "[epoch : 2, i :   154] loss: 0.000\n",
            "[epoch : 2, i :   156] loss: 0.000\n",
            "[epoch : 2, i :   158] loss: 0.003\n",
            "[epoch : 2, i :   160] loss: 0.000\n",
            "[epoch : 2, i :   162] loss: 0.001\n",
            "[epoch : 2, i :   164] loss: 0.000\n",
            "[epoch : 2, i :   166] loss: 0.000\n",
            "[epoch : 2, i :   168] loss: 0.000\n",
            "[epoch : 2, i :   170] loss: 0.000\n",
            "[epoch : 2, i :   172] loss: 0.000\n",
            "[epoch : 2, i :   174] loss: 0.000\n",
            "[epoch : 2, i :   176] loss: 0.000\n",
            "[epoch : 2, i :   178] loss: 0.000\n",
            "[epoch : 2, i :   180] loss: 0.000\n",
            "[epoch : 2, i :   182] loss: 0.000\n",
            "[epoch : 2, i :   184] loss: 0.000\n",
            "[epoch : 2, i :   186] loss: 0.001\n",
            "[epoch : 2, i :   188] loss: 0.000\n",
            "[epoch : 2, i :   190] loss: 0.000\n",
            "[epoch : 2, i :   192] loss: 0.000\n",
            "[epoch : 2, i :   194] loss: 0.000\n",
            "[epoch : 2, i :   196] loss: 0.000\n",
            "[epoch : 2, i :   198] loss: 0.000\n",
            "[epoch : 2, i :   200] loss: 0.000\n",
            "[epoch : 2, i :   202] loss: 0.000\n",
            "[epoch : 2, i :   204] loss: 0.000\n",
            "[epoch : 2, i :   206] loss: 0.004\n",
            "[epoch : 2, i :   208] loss: 0.001\n",
            "[epoch : 2, i :   210] loss: 0.000\n",
            "[epoch : 2, i :   212] loss: 0.000\n",
            "[epoch : 2, i :   214] loss: 0.000\n",
            "[epoch : 2, i :   216] loss: 0.000\n",
            "[epoch : 2, i :   218] loss: 0.000\n",
            "[epoch : 2, i :   220] loss: 0.000\n",
            "[epoch : 2, i :   222] loss: 0.000\n",
            "[epoch : 2, i :   224] loss: 0.000\n",
            "[epoch : 2, i :   226] loss: 0.000\n",
            "[epoch : 2, i :   228] loss: 0.001\n",
            "[epoch : 2, i :   230] loss: 0.000\n",
            "[epoch : 2, i :   232] loss: 0.000\n",
            "[epoch : 2, i :   234] loss: 0.001\n",
            "[epoch : 2, i :   236] loss: 0.001\n",
            "[epoch : 2, i :   238] loss: 0.000\n",
            "[epoch : 2, i :   240] loss: 0.003\n",
            "[epoch : 2, i :   242] loss: 0.000\n",
            "[epoch : 2, i :   244] loss: 0.000\n",
            "[epoch : 2, i :   246] loss: 0.000\n",
            "[epoch : 2, i :   248] loss: 0.000\n",
            "[epoch : 2, i :   250] loss: 0.002\n",
            "[epoch : 2, i :   252] loss: 0.000\n",
            "[epoch : 2, i :   254] loss: 0.004\n",
            "[epoch : 2, i :   256] loss: 0.000\n",
            "[epoch : 2, i :   258] loss: 0.000\n",
            "[epoch : 2, i :   260] loss: 0.000\n",
            "[epoch : 2, i :   262] loss: 0.000\n",
            "[epoch : 2, i :   264] loss: 0.000\n",
            "[epoch : 2, i :   266] loss: 0.000\n",
            "[epoch : 2, i :   268] loss: 0.000\n",
            "[epoch : 2, i :   270] loss: 0.000\n",
            "[epoch : 2, i :   272] loss: 0.000\n",
            "[epoch : 2, i :   274] loss: 0.000\n",
            "[epoch : 2, i :   276] loss: 0.000\n",
            "[epoch : 2, i :   278] loss: 0.000\n",
            "[epoch : 2, i :   280] loss: 0.000\n",
            "[epoch : 2, i :   282] loss: 0.000\n",
            "[epoch : 2, i :   284] loss: 0.000\n",
            "[epoch : 2, i :   286] loss: 0.000\n",
            "[epoch : 2, i :   288] loss: 0.000\n",
            "[epoch : 2, i :   290] loss: 0.000\n",
            "[epoch : 2, i :   292] loss: 0.000\n",
            "[epoch : 2, i :   294] loss: 0.003\n",
            "[epoch : 2, i :   296] loss: 0.000\n",
            "[epoch : 2, i :   298] loss: 0.000\n",
            "[epoch : 2, i :   300] loss: 0.000\n",
            "[epoch : 2, i :   302] loss: 0.000\n",
            "[epoch : 2, i :   304] loss: 0.000\n",
            "[epoch : 2, i :   306] loss: 0.000\n",
            "[epoch : 2, i :   308] loss: 0.001\n",
            "[epoch : 2, i :   310] loss: 0.000\n",
            "[epoch : 2, i :   312] loss: 0.000\n",
            "[epoch : 2, i :   314] loss: 0.001\n",
            "[epoch : 2, i :   316] loss: 0.000\n",
            "[epoch : 2, i :   318] loss: 0.000\n",
            "[epoch : 2, i :   320] loss: 0.001\n",
            "[epoch : 2, i :   322] loss: 0.017\n",
            "[epoch : 2, i :   324] loss: 0.000\n",
            "[epoch : 2, i :   326] loss: 0.000\n",
            "[epoch : 2, i :   328] loss: 0.000\n",
            "[epoch : 2, i :   330] loss: 0.000\n",
            "[epoch : 2, i :   332] loss: 0.000\n",
            "[epoch : 2, i :   334] loss: 0.000\n",
            "[epoch : 2, i :   336] loss: 0.000\n",
            "[epoch : 2, i :   338] loss: 0.001\n",
            "[epoch : 2, i :   340] loss: 0.000\n",
            "[epoch : 2, i :   342] loss: 0.000\n",
            "[epoch : 2, i :   344] loss: 0.000\n",
            "[epoch : 2, i :   346] loss: 0.000\n",
            "[epoch : 2, i :   348] loss: 0.004\n",
            "[epoch : 2, i :   350] loss: 0.000\n",
            "[epoch : 2, i :   352] loss: 0.000\n",
            "[epoch : 2, i :   354] loss: 0.000\n",
            "[epoch : 2, i :   356] loss: 0.000\n",
            "[epoch : 2, i :   358] loss: 0.000\n",
            "[epoch : 2, i :   360] loss: 0.000\n",
            "[epoch : 2, i :   362] loss: 0.000\n",
            "[epoch : 2, i :   364] loss: 0.000\n",
            "[epoch : 2, i :   366] loss: 0.000\n",
            "[epoch : 2, i :   368] loss: 0.000\n",
            "[epoch : 2, i :   370] loss: 0.000\n",
            "[epoch : 2, i :   372] loss: 0.000\n",
            "[epoch : 2, i :   374] loss: 0.000\n",
            "[epoch : 2, i :   376] loss: 0.000\n",
            "[epoch : 2, i :   378] loss: 0.006\n",
            "[epoch : 2, i :   380] loss: 0.000\n",
            "[epoch : 2, i :   382] loss: 0.001\n",
            "[epoch : 2, i :   384] loss: 0.000\n",
            "[epoch : 2, i :   386] loss: 0.000\n",
            "[epoch : 2, i :   388] loss: 0.000\n",
            "[epoch : 2, i :   390] loss: 0.001\n",
            "[epoch : 2, i :   392] loss: 0.000\n",
            "[epoch : 2, i :   394] loss: 0.000\n",
            "[epoch : 2, i :   396] loss: 0.000\n",
            "[epoch : 2, i :   398] loss: 0.001\n",
            "[epoch : 2, i :   400] loss: 0.000\n",
            "[epoch : 2, i :   402] loss: 0.000\n",
            "[epoch : 2, i :   404] loss: 0.000\n",
            "[epoch : 2, i :   406] loss: 0.000\n",
            "[epoch : 2, i :   408] loss: 0.000\n",
            "[epoch : 2, i :   410] loss: 0.000\n",
            "[epoch : 2, i :   412] loss: 0.000\n",
            "[epoch : 2, i :   414] loss: 0.000\n",
            "[epoch : 2, i :   416] loss: 0.000\n",
            "[epoch : 2, i :   418] loss: 0.000\n",
            "[epoch : 2, i :   420] loss: 0.002\n",
            "[epoch : 2, i :   422] loss: 0.000\n",
            "[epoch : 2, i :   424] loss: 0.015\n",
            "[epoch : 2, i :   426] loss: 0.011\n",
            "[epoch : 2, i :   428] loss: 0.000\n",
            "[epoch : 2, i :   430] loss: 0.000\n",
            "[epoch : 2, i :   432] loss: 0.000\n",
            "[epoch : 2, i :   434] loss: 0.001\n",
            "[epoch : 2, i :   436] loss: 0.000\n",
            "[epoch : 2, i :   438] loss: 0.000\n",
            "[epoch : 2, i :   440] loss: 0.009\n",
            "[epoch : 2, i :   442] loss: 0.000\n",
            "[epoch : 2, i :   444] loss: 0.000\n",
            "[epoch : 2, i :   446] loss: 0.000\n",
            "[epoch : 2, i :   448] loss: 0.000\n",
            "[epoch : 2, i :   450] loss: 0.000\n",
            "[epoch : 2, i :   452] loss: 0.000\n",
            "[epoch : 2, i :   454] loss: 0.000\n",
            "[epoch : 2, i :   456] loss: 0.000\n",
            "[epoch : 2, i :   458] loss: 0.000\n",
            "[epoch : 2, i :   460] loss: 0.000\n",
            "[epoch : 2, i :   462] loss: 0.000\n",
            "[epoch : 2, i :   464] loss: 0.000\n",
            "[epoch : 2, i :   466] loss: 0.000\n",
            "[epoch : 3, i :     2] loss: 0.000\n",
            "[epoch : 3, i :     4] loss: 0.000\n",
            "[epoch : 3, i :     6] loss: 0.000\n",
            "[epoch : 3, i :     8] loss: 0.000\n",
            "[epoch : 3, i :    10] loss: 0.000\n",
            "[epoch : 3, i :    12] loss: 0.000\n",
            "[epoch : 3, i :    14] loss: 0.000\n",
            "[epoch : 3, i :    16] loss: 0.000\n",
            "[epoch : 3, i :    18] loss: 0.000\n",
            "[epoch : 3, i :    20] loss: 0.000\n",
            "[epoch : 3, i :    22] loss: 0.000\n",
            "[epoch : 3, i :    24] loss: 0.000\n",
            "[epoch : 3, i :    26] loss: 0.000\n",
            "[epoch : 3, i :    28] loss: 0.000\n",
            "[epoch : 3, i :    30] loss: 0.000\n",
            "[epoch : 3, i :    32] loss: 0.000\n",
            "[epoch : 3, i :    34] loss: 0.000\n",
            "[epoch : 3, i :    36] loss: 0.000\n",
            "[epoch : 3, i :    38] loss: 0.000\n",
            "[epoch : 3, i :    40] loss: 0.000\n",
            "[epoch : 3, i :    42] loss: 0.000\n",
            "[epoch : 3, i :    44] loss: 0.000\n",
            "[epoch : 3, i :    46] loss: 0.000\n",
            "[epoch : 3, i :    48] loss: 0.000\n",
            "[epoch : 3, i :    50] loss: 0.000\n",
            "[epoch : 3, i :    52] loss: 0.000\n",
            "[epoch : 3, i :    54] loss: 0.000\n",
            "[epoch : 3, i :    56] loss: 0.000\n",
            "[epoch : 3, i :    58] loss: 0.000\n",
            "[epoch : 3, i :    60] loss: 0.000\n",
            "[epoch : 3, i :    62] loss: 0.000\n",
            "[epoch : 3, i :    64] loss: 0.000\n",
            "[epoch : 3, i :    66] loss: 0.000\n",
            "[epoch : 3, i :    68] loss: 0.000\n",
            "[epoch : 3, i :    70] loss: 0.000\n",
            "[epoch : 3, i :    72] loss: 0.000\n",
            "[epoch : 3, i :    74] loss: 0.000\n",
            "[epoch : 3, i :    76] loss: 0.000\n",
            "[epoch : 3, i :    78] loss: 0.000\n",
            "[epoch : 3, i :    80] loss: 0.000\n",
            "[epoch : 3, i :    82] loss: 0.000\n",
            "[epoch : 3, i :    84] loss: 0.000\n",
            "[epoch : 3, i :    86] loss: 0.000\n",
            "[epoch : 3, i :    88] loss: 0.000\n",
            "[epoch : 3, i :    90] loss: 0.000\n",
            "[epoch : 3, i :    92] loss: 0.000\n",
            "[epoch : 3, i :    94] loss: 0.000\n",
            "[epoch : 3, i :    96] loss: 0.000\n",
            "[epoch : 3, i :    98] loss: 0.000\n",
            "[epoch : 3, i :   100] loss: 0.000\n",
            "[epoch : 3, i :   102] loss: 0.000\n",
            "[epoch : 3, i :   104] loss: 0.000\n",
            "[epoch : 3, i :   106] loss: 0.000\n",
            "[epoch : 3, i :   108] loss: 0.000\n",
            "[epoch : 3, i :   110] loss: 0.000\n",
            "[epoch : 3, i :   112] loss: 0.000\n",
            "[epoch : 3, i :   114] loss: 0.000\n",
            "[epoch : 3, i :   116] loss: 0.000\n",
            "[epoch : 3, i :   118] loss: 0.000\n",
            "[epoch : 3, i :   120] loss: 0.000\n",
            "[epoch : 3, i :   122] loss: 0.000\n",
            "[epoch : 3, i :   124] loss: 0.000\n",
            "[epoch : 3, i :   126] loss: 0.000\n",
            "[epoch : 3, i :   128] loss: 0.000\n",
            "[epoch : 3, i :   130] loss: 0.000\n",
            "[epoch : 3, i :   132] loss: 0.000\n",
            "[epoch : 3, i :   134] loss: 0.000\n",
            "[epoch : 3, i :   136] loss: 0.000\n",
            "[epoch : 3, i :   138] loss: 0.000\n",
            "[epoch : 3, i :   140] loss: 0.000\n",
            "[epoch : 3, i :   142] loss: 0.000\n",
            "[epoch : 3, i :   144] loss: 0.000\n",
            "[epoch : 3, i :   146] loss: 0.000\n",
            "[epoch : 3, i :   148] loss: 0.000\n",
            "[epoch : 3, i :   150] loss: 0.000\n",
            "[epoch : 3, i :   152] loss: 0.000\n",
            "[epoch : 3, i :   154] loss: 0.000\n",
            "[epoch : 3, i :   156] loss: 0.000\n",
            "[epoch : 3, i :   158] loss: 0.000\n",
            "[epoch : 3, i :   160] loss: 0.000\n",
            "[epoch : 3, i :   162] loss: 0.000\n",
            "[epoch : 3, i :   164] loss: 0.000\n",
            "[epoch : 3, i :   166] loss: 0.000\n",
            "[epoch : 3, i :   168] loss: 0.000\n",
            "[epoch : 3, i :   170] loss: 0.000\n",
            "[epoch : 3, i :   172] loss: 0.000\n",
            "[epoch : 3, i :   174] loss: 0.000\n",
            "[epoch : 3, i :   176] loss: 0.000\n",
            "[epoch : 3, i :   178] loss: 0.000\n",
            "[epoch : 3, i :   180] loss: 0.000\n",
            "[epoch : 3, i :   182] loss: 0.000\n",
            "[epoch : 3, i :   184] loss: 0.000\n",
            "[epoch : 3, i :   186] loss: 0.000\n",
            "[epoch : 3, i :   188] loss: 0.000\n",
            "[epoch : 3, i :   190] loss: 0.000\n",
            "[epoch : 3, i :   192] loss: 0.000\n",
            "[epoch : 3, i :   194] loss: 0.000\n",
            "[epoch : 3, i :   196] loss: 0.000\n",
            "[epoch : 3, i :   198] loss: 0.000\n",
            "[epoch : 3, i :   200] loss: 0.000\n",
            "[epoch : 3, i :   202] loss: 0.000\n",
            "[epoch : 3, i :   204] loss: 0.000\n",
            "[epoch : 3, i :   206] loss: 0.000\n",
            "[epoch : 3, i :   208] loss: 0.000\n",
            "[epoch : 3, i :   210] loss: 0.000\n",
            "[epoch : 3, i :   212] loss: 0.000\n",
            "[epoch : 3, i :   214] loss: 0.000\n",
            "[epoch : 3, i :   216] loss: 0.000\n",
            "[epoch : 3, i :   218] loss: 0.000\n",
            "[epoch : 3, i :   220] loss: 0.000\n",
            "[epoch : 3, i :   222] loss: 0.000\n",
            "[epoch : 3, i :   224] loss: 0.000\n",
            "[epoch : 3, i :   226] loss: 0.000\n",
            "[epoch : 3, i :   228] loss: 0.000\n",
            "[epoch : 3, i :   230] loss: 0.000\n",
            "[epoch : 3, i :   232] loss: 0.000\n",
            "[epoch : 3, i :   234] loss: 0.000\n",
            "[epoch : 3, i :   236] loss: 0.000\n",
            "[epoch : 3, i :   238] loss: 0.000\n",
            "[epoch : 3, i :   240] loss: 0.000\n",
            "[epoch : 3, i :   242] loss: 0.000\n",
            "[epoch : 3, i :   244] loss: 0.000\n",
            "[epoch : 3, i :   246] loss: 0.000\n",
            "[epoch : 3, i :   248] loss: 0.000\n",
            "[epoch : 3, i :   250] loss: 0.000\n",
            "[epoch : 3, i :   252] loss: 0.000\n",
            "[epoch : 3, i :   254] loss: 0.000\n",
            "[epoch : 3, i :   256] loss: 0.000\n",
            "[epoch : 3, i :   258] loss: 0.000\n",
            "[epoch : 3, i :   260] loss: 0.000\n",
            "[epoch : 3, i :   262] loss: 0.000\n",
            "[epoch : 3, i :   264] loss: 0.000\n",
            "[epoch : 3, i :   266] loss: 0.000\n",
            "[epoch : 3, i :   268] loss: 0.000\n",
            "[epoch : 3, i :   270] loss: 0.000\n",
            "[epoch : 3, i :   272] loss: 0.000\n",
            "[epoch : 3, i :   274] loss: 0.000\n",
            "[epoch : 3, i :   276] loss: 0.000\n",
            "[epoch : 3, i :   278] loss: 0.000\n",
            "[epoch : 3, i :   280] loss: 0.000\n",
            "[epoch : 3, i :   282] loss: 0.000\n",
            "[epoch : 3, i :   284] loss: 0.000\n",
            "[epoch : 3, i :   286] loss: 0.000\n",
            "[epoch : 3, i :   288] loss: 0.000\n",
            "[epoch : 3, i :   290] loss: 0.000\n",
            "[epoch : 3, i :   292] loss: 0.000\n",
            "[epoch : 3, i :   294] loss: 0.000\n",
            "[epoch : 3, i :   296] loss: 0.000\n",
            "[epoch : 3, i :   298] loss: 0.000\n",
            "[epoch : 3, i :   300] loss: 0.000\n",
            "[epoch : 3, i :   302] loss: 0.000\n",
            "[epoch : 3, i :   304] loss: 0.000\n",
            "[epoch : 3, i :   306] loss: 0.000\n",
            "[epoch : 3, i :   308] loss: 0.000\n",
            "[epoch : 3, i :   310] loss: 0.000\n",
            "[epoch : 3, i :   312] loss: 0.000\n",
            "[epoch : 3, i :   314] loss: 0.000\n",
            "[epoch : 3, i :   316] loss: 0.000\n",
            "[epoch : 3, i :   318] loss: 0.000\n",
            "[epoch : 3, i :   320] loss: 0.000\n",
            "[epoch : 3, i :   322] loss: 0.000\n",
            "[epoch : 3, i :   324] loss: 0.000\n",
            "[epoch : 3, i :   326] loss: 0.000\n",
            "[epoch : 3, i :   328] loss: 0.000\n",
            "[epoch : 3, i :   330] loss: 0.000\n",
            "[epoch : 3, i :   332] loss: 0.000\n",
            "[epoch : 3, i :   334] loss: 0.000\n",
            "[epoch : 3, i :   336] loss: 0.000\n",
            "[epoch : 3, i :   338] loss: 0.000\n",
            "[epoch : 3, i :   340] loss: 0.000\n",
            "[epoch : 3, i :   342] loss: 0.000\n",
            "[epoch : 3, i :   344] loss: 0.000\n",
            "[epoch : 3, i :   346] loss: 0.000\n",
            "[epoch : 3, i :   348] loss: 0.000\n",
            "[epoch : 3, i :   350] loss: 0.000\n",
            "[epoch : 3, i :   352] loss: 0.000\n",
            "[epoch : 3, i :   354] loss: 0.000\n",
            "[epoch : 3, i :   356] loss: 0.000\n",
            "[epoch : 3, i :   358] loss: 0.000\n",
            "[epoch : 3, i :   360] loss: 0.000\n",
            "[epoch : 3, i :   362] loss: 0.000\n",
            "[epoch : 3, i :   364] loss: 0.000\n",
            "[epoch : 3, i :   366] loss: 0.000\n",
            "[epoch : 3, i :   368] loss: 0.000\n",
            "[epoch : 3, i :   370] loss: 0.000\n",
            "[epoch : 3, i :   372] loss: 0.000\n",
            "[epoch : 3, i :   374] loss: 0.000\n",
            "[epoch : 3, i :   376] loss: 0.000\n",
            "[epoch : 3, i :   378] loss: 0.000\n",
            "[epoch : 3, i :   380] loss: 0.000\n",
            "[epoch : 3, i :   382] loss: 0.000\n",
            "[epoch : 3, i :   384] loss: 0.000\n",
            "[epoch : 3, i :   386] loss: 0.000\n",
            "[epoch : 3, i :   388] loss: 0.000\n",
            "[epoch : 3, i :   390] loss: 0.000\n",
            "[epoch : 3, i :   392] loss: 0.000\n",
            "[epoch : 3, i :   394] loss: 0.000\n",
            "[epoch : 3, i :   396] loss: 0.000\n",
            "[epoch : 3, i :   398] loss: 0.000\n",
            "[epoch : 3, i :   400] loss: 0.000\n",
            "[epoch : 3, i :   402] loss: 0.000\n",
            "[epoch : 3, i :   404] loss: 0.000\n",
            "[epoch : 3, i :   406] loss: 0.000\n",
            "[epoch : 3, i :   408] loss: 0.000\n",
            "[epoch : 3, i :   410] loss: 0.000\n",
            "[epoch : 3, i :   412] loss: 0.000\n",
            "[epoch : 3, i :   414] loss: 0.000\n",
            "[epoch : 3, i :   416] loss: 0.000\n",
            "[epoch : 3, i :   418] loss: 0.000\n",
            "[epoch : 3, i :   420] loss: 0.000\n",
            "[epoch : 3, i :   422] loss: 0.000\n",
            "[epoch : 3, i :   424] loss: 0.000\n",
            "[epoch : 3, i :   426] loss: 0.000\n",
            "[epoch : 3, i :   428] loss: 0.000\n",
            "[epoch : 3, i :   430] loss: 0.000\n",
            "[epoch : 3, i :   432] loss: 0.000\n",
            "[epoch : 3, i :   434] loss: 0.000\n",
            "[epoch : 3, i :   436] loss: 0.000\n",
            "[epoch : 3, i :   438] loss: 0.000\n",
            "[epoch : 3, i :   440] loss: 0.000\n",
            "[epoch : 3, i :   442] loss: 0.000\n",
            "[epoch : 3, i :   444] loss: 0.000\n",
            "[epoch : 3, i :   446] loss: 0.000\n",
            "[epoch : 3, i :   448] loss: 0.000\n",
            "[epoch : 3, i :   450] loss: 0.000\n",
            "[epoch : 3, i :   452] loss: 0.000\n",
            "[epoch : 3, i :   454] loss: 0.000\n",
            "[epoch : 3, i :   456] loss: 0.000\n",
            "[epoch : 3, i :   458] loss: 0.000\n",
            "[epoch : 3, i :   460] loss: 0.000\n",
            "[epoch : 3, i :   462] loss: 0.000\n",
            "[epoch : 3, i :   464] loss: 0.000\n",
            "[epoch : 3, i :   466] loss: 0.000\n",
            "[epoch : 4, i :     2] loss: 0.000\n",
            "[epoch : 4, i :     4] loss: 0.000\n",
            "[epoch : 4, i :     6] loss: 0.000\n",
            "[epoch : 4, i :     8] loss: 0.000\n",
            "[epoch : 4, i :    10] loss: 0.000\n",
            "[epoch : 4, i :    12] loss: 0.000\n",
            "[epoch : 4, i :    14] loss: 0.000\n",
            "[epoch : 4, i :    16] loss: 0.000\n",
            "[epoch : 4, i :    18] loss: 0.000\n",
            "[epoch : 4, i :    20] loss: 0.000\n",
            "[epoch : 4, i :    22] loss: 0.000\n",
            "[epoch : 4, i :    24] loss: 0.000\n",
            "[epoch : 4, i :    26] loss: 0.000\n",
            "[epoch : 4, i :    28] loss: 0.000\n",
            "[epoch : 4, i :    30] loss: 0.000\n",
            "[epoch : 4, i :    32] loss: 0.000\n",
            "[epoch : 4, i :    34] loss: 0.000\n",
            "[epoch : 4, i :    36] loss: 0.000\n",
            "[epoch : 4, i :    38] loss: 0.000\n",
            "[epoch : 4, i :    40] loss: 0.000\n",
            "[epoch : 4, i :    42] loss: 0.000\n",
            "[epoch : 4, i :    44] loss: 0.000\n",
            "[epoch : 4, i :    46] loss: 0.000\n",
            "[epoch : 4, i :    48] loss: 0.000\n",
            "[epoch : 4, i :    50] loss: 0.000\n",
            "[epoch : 4, i :    52] loss: 0.000\n",
            "[epoch : 4, i :    54] loss: 0.000\n",
            "[epoch : 4, i :    56] loss: 0.000\n",
            "[epoch : 4, i :    58] loss: 0.000\n",
            "[epoch : 4, i :    60] loss: 0.000\n",
            "[epoch : 4, i :    62] loss: 0.000\n",
            "[epoch : 4, i :    64] loss: 0.000\n",
            "[epoch : 4, i :    66] loss: 0.000\n",
            "[epoch : 4, i :    68] loss: 0.000\n",
            "[epoch : 4, i :    70] loss: 0.000\n",
            "[epoch : 4, i :    72] loss: 0.000\n",
            "[epoch : 4, i :    74] loss: 0.000\n",
            "[epoch : 4, i :    76] loss: 0.000\n",
            "[epoch : 4, i :    78] loss: 0.000\n",
            "[epoch : 4, i :    80] loss: 0.000\n",
            "[epoch : 4, i :    82] loss: 0.000\n",
            "[epoch : 4, i :    84] loss: 0.000\n",
            "[epoch : 4, i :    86] loss: 0.000\n",
            "[epoch : 4, i :    88] loss: 0.000\n",
            "[epoch : 4, i :    90] loss: 0.000\n",
            "[epoch : 4, i :    92] loss: 0.000\n",
            "[epoch : 4, i :    94] loss: 0.000\n",
            "[epoch : 4, i :    96] loss: 0.000\n",
            "[epoch : 4, i :    98] loss: 0.000\n",
            "[epoch : 4, i :   100] loss: 0.000\n",
            "[epoch : 4, i :   102] loss: 0.000\n",
            "[epoch : 4, i :   104] loss: 0.000\n",
            "[epoch : 4, i :   106] loss: 0.000\n",
            "[epoch : 4, i :   108] loss: 0.000\n",
            "[epoch : 4, i :   110] loss: 0.000\n",
            "[epoch : 4, i :   112] loss: 0.000\n",
            "[epoch : 4, i :   114] loss: 0.000\n",
            "[epoch : 4, i :   116] loss: 0.000\n",
            "[epoch : 4, i :   118] loss: 0.000\n",
            "[epoch : 4, i :   120] loss: 0.000\n",
            "[epoch : 4, i :   122] loss: 0.000\n",
            "[epoch : 4, i :   124] loss: 0.000\n",
            "[epoch : 4, i :   126] loss: 0.000\n",
            "[epoch : 4, i :   128] loss: 0.000\n",
            "[epoch : 4, i :   130] loss: 0.000\n",
            "[epoch : 4, i :   132] loss: 0.000\n",
            "[epoch : 4, i :   134] loss: 0.000\n",
            "[epoch : 4, i :   136] loss: 0.000\n",
            "[epoch : 4, i :   138] loss: 0.000\n",
            "[epoch : 4, i :   140] loss: 0.000\n",
            "[epoch : 4, i :   142] loss: 0.000\n",
            "[epoch : 4, i :   144] loss: 0.000\n",
            "[epoch : 4, i :   146] loss: 0.000\n",
            "[epoch : 4, i :   148] loss: 0.000\n",
            "[epoch : 4, i :   150] loss: 0.000\n",
            "[epoch : 4, i :   152] loss: 0.000\n",
            "[epoch : 4, i :   154] loss: 0.000\n",
            "[epoch : 4, i :   156] loss: 0.000\n",
            "[epoch : 4, i :   158] loss: 0.000\n",
            "[epoch : 4, i :   160] loss: 0.000\n",
            "[epoch : 4, i :   162] loss: 0.000\n",
            "[epoch : 4, i :   164] loss: 0.000\n",
            "[epoch : 4, i :   166] loss: 0.000\n",
            "[epoch : 4, i :   168] loss: 0.000\n",
            "[epoch : 4, i :   170] loss: 0.000\n",
            "[epoch : 4, i :   172] loss: 0.000\n",
            "[epoch : 4, i :   174] loss: 0.000\n",
            "[epoch : 4, i :   176] loss: 0.000\n",
            "[epoch : 4, i :   178] loss: 0.000\n",
            "[epoch : 4, i :   180] loss: 0.000\n",
            "[epoch : 4, i :   182] loss: 0.000\n",
            "[epoch : 4, i :   184] loss: 0.000\n",
            "[epoch : 4, i :   186] loss: 0.000\n",
            "[epoch : 4, i :   188] loss: 0.000\n",
            "[epoch : 4, i :   190] loss: 0.000\n",
            "[epoch : 4, i :   192] loss: 0.000\n",
            "[epoch : 4, i :   194] loss: 0.000\n",
            "[epoch : 4, i :   196] loss: 0.000\n",
            "[epoch : 4, i :   198] loss: 0.000\n",
            "[epoch : 4, i :   200] loss: 0.000\n",
            "[epoch : 4, i :   202] loss: 0.000\n",
            "[epoch : 4, i :   204] loss: 0.000\n",
            "[epoch : 4, i :   206] loss: 0.000\n",
            "[epoch : 4, i :   208] loss: 0.000\n",
            "[epoch : 4, i :   210] loss: 0.000\n",
            "[epoch : 4, i :   212] loss: 0.000\n",
            "[epoch : 4, i :   214] loss: 0.000\n",
            "[epoch : 4, i :   216] loss: 0.000\n",
            "[epoch : 4, i :   218] loss: 0.000\n",
            "[epoch : 4, i :   220] loss: 0.000\n",
            "[epoch : 4, i :   222] loss: 0.000\n",
            "[epoch : 4, i :   224] loss: 0.000\n",
            "[epoch : 4, i :   226] loss: 0.000\n",
            "[epoch : 4, i :   228] loss: 0.000\n",
            "[epoch : 4, i :   230] loss: 0.000\n",
            "[epoch : 4, i :   232] loss: 0.000\n",
            "[epoch : 4, i :   234] loss: 0.000\n",
            "[epoch : 4, i :   236] loss: 0.000\n",
            "[epoch : 4, i :   238] loss: 0.000\n",
            "[epoch : 4, i :   240] loss: 0.000\n",
            "[epoch : 4, i :   242] loss: 0.000\n",
            "[epoch : 4, i :   244] loss: 0.000\n",
            "[epoch : 4, i :   246] loss: 0.000\n",
            "[epoch : 4, i :   248] loss: 0.000\n",
            "[epoch : 4, i :   250] loss: 0.000\n",
            "[epoch : 4, i :   252] loss: 0.000\n",
            "[epoch : 4, i :   254] loss: 0.000\n",
            "[epoch : 4, i :   256] loss: 0.000\n",
            "[epoch : 4, i :   258] loss: 0.000\n",
            "[epoch : 4, i :   260] loss: 0.000\n",
            "[epoch : 4, i :   262] loss: 0.000\n",
            "[epoch : 4, i :   264] loss: 0.000\n",
            "[epoch : 4, i :   266] loss: 0.000\n",
            "[epoch : 4, i :   268] loss: 0.000\n",
            "[epoch : 4, i :   270] loss: 0.000\n",
            "[epoch : 4, i :   272] loss: 0.000\n",
            "[epoch : 4, i :   274] loss: 0.000\n",
            "[epoch : 4, i :   276] loss: 0.000\n",
            "[epoch : 4, i :   278] loss: 0.000\n",
            "[epoch : 4, i :   280] loss: 0.000\n",
            "[epoch : 4, i :   282] loss: 0.000\n",
            "[epoch : 4, i :   284] loss: 0.000\n",
            "[epoch : 4, i :   286] loss: 0.000\n",
            "[epoch : 4, i :   288] loss: 0.000\n",
            "[epoch : 4, i :   290] loss: 0.000\n",
            "[epoch : 4, i :   292] loss: 0.000\n",
            "[epoch : 4, i :   294] loss: 0.000\n",
            "[epoch : 4, i :   296] loss: 0.000\n",
            "[epoch : 4, i :   298] loss: 0.000\n",
            "[epoch : 4, i :   300] loss: 0.000\n",
            "[epoch : 4, i :   302] loss: 0.000\n",
            "[epoch : 4, i :   304] loss: 0.000\n",
            "[epoch : 4, i :   306] loss: 0.000\n",
            "[epoch : 4, i :   308] loss: 0.000\n",
            "[epoch : 4, i :   310] loss: 0.000\n",
            "[epoch : 4, i :   312] loss: 0.000\n",
            "[epoch : 4, i :   314] loss: 0.000\n",
            "[epoch : 4, i :   316] loss: 0.000\n",
            "[epoch : 4, i :   318] loss: 0.000\n",
            "[epoch : 4, i :   320] loss: 0.000\n",
            "[epoch : 4, i :   322] loss: 0.000\n",
            "[epoch : 4, i :   324] loss: 0.000\n",
            "[epoch : 4, i :   326] loss: 0.000\n",
            "[epoch : 4, i :   328] loss: 0.000\n",
            "[epoch : 4, i :   330] loss: 0.000\n",
            "[epoch : 4, i :   332] loss: 0.000\n",
            "[epoch : 4, i :   334] loss: 0.000\n",
            "[epoch : 4, i :   336] loss: 0.000\n",
            "[epoch : 4, i :   338] loss: 0.000\n",
            "[epoch : 4, i :   340] loss: 0.000\n",
            "[epoch : 4, i :   342] loss: 0.000\n",
            "[epoch : 4, i :   344] loss: 0.000\n",
            "[epoch : 4, i :   346] loss: 0.000\n",
            "[epoch : 4, i :   348] loss: 0.000\n",
            "[epoch : 4, i :   350] loss: 0.000\n",
            "[epoch : 4, i :   352] loss: 0.000\n",
            "[epoch : 4, i :   354] loss: 0.000\n",
            "[epoch : 4, i :   356] loss: 0.000\n",
            "[epoch : 4, i :   358] loss: 0.000\n",
            "[epoch : 4, i :   360] loss: 0.000\n",
            "[epoch : 4, i :   362] loss: 0.000\n",
            "[epoch : 4, i :   364] loss: 0.000\n",
            "[epoch : 4, i :   366] loss: 0.000\n",
            "[epoch : 4, i :   368] loss: 0.000\n",
            "[epoch : 4, i :   370] loss: 0.000\n",
            "[epoch : 4, i :   372] loss: 0.000\n",
            "[epoch : 4, i :   374] loss: 0.000\n",
            "[epoch : 4, i :   376] loss: 0.000\n",
            "[epoch : 4, i :   378] loss: 0.000\n",
            "[epoch : 4, i :   380] loss: 0.000\n",
            "[epoch : 4, i :   382] loss: 0.000\n",
            "[epoch : 4, i :   384] loss: 0.000\n",
            "[epoch : 4, i :   386] loss: 0.000\n",
            "[epoch : 4, i :   388] loss: 0.000\n",
            "[epoch : 4, i :   390] loss: 0.000\n",
            "[epoch : 4, i :   392] loss: 0.000\n",
            "[epoch : 4, i :   394] loss: 0.000\n",
            "[epoch : 4, i :   396] loss: 0.000\n",
            "[epoch : 4, i :   398] loss: 0.000\n",
            "[epoch : 4, i :   400] loss: 0.000\n",
            "[epoch : 4, i :   402] loss: 0.000\n",
            "[epoch : 4, i :   404] loss: 0.000\n",
            "[epoch : 4, i :   406] loss: 0.000\n",
            "[epoch : 4, i :   408] loss: 0.000\n",
            "[epoch : 4, i :   410] loss: 0.000\n",
            "[epoch : 4, i :   412] loss: 0.000\n",
            "[epoch : 4, i :   414] loss: 0.000\n",
            "[epoch : 4, i :   416] loss: 0.000\n",
            "[epoch : 4, i :   418] loss: 0.000\n",
            "[epoch : 4, i :   420] loss: 0.000\n",
            "[epoch : 4, i :   422] loss: 0.000\n",
            "[epoch : 4, i :   424] loss: 0.000\n",
            "[epoch : 4, i :   426] loss: 0.000\n",
            "[epoch : 4, i :   428] loss: 0.000\n",
            "[epoch : 4, i :   430] loss: 0.000\n",
            "[epoch : 4, i :   432] loss: 0.000\n",
            "[epoch : 4, i :   434] loss: 0.000\n",
            "[epoch : 4, i :   436] loss: 0.000\n",
            "[epoch : 4, i :   438] loss: 0.000\n",
            "[epoch : 4, i :   440] loss: 0.000\n",
            "[epoch : 4, i :   442] loss: 0.000\n",
            "[epoch : 4, i :   444] loss: 0.000\n",
            "[epoch : 4, i :   446] loss: 0.000\n",
            "[epoch : 4, i :   448] loss: 0.000\n",
            "[epoch : 4, i :   450] loss: 0.000\n",
            "[epoch : 4, i :   452] loss: 0.000\n",
            "[epoch : 4, i :   454] loss: 0.000\n",
            "[epoch : 4, i :   456] loss: 0.000\n",
            "[epoch : 4, i :   458] loss: 0.000\n",
            "[epoch : 4, i :   460] loss: 0.000\n",
            "[epoch : 4, i :   462] loss: 0.000\n",
            "[epoch : 4, i :   464] loss: 0.000\n",
            "[epoch : 4, i :   466] loss: 0.000\n",
            "[epoch : 5, i :     2] loss: 0.000\n",
            "[epoch : 5, i :     4] loss: 0.000\n",
            "[epoch : 5, i :     6] loss: 0.000\n",
            "[epoch : 5, i :     8] loss: 0.000\n",
            "[epoch : 5, i :    10] loss: 0.000\n",
            "[epoch : 5, i :    12] loss: 0.000\n",
            "[epoch : 5, i :    14] loss: 0.000\n",
            "[epoch : 5, i :    16] loss: 0.000\n",
            "[epoch : 5, i :    18] loss: 0.000\n",
            "[epoch : 5, i :    20] loss: 0.000\n",
            "[epoch : 5, i :    22] loss: 0.000\n",
            "[epoch : 5, i :    24] loss: 0.000\n",
            "[epoch : 5, i :    26] loss: 0.000\n",
            "[epoch : 5, i :    28] loss: 0.000\n",
            "[epoch : 5, i :    30] loss: 0.000\n",
            "[epoch : 5, i :    32] loss: 0.000\n",
            "[epoch : 5, i :    34] loss: 0.000\n",
            "[epoch : 5, i :    36] loss: 0.000\n",
            "[epoch : 5, i :    38] loss: 0.000\n",
            "[epoch : 5, i :    40] loss: 0.000\n",
            "[epoch : 5, i :    42] loss: 0.000\n",
            "[epoch : 5, i :    44] loss: 0.000\n",
            "[epoch : 5, i :    46] loss: 0.000\n",
            "[epoch : 5, i :    48] loss: 0.000\n",
            "[epoch : 5, i :    50] loss: 0.000\n",
            "[epoch : 5, i :    52] loss: 0.000\n",
            "[epoch : 5, i :    54] loss: 0.000\n",
            "[epoch : 5, i :    56] loss: 0.000\n",
            "[epoch : 5, i :    58] loss: 0.000\n",
            "[epoch : 5, i :    60] loss: 0.000\n",
            "[epoch : 5, i :    62] loss: 0.000\n",
            "[epoch : 5, i :    64] loss: 0.000\n",
            "[epoch : 5, i :    66] loss: 0.000\n",
            "[epoch : 5, i :    68] loss: 0.000\n",
            "[epoch : 5, i :    70] loss: 0.000\n",
            "[epoch : 5, i :    72] loss: 0.000\n",
            "[epoch : 5, i :    74] loss: 0.000\n",
            "[epoch : 5, i :    76] loss: 0.000\n",
            "[epoch : 5, i :    78] loss: 0.000\n",
            "[epoch : 5, i :    80] loss: 0.000\n",
            "[epoch : 5, i :    82] loss: 0.000\n",
            "[epoch : 5, i :    84] loss: 0.000\n",
            "[epoch : 5, i :    86] loss: 0.000\n",
            "[epoch : 5, i :    88] loss: 0.000\n",
            "[epoch : 5, i :    90] loss: 0.000\n",
            "[epoch : 5, i :    92] loss: 0.000\n",
            "[epoch : 5, i :    94] loss: 0.000\n",
            "[epoch : 5, i :    96] loss: 0.000\n",
            "[epoch : 5, i :    98] loss: 0.000\n",
            "[epoch : 5, i :   100] loss: 0.000\n",
            "[epoch : 5, i :   102] loss: 0.000\n",
            "[epoch : 5, i :   104] loss: 0.000\n",
            "[epoch : 5, i :   106] loss: 0.000\n",
            "[epoch : 5, i :   108] loss: 0.000\n",
            "[epoch : 5, i :   110] loss: 0.000\n",
            "[epoch : 5, i :   112] loss: 0.000\n",
            "[epoch : 5, i :   114] loss: 0.000\n",
            "[epoch : 5, i :   116] loss: 0.000\n",
            "[epoch : 5, i :   118] loss: 0.000\n",
            "[epoch : 5, i :   120] loss: 0.000\n",
            "[epoch : 5, i :   122] loss: 0.000\n",
            "[epoch : 5, i :   124] loss: 0.000\n",
            "[epoch : 5, i :   126] loss: 0.000\n",
            "[epoch : 5, i :   128] loss: 0.000\n",
            "[epoch : 5, i :   130] loss: 0.000\n",
            "[epoch : 5, i :   132] loss: 0.000\n",
            "[epoch : 5, i :   134] loss: 0.000\n",
            "[epoch : 5, i :   136] loss: 0.000\n",
            "[epoch : 5, i :   138] loss: 0.000\n",
            "[epoch : 5, i :   140] loss: 0.000\n",
            "[epoch : 5, i :   142] loss: 0.000\n",
            "[epoch : 5, i :   144] loss: 0.000\n",
            "[epoch : 5, i :   146] loss: 0.000\n",
            "[epoch : 5, i :   148] loss: 0.000\n",
            "[epoch : 5, i :   150] loss: 0.000\n",
            "[epoch : 5, i :   152] loss: 0.000\n",
            "[epoch : 5, i :   154] loss: 0.000\n",
            "[epoch : 5, i :   156] loss: 0.000\n",
            "[epoch : 5, i :   158] loss: 0.000\n",
            "[epoch : 5, i :   160] loss: 0.000\n",
            "[epoch : 5, i :   162] loss: 0.000\n",
            "[epoch : 5, i :   164] loss: 0.000\n",
            "[epoch : 5, i :   166] loss: 0.000\n",
            "[epoch : 5, i :   168] loss: 0.000\n",
            "[epoch : 5, i :   170] loss: 0.000\n",
            "[epoch : 5, i :   172] loss: 0.000\n",
            "[epoch : 5, i :   174] loss: 0.000\n",
            "[epoch : 5, i :   176] loss: 0.000\n",
            "[epoch : 5, i :   178] loss: 0.000\n",
            "[epoch : 5, i :   180] loss: 0.000\n",
            "[epoch : 5, i :   182] loss: 0.000\n",
            "[epoch : 5, i :   184] loss: 0.000\n",
            "[epoch : 5, i :   186] loss: 0.000\n",
            "[epoch : 5, i :   188] loss: 0.000\n",
            "[epoch : 5, i :   190] loss: 0.000\n",
            "[epoch : 5, i :   192] loss: 0.000\n",
            "[epoch : 5, i :   194] loss: 0.000\n",
            "[epoch : 5, i :   196] loss: 0.000\n",
            "[epoch : 5, i :   198] loss: 0.000\n",
            "[epoch : 5, i :   200] loss: 0.000\n",
            "[epoch : 5, i :   202] loss: 0.000\n",
            "[epoch : 5, i :   204] loss: 0.000\n",
            "[epoch : 5, i :   206] loss: 0.000\n",
            "[epoch : 5, i :   208] loss: 0.000\n",
            "[epoch : 5, i :   210] loss: 0.000\n",
            "[epoch : 5, i :   212] loss: 0.000\n",
            "[epoch : 5, i :   214] loss: 0.000\n",
            "[epoch : 5, i :   216] loss: 0.000\n",
            "[epoch : 5, i :   218] loss: 0.000\n",
            "[epoch : 5, i :   220] loss: 0.000\n",
            "[epoch : 5, i :   222] loss: 0.000\n",
            "[epoch : 5, i :   224] loss: 0.000\n",
            "[epoch : 5, i :   226] loss: 0.000\n",
            "[epoch : 5, i :   228] loss: 0.000\n",
            "[epoch : 5, i :   230] loss: 0.000\n",
            "[epoch : 5, i :   232] loss: 0.000\n",
            "[epoch : 5, i :   234] loss: 0.000\n",
            "[epoch : 5, i :   236] loss: 0.000\n",
            "[epoch : 5, i :   238] loss: 0.000\n",
            "[epoch : 5, i :   240] loss: 0.000\n",
            "[epoch : 5, i :   242] loss: 0.000\n",
            "[epoch : 5, i :   244] loss: 0.000\n",
            "[epoch : 5, i :   246] loss: 0.000\n",
            "[epoch : 5, i :   248] loss: 0.000\n",
            "[epoch : 5, i :   250] loss: 0.000\n",
            "[epoch : 5, i :   252] loss: 0.000\n",
            "[epoch : 5, i :   254] loss: 0.000\n",
            "[epoch : 5, i :   256] loss: 0.000\n",
            "[epoch : 5, i :   258] loss: 0.000\n",
            "[epoch : 5, i :   260] loss: 0.000\n",
            "[epoch : 5, i :   262] loss: 0.000\n",
            "[epoch : 5, i :   264] loss: 0.000\n",
            "[epoch : 5, i :   266] loss: 0.000\n",
            "[epoch : 5, i :   268] loss: 0.000\n",
            "[epoch : 5, i :   270] loss: 0.000\n",
            "[epoch : 5, i :   272] loss: 0.000\n",
            "[epoch : 5, i :   274] loss: 0.000\n",
            "[epoch : 5, i :   276] loss: 0.000\n",
            "[epoch : 5, i :   278] loss: 0.000\n",
            "[epoch : 5, i :   280] loss: 0.000\n",
            "[epoch : 5, i :   282] loss: 0.000\n",
            "[epoch : 5, i :   284] loss: 0.000\n",
            "[epoch : 5, i :   286] loss: 0.000\n",
            "[epoch : 5, i :   288] loss: 0.000\n",
            "[epoch : 5, i :   290] loss: 0.000\n",
            "[epoch : 5, i :   292] loss: 0.000\n",
            "[epoch : 5, i :   294] loss: 0.000\n",
            "[epoch : 5, i :   296] loss: 0.000\n",
            "[epoch : 5, i :   298] loss: 0.000\n",
            "[epoch : 5, i :   300] loss: 0.000\n",
            "[epoch : 5, i :   302] loss: 0.000\n",
            "[epoch : 5, i :   304] loss: 0.000\n",
            "[epoch : 5, i :   306] loss: 0.000\n",
            "[epoch : 5, i :   308] loss: 0.000\n",
            "[epoch : 5, i :   310] loss: 0.000\n",
            "[epoch : 5, i :   312] loss: 0.000\n",
            "[epoch : 5, i :   314] loss: 0.000\n",
            "[epoch : 5, i :   316] loss: 0.000\n",
            "[epoch : 5, i :   318] loss: 0.000\n",
            "[epoch : 5, i :   320] loss: 0.000\n",
            "[epoch : 5, i :   322] loss: 0.000\n",
            "[epoch : 5, i :   324] loss: 0.000\n",
            "[epoch : 5, i :   326] loss: 0.000\n",
            "[epoch : 5, i :   328] loss: 0.000\n",
            "[epoch : 5, i :   330] loss: 0.000\n",
            "[epoch : 5, i :   332] loss: 0.000\n",
            "[epoch : 5, i :   334] loss: 0.000\n",
            "[epoch : 5, i :   336] loss: 0.000\n",
            "[epoch : 5, i :   338] loss: 0.000\n",
            "[epoch : 5, i :   340] loss: 0.000\n",
            "[epoch : 5, i :   342] loss: 0.000\n",
            "[epoch : 5, i :   344] loss: 0.000\n",
            "[epoch : 5, i :   346] loss: 0.000\n",
            "[epoch : 5, i :   348] loss: 0.000\n",
            "[epoch : 5, i :   350] loss: 0.000\n",
            "[epoch : 5, i :   352] loss: 0.000\n",
            "[epoch : 5, i :   354] loss: 0.000\n",
            "[epoch : 5, i :   356] loss: 0.000\n",
            "[epoch : 5, i :   358] loss: 0.000\n",
            "[epoch : 5, i :   360] loss: 0.000\n",
            "[epoch : 5, i :   362] loss: 0.000\n",
            "[epoch : 5, i :   364] loss: 0.000\n",
            "[epoch : 5, i :   366] loss: 0.000\n",
            "[epoch : 5, i :   368] loss: 0.000\n",
            "[epoch : 5, i :   370] loss: 0.000\n",
            "[epoch : 5, i :   372] loss: 0.000\n",
            "[epoch : 5, i :   374] loss: 0.000\n",
            "[epoch : 5, i :   376] loss: 0.000\n",
            "[epoch : 5, i :   378] loss: 0.000\n",
            "[epoch : 5, i :   380] loss: 0.000\n",
            "[epoch : 5, i :   382] loss: 0.000\n",
            "[epoch : 5, i :   384] loss: 0.000\n",
            "[epoch : 5, i :   386] loss: 0.000\n",
            "[epoch : 5, i :   388] loss: 0.000\n",
            "[epoch : 5, i :   390] loss: 0.000\n",
            "[epoch : 5, i :   392] loss: 0.000\n",
            "[epoch : 5, i :   394] loss: 0.000\n",
            "[epoch : 5, i :   396] loss: 0.000\n",
            "[epoch : 5, i :   398] loss: 0.000\n",
            "[epoch : 5, i :   400] loss: 0.000\n",
            "[epoch : 5, i :   402] loss: 0.000\n",
            "[epoch : 5, i :   404] loss: 0.000\n",
            "[epoch : 5, i :   406] loss: 0.000\n",
            "[epoch : 5, i :   408] loss: 0.000\n",
            "[epoch : 5, i :   410] loss: 0.000\n",
            "[epoch : 5, i :   412] loss: 0.000\n",
            "[epoch : 5, i :   414] loss: 0.000\n",
            "[epoch : 5, i :   416] loss: 0.000\n",
            "[epoch : 5, i :   418] loss: 0.000\n",
            "[epoch : 5, i :   420] loss: 0.000\n",
            "[epoch : 5, i :   422] loss: 0.000\n",
            "[epoch : 5, i :   424] loss: 0.000\n",
            "[epoch : 5, i :   426] loss: 0.000\n",
            "[epoch : 5, i :   428] loss: 0.000\n",
            "[epoch : 5, i :   430] loss: 0.000\n",
            "[epoch : 5, i :   432] loss: 0.000\n",
            "[epoch : 5, i :   434] loss: 0.000\n",
            "[epoch : 5, i :   436] loss: 0.000\n",
            "[epoch : 5, i :   438] loss: 0.000\n",
            "[epoch : 5, i :   440] loss: 0.000\n",
            "[epoch : 5, i :   442] loss: 0.000\n",
            "[epoch : 5, i :   444] loss: 0.000\n",
            "[epoch : 5, i :   446] loss: 0.000\n",
            "[epoch : 5, i :   448] loss: 0.000\n",
            "[epoch : 5, i :   450] loss: 0.000\n",
            "[epoch : 5, i :   452] loss: 0.000\n",
            "[epoch : 5, i :   454] loss: 0.000\n",
            "[epoch : 5, i :   456] loss: 0.000\n",
            "[epoch : 5, i :   458] loss: 0.000\n",
            "[epoch : 5, i :   460] loss: 0.000\n",
            "[epoch : 5, i :   462] loss: 0.000\n",
            "[epoch : 5, i :   464] loss: 0.000\n",
            "[epoch : 5, i :   466] loss: 0.000\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"padding-bottom: 20px;\" dir=\"rtl\">BOW + weighted loss</h3>\n"
      ],
      "metadata": {
        "id": "bEtYYdMKgwdT"
      },
      "id": "bEtYYdMKgwdT"
    },
    {
      "cell_type": "code",
      "source": [
        "y = bow_df.loc[:, ['category']]\n",
        "X = bow_df.drop(['brand', 'image-count', 'price', 'city', 'category'], axis=1)\n",
        "\n",
        "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "train_data = torch.tensor(X_train_bow.values, dtype=torch.float32)\n",
        "train_labels = torch.tensor([y[0] for y in y_train_bow.values], dtype=torch.long)\n",
        "train_dataset = torch.utils.data.TensorDataset(train_data, train_labels)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Calculate class weights based on frequency\n",
        "class_freq = torch.bincount(train_labels)\n",
        "total_samples = len(train_labels)\n",
        "class_weights = total_samples / (len(class_freq) * class_freq.float())\n",
        "\n",
        "# Initialize the network and optimizer\n",
        "model = MLP(train_data.shape[1], 20, 4)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Define the loss function with class weights\n",
        "def weighted_cross_entropy_loss(outputs, labels):\n",
        "    return F.cross_entropy(outputs, labels, weight=class_weights)\n",
        "\n",
        "# Train the network using the weighted loss\n",
        "train(model, optimizer, weighted_cross_entropy_loss, train_loader, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPgGm8qMuJC_",
        "outputId": "082fe39c-56cc-4f12-8a3b-7e2820116706"
      },
      "id": "nPgGm8qMuJC_",
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch : 1, i :     2] loss: 0.027\n",
            "[epoch : 1, i :     4] loss: 0.026\n",
            "[epoch : 1, i :     6] loss: 0.026\n",
            "[epoch : 1, i :     8] loss: 0.027\n",
            "[epoch : 1, i :    10] loss: 0.022\n",
            "[epoch : 1, i :    12] loss: 0.031\n",
            "[epoch : 1, i :    14] loss: 0.031\n",
            "[epoch : 1, i :    16] loss: 0.025\n",
            "[epoch : 1, i :    18] loss: 0.020\n",
            "[epoch : 1, i :    20] loss: 0.026\n",
            "[epoch : 1, i :    22] loss: 0.025\n",
            "[epoch : 1, i :    24] loss: 0.022\n",
            "[epoch : 1, i :    26] loss: 0.022\n",
            "[epoch : 1, i :    28] loss: 0.027\n",
            "[epoch : 1, i :    30] loss: 0.031\n",
            "[epoch : 1, i :    32] loss: 0.026\n",
            "[epoch : 1, i :    34] loss: 0.014\n",
            "[epoch : 1, i :    36] loss: 0.021\n",
            "[epoch : 1, i :    38] loss: 0.019\n",
            "[epoch : 1, i :    40] loss: 0.028\n",
            "[epoch : 1, i :    42] loss: 0.022\n",
            "[epoch : 1, i :    44] loss: 0.026\n",
            "[epoch : 1, i :    46] loss: 0.026\n",
            "[epoch : 1, i :    48] loss: 0.027\n",
            "[epoch : 1, i :    50] loss: 0.007\n",
            "[epoch : 1, i :    52] loss: 0.021\n",
            "[epoch : 1, i :    54] loss: 0.024\n",
            "[epoch : 1, i :    56] loss: 0.023\n",
            "[epoch : 1, i :    58] loss: 0.020\n",
            "[epoch : 1, i :    60] loss: 0.010\n",
            "[epoch : 1, i :    62] loss: 0.017\n",
            "[epoch : 1, i :    64] loss: 0.021\n",
            "[epoch : 1, i :    66] loss: 0.026\n",
            "[epoch : 1, i :    68] loss: 0.005\n",
            "[epoch : 1, i :    70] loss: 0.017\n",
            "[epoch : 1, i :    72] loss: 0.020\n",
            "[epoch : 1, i :    74] loss: 0.005\n",
            "[epoch : 1, i :    76] loss: 0.021\n",
            "[epoch : 1, i :    78] loss: 0.020\n",
            "[epoch : 1, i :    80] loss: 0.028\n",
            "[epoch : 1, i :    82] loss: 0.017\n",
            "[epoch : 1, i :    84] loss: 0.018\n",
            "[epoch : 1, i :    86] loss: 0.013\n",
            "[epoch : 1, i :    88] loss: 0.019\n",
            "[epoch : 1, i :    90] loss: 0.014\n",
            "[epoch : 1, i :    92] loss: 0.008\n",
            "[epoch : 1, i :    94] loss: 0.010\n",
            "[epoch : 1, i :    96] loss: 0.012\n",
            "[epoch : 1, i :    98] loss: 0.006\n",
            "[epoch : 1, i :   100] loss: 0.011\n",
            "[epoch : 1, i :   102] loss: 0.005\n",
            "[epoch : 1, i :   104] loss: 0.008\n",
            "[epoch : 1, i :   106] loss: 0.005\n",
            "[epoch : 1, i :   108] loss: 0.008\n",
            "[epoch : 1, i :   110] loss: 0.014\n",
            "[epoch : 1, i :   112] loss: 0.025\n",
            "[epoch : 1, i :   114] loss: 0.008\n",
            "[epoch : 1, i :   116] loss: 0.006\n",
            "[epoch : 1, i :   118] loss: 0.006\n",
            "[epoch : 1, i :   120] loss: 0.005\n",
            "[epoch : 1, i :   122] loss: 0.016\n",
            "[epoch : 1, i :   124] loss: 0.016\n",
            "[epoch : 1, i :   126] loss: 0.015\n",
            "[epoch : 1, i :   128] loss: 0.012\n",
            "[epoch : 1, i :   130] loss: 0.012\n",
            "[epoch : 1, i :   132] loss: 0.007\n",
            "[epoch : 1, i :   134] loss: 0.008\n",
            "[epoch : 1, i :   136] loss: 0.004\n",
            "[epoch : 1, i :   138] loss: 0.009\n",
            "[epoch : 1, i :   140] loss: 0.033\n",
            "[epoch : 1, i :   142] loss: 0.011\n",
            "[epoch : 1, i :   144] loss: 0.017\n",
            "[epoch : 1, i :   146] loss: 0.001\n",
            "[epoch : 1, i :   148] loss: 0.012\n",
            "[epoch : 1, i :   150] loss: 0.005\n",
            "[epoch : 1, i :   152] loss: 0.012\n",
            "[epoch : 1, i :   154] loss: 0.007\n",
            "[epoch : 1, i :   156] loss: 0.005\n",
            "[epoch : 1, i :   158] loss: 0.005\n",
            "[epoch : 1, i :   160] loss: 0.009\n",
            "[epoch : 1, i :   162] loss: 0.006\n",
            "[epoch : 1, i :   164] loss: 0.013\n",
            "[epoch : 1, i :   166] loss: 0.006\n",
            "[epoch : 1, i :   168] loss: 0.013\n",
            "[epoch : 1, i :   170] loss: 0.008\n",
            "[epoch : 1, i :   172] loss: 0.006\n",
            "[epoch : 1, i :   174] loss: 0.001\n",
            "[epoch : 1, i :   176] loss: 0.001\n",
            "[epoch : 1, i :   178] loss: 0.043\n",
            "[epoch : 1, i :   180] loss: 0.014\n",
            "[epoch : 1, i :   182] loss: 0.001\n",
            "[epoch : 1, i :   184] loss: 0.004\n",
            "[epoch : 1, i :   186] loss: 0.014\n",
            "[epoch : 1, i :   188] loss: 0.007\n",
            "[epoch : 1, i :   190] loss: 0.009\n",
            "[epoch : 1, i :   192] loss: 0.010\n",
            "[epoch : 1, i :   194] loss: 0.019\n",
            "[epoch : 1, i :   196] loss: 0.001\n",
            "[epoch : 1, i :   198] loss: 0.017\n",
            "[epoch : 1, i :   200] loss: 0.003\n",
            "[epoch : 1, i :   202] loss: 0.010\n",
            "[epoch : 1, i :   204] loss: 0.013\n",
            "[epoch : 1, i :   206] loss: 0.007\n",
            "[epoch : 1, i :   208] loss: 0.011\n",
            "[epoch : 1, i :   210] loss: 0.007\n",
            "[epoch : 1, i :   212] loss: 0.007\n",
            "[epoch : 1, i :   214] loss: 0.020\n",
            "[epoch : 1, i :   216] loss: 0.015\n",
            "[epoch : 1, i :   218] loss: 0.010\n",
            "[epoch : 1, i :   220] loss: 0.019\n",
            "[epoch : 1, i :   222] loss: 0.010\n",
            "[epoch : 1, i :   224] loss: 0.007\n",
            "[epoch : 1, i :   226] loss: 0.001\n",
            "[epoch : 1, i :   228] loss: 0.022\n",
            "[epoch : 1, i :   230] loss: 0.007\n",
            "[epoch : 1, i :   232] loss: 0.004\n",
            "[epoch : 1, i :   234] loss: 0.008\n",
            "[epoch : 1, i :   236] loss: 0.015\n",
            "[epoch : 1, i :   238] loss: 0.004\n",
            "[epoch : 1, i :   240] loss: 0.000\n",
            "[epoch : 1, i :   242] loss: 0.025\n",
            "[epoch : 1, i :   244] loss: 0.002\n",
            "[epoch : 1, i :   246] loss: 0.003\n",
            "[epoch : 1, i :   248] loss: 0.001\n",
            "[epoch : 1, i :   250] loss: 0.010\n",
            "[epoch : 1, i :   252] loss: 0.000\n",
            "[epoch : 1, i :   254] loss: 0.037\n",
            "[epoch : 1, i :   256] loss: 0.004\n",
            "[epoch : 1, i :   258] loss: 0.000\n",
            "[epoch : 1, i :   260] loss: 0.004\n",
            "[epoch : 1, i :   262] loss: 0.001\n",
            "[epoch : 1, i :   264] loss: 0.003\n",
            "[epoch : 1, i :   266] loss: 0.006\n",
            "[epoch : 1, i :   268] loss: 0.001\n",
            "[epoch : 1, i :   270] loss: 0.013\n",
            "[epoch : 1, i :   272] loss: 0.008\n",
            "[epoch : 1, i :   274] loss: 0.006\n",
            "[epoch : 1, i :   276] loss: 0.014\n",
            "[epoch : 1, i :   278] loss: 0.007\n",
            "[epoch : 1, i :   280] loss: 0.001\n",
            "[epoch : 1, i :   282] loss: 0.023\n",
            "[epoch : 1, i :   284] loss: 0.024\n",
            "[epoch : 1, i :   286] loss: 0.010\n",
            "[epoch : 1, i :   288] loss: 0.001\n",
            "[epoch : 1, i :   290] loss: 0.000\n",
            "[epoch : 1, i :   292] loss: 0.000\n",
            "[epoch : 1, i :   294] loss: 0.014\n",
            "[epoch : 1, i :   296] loss: 0.025\n",
            "[epoch : 1, i :   298] loss: 0.004\n",
            "[epoch : 1, i :   300] loss: 0.003\n",
            "[epoch : 1, i :   302] loss: 0.005\n",
            "[epoch : 1, i :   304] loss: 0.000\n",
            "[epoch : 1, i :   306] loss: 0.001\n",
            "[epoch : 1, i :   308] loss: 0.000\n",
            "[epoch : 1, i :   310] loss: 0.012\n",
            "[epoch : 1, i :   312] loss: 0.012\n",
            "[epoch : 1, i :   314] loss: 0.005\n",
            "[epoch : 1, i :   316] loss: 0.006\n",
            "[epoch : 1, i :   318] loss: 0.000\n",
            "[epoch : 1, i :   320] loss: 0.000\n",
            "[epoch : 1, i :   322] loss: 0.007\n",
            "[epoch : 1, i :   324] loss: 0.007\n",
            "[epoch : 1, i :   326] loss: 0.002\n",
            "[epoch : 1, i :   328] loss: 0.003\n",
            "[epoch : 1, i :   330] loss: 0.004\n",
            "[epoch : 1, i :   332] loss: 0.009\n",
            "[epoch : 1, i :   334] loss: 0.001\n",
            "[epoch : 1, i :   336] loss: 0.054\n",
            "[epoch : 1, i :   338] loss: 0.005\n",
            "[epoch : 1, i :   340] loss: 0.030\n",
            "[epoch : 1, i :   342] loss: 0.025\n",
            "[epoch : 1, i :   344] loss: 0.001\n",
            "[epoch : 1, i :   346] loss: 0.000\n",
            "[epoch : 1, i :   348] loss: 0.010\n",
            "[epoch : 1, i :   350] loss: 0.019\n",
            "[epoch : 1, i :   352] loss: 0.001\n",
            "[epoch : 1, i :   354] loss: 0.000\n",
            "[epoch : 1, i :   356] loss: 0.009\n",
            "[epoch : 1, i :   358] loss: 0.028\n",
            "[epoch : 1, i :   360] loss: 0.005\n",
            "[epoch : 1, i :   362] loss: 0.002\n",
            "[epoch : 1, i :   364] loss: 0.000\n",
            "[epoch : 1, i :   366] loss: 0.006\n",
            "[epoch : 1, i :   368] loss: 0.002\n",
            "[epoch : 1, i :   370] loss: 0.036\n",
            "[epoch : 1, i :   372] loss: 0.001\n",
            "[epoch : 2, i :     2] loss: 0.001\n",
            "[epoch : 2, i :     4] loss: 0.001\n",
            "[epoch : 2, i :     6] loss: 0.001\n",
            "[epoch : 2, i :     8] loss: 0.000\n",
            "[epoch : 2, i :    10] loss: 0.000\n",
            "[epoch : 2, i :    12] loss: 0.006\n",
            "[epoch : 2, i :    14] loss: 0.006\n",
            "[epoch : 2, i :    16] loss: 0.003\n",
            "[epoch : 2, i :    18] loss: 0.000\n",
            "[epoch : 2, i :    20] loss: 0.005\n",
            "[epoch : 2, i :    22] loss: 0.000\n",
            "[epoch : 2, i :    24] loss: 0.005\n",
            "[epoch : 2, i :    26] loss: 0.001\n",
            "[epoch : 2, i :    28] loss: 0.000\n",
            "[epoch : 2, i :    30] loss: 0.000\n",
            "[epoch : 2, i :    32] loss: 0.001\n",
            "[epoch : 2, i :    34] loss: 0.000\n",
            "[epoch : 2, i :    36] loss: 0.001\n",
            "[epoch : 2, i :    38] loss: 0.002\n",
            "[epoch : 2, i :    40] loss: 0.002\n",
            "[epoch : 2, i :    42] loss: 0.002\n",
            "[epoch : 2, i :    44] loss: 0.000\n",
            "[epoch : 2, i :    46] loss: 0.000\n",
            "[epoch : 2, i :    48] loss: 0.001\n",
            "[epoch : 2, i :    50] loss: 0.003\n",
            "[epoch : 2, i :    52] loss: 0.000\n",
            "[epoch : 2, i :    54] loss: 0.002\n",
            "[epoch : 2, i :    56] loss: 0.000\n",
            "[epoch : 2, i :    58] loss: 0.000\n",
            "[epoch : 2, i :    60] loss: 0.000\n",
            "[epoch : 2, i :    62] loss: 0.000\n",
            "[epoch : 2, i :    64] loss: 0.001\n",
            "[epoch : 2, i :    66] loss: 0.000\n",
            "[epoch : 2, i :    68] loss: 0.007\n",
            "[epoch : 2, i :    70] loss: 0.002\n",
            "[epoch : 2, i :    72] loss: 0.000\n",
            "[epoch : 2, i :    74] loss: 0.002\n",
            "[epoch : 2, i :    76] loss: 0.000\n",
            "[epoch : 2, i :    78] loss: 0.001\n",
            "[epoch : 2, i :    80] loss: 0.004\n",
            "[epoch : 2, i :    82] loss: 0.000\n",
            "[epoch : 2, i :    84] loss: 0.003\n",
            "[epoch : 2, i :    86] loss: 0.000\n",
            "[epoch : 2, i :    88] loss: 0.000\n",
            "[epoch : 2, i :    90] loss: 0.000\n",
            "[epoch : 2, i :    92] loss: 0.000\n",
            "[epoch : 2, i :    94] loss: 0.001\n",
            "[epoch : 2, i :    96] loss: 0.006\n",
            "[epoch : 2, i :    98] loss: 0.000\n",
            "[epoch : 2, i :   100] loss: 0.005\n",
            "[epoch : 2, i :   102] loss: 0.000\n",
            "[epoch : 2, i :   104] loss: 0.003\n",
            "[epoch : 2, i :   106] loss: 0.000\n",
            "[epoch : 2, i :   108] loss: 0.000\n",
            "[epoch : 2, i :   110] loss: 0.001\n",
            "[epoch : 2, i :   112] loss: 0.000\n",
            "[epoch : 2, i :   114] loss: 0.000\n",
            "[epoch : 2, i :   116] loss: 0.001\n",
            "[epoch : 2, i :   118] loss: 0.001\n",
            "[epoch : 2, i :   120] loss: 0.002\n",
            "[epoch : 2, i :   122] loss: 0.001\n",
            "[epoch : 2, i :   124] loss: 0.000\n",
            "[epoch : 2, i :   126] loss: 0.001\n",
            "[epoch : 2, i :   128] loss: 0.007\n",
            "[epoch : 2, i :   130] loss: 0.004\n",
            "[epoch : 2, i :   132] loss: 0.000\n",
            "[epoch : 2, i :   134] loss: 0.000\n",
            "[epoch : 2, i :   136] loss: 0.000\n",
            "[epoch : 2, i :   138] loss: 0.002\n",
            "[epoch : 2, i :   140] loss: 0.002\n",
            "[epoch : 2, i :   142] loss: 0.000\n",
            "[epoch : 2, i :   144] loss: 0.001\n",
            "[epoch : 2, i :   146] loss: 0.004\n",
            "[epoch : 2, i :   148] loss: 0.001\n",
            "[epoch : 2, i :   150] loss: 0.000\n",
            "[epoch : 2, i :   152] loss: 0.000\n",
            "[epoch : 2, i :   154] loss: 0.000\n",
            "[epoch : 2, i :   156] loss: 0.001\n",
            "[epoch : 2, i :   158] loss: 0.000\n",
            "[epoch : 2, i :   160] loss: 0.008\n",
            "[epoch : 2, i :   162] loss: 0.001\n",
            "[epoch : 2, i :   164] loss: 0.000\n",
            "[epoch : 2, i :   166] loss: 0.003\n",
            "[epoch : 2, i :   168] loss: 0.000\n",
            "[epoch : 2, i :   170] loss: 0.000\n",
            "[epoch : 2, i :   172] loss: 0.004\n",
            "[epoch : 2, i :   174] loss: 0.000\n",
            "[epoch : 2, i :   176] loss: 0.000\n",
            "[epoch : 2, i :   178] loss: 0.001\n",
            "[epoch : 2, i :   180] loss: 0.002\n",
            "[epoch : 2, i :   182] loss: 0.000\n",
            "[epoch : 2, i :   184] loss: 0.000\n",
            "[epoch : 2, i :   186] loss: 0.000\n",
            "[epoch : 2, i :   188] loss: 0.001\n",
            "[epoch : 2, i :   190] loss: 0.000\n",
            "[epoch : 2, i :   192] loss: 0.000\n",
            "[epoch : 2, i :   194] loss: 0.000\n",
            "[epoch : 2, i :   196] loss: 0.005\n",
            "[epoch : 2, i :   198] loss: 0.002\n",
            "[epoch : 2, i :   200] loss: 0.000\n",
            "[epoch : 2, i :   202] loss: 0.000\n",
            "[epoch : 2, i :   204] loss: 0.000\n",
            "[epoch : 2, i :   206] loss: 0.000\n",
            "[epoch : 2, i :   208] loss: 0.000\n",
            "[epoch : 2, i :   210] loss: 0.004\n",
            "[epoch : 2, i :   212] loss: 0.003\n",
            "[epoch : 2, i :   214] loss: 0.000\n",
            "[epoch : 2, i :   216] loss: 0.001\n",
            "[epoch : 2, i :   218] loss: 0.001\n",
            "[epoch : 2, i :   220] loss: 0.000\n",
            "[epoch : 2, i :   222] loss: 0.000\n",
            "[epoch : 2, i :   224] loss: 0.003\n",
            "[epoch : 2, i :   226] loss: 0.000\n",
            "[epoch : 2, i :   228] loss: 0.000\n",
            "[epoch : 2, i :   230] loss: 0.000\n",
            "[epoch : 2, i :   232] loss: 0.000\n",
            "[epoch : 2, i :   234] loss: 0.020\n",
            "[epoch : 2, i :   236] loss: 0.000\n",
            "[epoch : 2, i :   238] loss: 0.000\n",
            "[epoch : 2, i :   240] loss: 0.001\n",
            "[epoch : 2, i :   242] loss: 0.001\n",
            "[epoch : 2, i :   244] loss: 0.000\n",
            "[epoch : 2, i :   246] loss: 0.001\n",
            "[epoch : 2, i :   248] loss: 0.006\n",
            "[epoch : 2, i :   250] loss: 0.000\n",
            "[epoch : 2, i :   252] loss: 0.004\n",
            "[epoch : 2, i :   254] loss: 0.000\n",
            "[epoch : 2, i :   256] loss: 0.001\n",
            "[epoch : 2, i :   258] loss: 0.007\n",
            "[epoch : 2, i :   260] loss: 0.000\n",
            "[epoch : 2, i :   262] loss: 0.000\n",
            "[epoch : 2, i :   264] loss: 0.000\n",
            "[epoch : 2, i :   266] loss: 0.002\n",
            "[epoch : 2, i :   268] loss: 0.000\n",
            "[epoch : 2, i :   270] loss: 0.000\n",
            "[epoch : 2, i :   272] loss: 0.013\n",
            "[epoch : 2, i :   274] loss: 0.002\n",
            "[epoch : 2, i :   276] loss: 0.000\n",
            "[epoch : 2, i :   278] loss: 0.004\n",
            "[epoch : 2, i :   280] loss: 0.000\n",
            "[epoch : 2, i :   282] loss: 0.000\n",
            "[epoch : 2, i :   284] loss: 0.000\n",
            "[epoch : 2, i :   286] loss: 0.000\n",
            "[epoch : 2, i :   288] loss: 0.001\n",
            "[epoch : 2, i :   290] loss: 0.000\n",
            "[epoch : 2, i :   292] loss: 0.014\n",
            "[epoch : 2, i :   294] loss: 0.002\n",
            "[epoch : 2, i :   296] loss: 0.000\n",
            "[epoch : 2, i :   298] loss: 0.001\n",
            "[epoch : 2, i :   300] loss: 0.000\n",
            "[epoch : 2, i :   302] loss: 0.009\n",
            "[epoch : 2, i :   304] loss: 0.000\n",
            "[epoch : 2, i :   306] loss: 0.001\n",
            "[epoch : 2, i :   308] loss: 0.001\n",
            "[epoch : 2, i :   310] loss: 0.000\n",
            "[epoch : 2, i :   312] loss: 0.005\n",
            "[epoch : 2, i :   314] loss: 0.000\n",
            "[epoch : 2, i :   316] loss: 0.000\n",
            "[epoch : 2, i :   318] loss: 0.001\n",
            "[epoch : 2, i :   320] loss: 0.001\n",
            "[epoch : 2, i :   322] loss: 0.000\n",
            "[epoch : 2, i :   324] loss: 0.000\n",
            "[epoch : 2, i :   326] loss: 0.001\n",
            "[epoch : 2, i :   328] loss: 0.000\n",
            "[epoch : 2, i :   330] loss: 0.004\n",
            "[epoch : 2, i :   332] loss: 0.000\n",
            "[epoch : 2, i :   334] loss: 0.005\n",
            "[epoch : 2, i :   336] loss: 0.000\n",
            "[epoch : 2, i :   338] loss: 0.001\n",
            "[epoch : 2, i :   340] loss: 0.000\n",
            "[epoch : 2, i :   342] loss: 0.003\n",
            "[epoch : 2, i :   344] loss: 0.000\n",
            "[epoch : 2, i :   346] loss: 0.004\n",
            "[epoch : 2, i :   348] loss: 0.002\n",
            "[epoch : 2, i :   350] loss: 0.001\n",
            "[epoch : 2, i :   352] loss: 0.001\n",
            "[epoch : 2, i :   354] loss: 0.000\n",
            "[epoch : 2, i :   356] loss: 0.000\n",
            "[epoch : 2, i :   358] loss: 0.002\n",
            "[epoch : 2, i :   360] loss: 0.000\n",
            "[epoch : 2, i :   362] loss: 0.000\n",
            "[epoch : 2, i :   364] loss: 0.001\n",
            "[epoch : 2, i :   366] loss: 0.001\n",
            "[epoch : 2, i :   368] loss: 0.001\n",
            "[epoch : 2, i :   370] loss: 0.002\n",
            "[epoch : 2, i :   372] loss: 0.000\n",
            "[epoch : 3, i :     2] loss: 0.000\n",
            "[epoch : 3, i :     4] loss: 0.000\n",
            "[epoch : 3, i :     6] loss: 0.000\n",
            "[epoch : 3, i :     8] loss: 0.000\n",
            "[epoch : 3, i :    10] loss: 0.000\n",
            "[epoch : 3, i :    12] loss: 0.000\n",
            "[epoch : 3, i :    14] loss: 0.000\n",
            "[epoch : 3, i :    16] loss: 0.000\n",
            "[epoch : 3, i :    18] loss: 0.001\n",
            "[epoch : 3, i :    20] loss: 0.000\n",
            "[epoch : 3, i :    22] loss: 0.001\n",
            "[epoch : 3, i :    24] loss: 0.000\n",
            "[epoch : 3, i :    26] loss: 0.000\n",
            "[epoch : 3, i :    28] loss: 0.000\n",
            "[epoch : 3, i :    30] loss: 0.000\n",
            "[epoch : 3, i :    32] loss: 0.000\n",
            "[epoch : 3, i :    34] loss: 0.000\n",
            "[epoch : 3, i :    36] loss: 0.000\n",
            "[epoch : 3, i :    38] loss: 0.000\n",
            "[epoch : 3, i :    40] loss: 0.000\n",
            "[epoch : 3, i :    42] loss: 0.000\n",
            "[epoch : 3, i :    44] loss: 0.000\n",
            "[epoch : 3, i :    46] loss: 0.000\n",
            "[epoch : 3, i :    48] loss: 0.000\n",
            "[epoch : 3, i :    50] loss: 0.000\n",
            "[epoch : 3, i :    52] loss: 0.000\n",
            "[epoch : 3, i :    54] loss: 0.000\n",
            "[epoch : 3, i :    56] loss: 0.000\n",
            "[epoch : 3, i :    58] loss: 0.000\n",
            "[epoch : 3, i :    60] loss: 0.000\n",
            "[epoch : 3, i :    62] loss: 0.001\n",
            "[epoch : 3, i :    64] loss: 0.000\n",
            "[epoch : 3, i :    66] loss: 0.001\n",
            "[epoch : 3, i :    68] loss: 0.000\n",
            "[epoch : 3, i :    70] loss: 0.002\n",
            "[epoch : 3, i :    72] loss: 0.000\n",
            "[epoch : 3, i :    74] loss: 0.000\n",
            "[epoch : 3, i :    76] loss: 0.000\n",
            "[epoch : 3, i :    78] loss: 0.000\n",
            "[epoch : 3, i :    80] loss: 0.000\n",
            "[epoch : 3, i :    82] loss: 0.000\n",
            "[epoch : 3, i :    84] loss: 0.000\n",
            "[epoch : 3, i :    86] loss: 0.000\n",
            "[epoch : 3, i :    88] loss: 0.000\n",
            "[epoch : 3, i :    90] loss: 0.000\n",
            "[epoch : 3, i :    92] loss: 0.000\n",
            "[epoch : 3, i :    94] loss: 0.000\n",
            "[epoch : 3, i :    96] loss: 0.001\n",
            "[epoch : 3, i :    98] loss: 0.000\n",
            "[epoch : 3, i :   100] loss: 0.000\n",
            "[epoch : 3, i :   102] loss: 0.000\n",
            "[epoch : 3, i :   104] loss: 0.000\n",
            "[epoch : 3, i :   106] loss: 0.000\n",
            "[epoch : 3, i :   108] loss: 0.001\n",
            "[epoch : 3, i :   110] loss: 0.000\n",
            "[epoch : 3, i :   112] loss: 0.000\n",
            "[epoch : 3, i :   114] loss: 0.000\n",
            "[epoch : 3, i :   116] loss: 0.000\n",
            "[epoch : 3, i :   118] loss: 0.000\n",
            "[epoch : 3, i :   120] loss: 0.000\n",
            "[epoch : 3, i :   122] loss: 0.000\n",
            "[epoch : 3, i :   124] loss: 0.000\n",
            "[epoch : 3, i :   126] loss: 0.000\n",
            "[epoch : 3, i :   128] loss: 0.000\n",
            "[epoch : 3, i :   130] loss: 0.000\n",
            "[epoch : 3, i :   132] loss: 0.000\n",
            "[epoch : 3, i :   134] loss: 0.000\n",
            "[epoch : 3, i :   136] loss: 0.000\n",
            "[epoch : 3, i :   138] loss: 0.000\n",
            "[epoch : 3, i :   140] loss: 0.000\n",
            "[epoch : 3, i :   142] loss: 0.000\n",
            "[epoch : 3, i :   144] loss: 0.010\n",
            "[epoch : 3, i :   146] loss: 0.000\n",
            "[epoch : 3, i :   148] loss: 0.000\n",
            "[epoch : 3, i :   150] loss: 0.000\n",
            "[epoch : 3, i :   152] loss: 0.000\n",
            "[epoch : 3, i :   154] loss: 0.000\n",
            "[epoch : 3, i :   156] loss: 0.000\n",
            "[epoch : 3, i :   158] loss: 0.000\n",
            "[epoch : 3, i :   160] loss: 0.000\n",
            "[epoch : 3, i :   162] loss: 0.000\n",
            "[epoch : 3, i :   164] loss: 0.000\n",
            "[epoch : 3, i :   166] loss: 0.000\n",
            "[epoch : 3, i :   168] loss: 0.000\n",
            "[epoch : 3, i :   170] loss: 0.000\n",
            "[epoch : 3, i :   172] loss: 0.000\n",
            "[epoch : 3, i :   174] loss: 0.000\n",
            "[epoch : 3, i :   176] loss: 0.000\n",
            "[epoch : 3, i :   178] loss: 0.000\n",
            "[epoch : 3, i :   180] loss: 0.000\n",
            "[epoch : 3, i :   182] loss: 0.001\n",
            "[epoch : 3, i :   184] loss: 0.000\n",
            "[epoch : 3, i :   186] loss: 0.000\n",
            "[epoch : 3, i :   188] loss: 0.000\n",
            "[epoch : 3, i :   190] loss: 0.000\n",
            "[epoch : 3, i :   192] loss: 0.000\n",
            "[epoch : 3, i :   194] loss: 0.000\n",
            "[epoch : 3, i :   196] loss: 0.000\n",
            "[epoch : 3, i :   198] loss: 0.016\n",
            "[epoch : 3, i :   200] loss: 0.001\n",
            "[epoch : 3, i :   202] loss: 0.000\n",
            "[epoch : 3, i :   204] loss: 0.000\n",
            "[epoch : 3, i :   206] loss: 0.000\n",
            "[epoch : 3, i :   208] loss: 0.000\n",
            "[epoch : 3, i :   210] loss: 0.000\n",
            "[epoch : 3, i :   212] loss: 0.000\n",
            "[epoch : 3, i :   214] loss: 0.000\n",
            "[epoch : 3, i :   216] loss: 0.001\n",
            "[epoch : 3, i :   218] loss: 0.000\n",
            "[epoch : 3, i :   220] loss: 0.000\n",
            "[epoch : 3, i :   222] loss: 0.002\n",
            "[epoch : 3, i :   224] loss: 0.006\n",
            "[epoch : 3, i :   226] loss: 0.000\n",
            "[epoch : 3, i :   228] loss: 0.000\n",
            "[epoch : 3, i :   230] loss: 0.000\n",
            "[epoch : 3, i :   232] loss: 0.000\n",
            "[epoch : 3, i :   234] loss: 0.000\n",
            "[epoch : 3, i :   236] loss: 0.000\n",
            "[epoch : 3, i :   238] loss: 0.000\n",
            "[epoch : 3, i :   240] loss: 0.000\n",
            "[epoch : 3, i :   242] loss: 0.000\n",
            "[epoch : 3, i :   244] loss: 0.000\n",
            "[epoch : 3, i :   246] loss: 0.000\n",
            "[epoch : 3, i :   248] loss: 0.000\n",
            "[epoch : 3, i :   250] loss: 0.000\n",
            "[epoch : 3, i :   252] loss: 0.000\n",
            "[epoch : 3, i :   254] loss: 0.000\n",
            "[epoch : 3, i :   256] loss: 0.000\n",
            "[epoch : 3, i :   258] loss: 0.000\n",
            "[epoch : 3, i :   260] loss: 0.000\n",
            "[epoch : 3, i :   262] loss: 0.000\n",
            "[epoch : 3, i :   264] loss: 0.000\n",
            "[epoch : 3, i :   266] loss: 0.000\n",
            "[epoch : 3, i :   268] loss: 0.000\n",
            "[epoch : 3, i :   270] loss: 0.012\n",
            "[epoch : 3, i :   272] loss: 0.000\n",
            "[epoch : 3, i :   274] loss: 0.000\n",
            "[epoch : 3, i :   276] loss: 0.000\n",
            "[epoch : 3, i :   278] loss: 0.000\n",
            "[epoch : 3, i :   280] loss: 0.000\n",
            "[epoch : 3, i :   282] loss: 0.000\n",
            "[epoch : 3, i :   284] loss: 0.000\n",
            "[epoch : 3, i :   286] loss: 0.000\n",
            "[epoch : 3, i :   288] loss: 0.003\n",
            "[epoch : 3, i :   290] loss: 0.000\n",
            "[epoch : 3, i :   292] loss: 0.000\n",
            "[epoch : 3, i :   294] loss: 0.000\n",
            "[epoch : 3, i :   296] loss: 0.000\n",
            "[epoch : 3, i :   298] loss: 0.000\n",
            "[epoch : 3, i :   300] loss: 0.000\n",
            "[epoch : 3, i :   302] loss: 0.000\n",
            "[epoch : 3, i :   304] loss: 0.000\n",
            "[epoch : 3, i :   306] loss: 0.000\n",
            "[epoch : 3, i :   308] loss: 0.000\n",
            "[epoch : 3, i :   310] loss: 0.002\n",
            "[epoch : 3, i :   312] loss: 0.000\n",
            "[epoch : 3, i :   314] loss: 0.000\n",
            "[epoch : 3, i :   316] loss: 0.000\n",
            "[epoch : 3, i :   318] loss: 0.000\n",
            "[epoch : 3, i :   320] loss: 0.000\n",
            "[epoch : 3, i :   322] loss: 0.000\n",
            "[epoch : 3, i :   324] loss: 0.001\n",
            "[epoch : 3, i :   326] loss: 0.000\n",
            "[epoch : 3, i :   328] loss: 0.000\n",
            "[epoch : 3, i :   330] loss: 0.000\n",
            "[epoch : 3, i :   332] loss: 0.000\n",
            "[epoch : 3, i :   334] loss: 0.000\n",
            "[epoch : 3, i :   336] loss: 0.000\n",
            "[epoch : 3, i :   338] loss: 0.000\n",
            "[epoch : 3, i :   340] loss: 0.002\n",
            "[epoch : 3, i :   342] loss: 0.000\n",
            "[epoch : 3, i :   344] loss: 0.000\n",
            "[epoch : 3, i :   346] loss: 0.000\n",
            "[epoch : 3, i :   348] loss: 0.000\n",
            "[epoch : 3, i :   350] loss: 0.000\n",
            "[epoch : 3, i :   352] loss: 0.000\n",
            "[epoch : 3, i :   354] loss: 0.000\n",
            "[epoch : 3, i :   356] loss: 0.000\n",
            "[epoch : 3, i :   358] loss: 0.000\n",
            "[epoch : 3, i :   360] loss: 0.000\n",
            "[epoch : 3, i :   362] loss: 0.000\n",
            "[epoch : 3, i :   364] loss: 0.000\n",
            "[epoch : 3, i :   366] loss: 0.000\n",
            "[epoch : 3, i :   368] loss: 0.006\n",
            "[epoch : 3, i :   370] loss: 0.000\n",
            "[epoch : 3, i :   372] loss: 0.000\n",
            "[epoch : 4, i :     2] loss: 0.000\n",
            "[epoch : 4, i :     4] loss: 0.000\n",
            "[epoch : 4, i :     6] loss: 0.000\n",
            "[epoch : 4, i :     8] loss: 0.000\n",
            "[epoch : 4, i :    10] loss: 0.000\n",
            "[epoch : 4, i :    12] loss: 0.000\n",
            "[epoch : 4, i :    14] loss: 0.000\n",
            "[epoch : 4, i :    16] loss: 0.000\n",
            "[epoch : 4, i :    18] loss: 0.000\n",
            "[epoch : 4, i :    20] loss: 0.000\n",
            "[epoch : 4, i :    22] loss: 0.000\n",
            "[epoch : 4, i :    24] loss: 0.000\n",
            "[epoch : 4, i :    26] loss: 0.000\n",
            "[epoch : 4, i :    28] loss: 0.000\n",
            "[epoch : 4, i :    30] loss: 0.000\n",
            "[epoch : 4, i :    32] loss: 0.000\n",
            "[epoch : 4, i :    34] loss: 0.000\n",
            "[epoch : 4, i :    36] loss: 0.000\n",
            "[epoch : 4, i :    38] loss: 0.000\n",
            "[epoch : 4, i :    40] loss: 0.000\n",
            "[epoch : 4, i :    42] loss: 0.000\n",
            "[epoch : 4, i :    44] loss: 0.000\n",
            "[epoch : 4, i :    46] loss: 0.000\n",
            "[epoch : 4, i :    48] loss: 0.000\n",
            "[epoch : 4, i :    50] loss: 0.000\n",
            "[epoch : 4, i :    52] loss: 0.001\n",
            "[epoch : 4, i :    54] loss: 0.000\n",
            "[epoch : 4, i :    56] loss: 0.000\n",
            "[epoch : 4, i :    58] loss: 0.000\n",
            "[epoch : 4, i :    60] loss: 0.000\n",
            "[epoch : 4, i :    62] loss: 0.000\n",
            "[epoch : 4, i :    64] loss: 0.000\n",
            "[epoch : 4, i :    66] loss: 0.000\n",
            "[epoch : 4, i :    68] loss: 0.000\n",
            "[epoch : 4, i :    70] loss: 0.000\n",
            "[epoch : 4, i :    72] loss: 0.000\n",
            "[epoch : 4, i :    74] loss: 0.000\n",
            "[epoch : 4, i :    76] loss: 0.000\n",
            "[epoch : 4, i :    78] loss: 0.000\n",
            "[epoch : 4, i :    80] loss: 0.000\n",
            "[epoch : 4, i :    82] loss: 0.000\n",
            "[epoch : 4, i :    84] loss: 0.000\n",
            "[epoch : 4, i :    86] loss: 0.000\n",
            "[epoch : 4, i :    88] loss: 0.000\n",
            "[epoch : 4, i :    90] loss: 0.000\n",
            "[epoch : 4, i :    92] loss: 0.000\n",
            "[epoch : 4, i :    94] loss: 0.000\n",
            "[epoch : 4, i :    96] loss: 0.000\n",
            "[epoch : 4, i :    98] loss: 0.000\n",
            "[epoch : 4, i :   100] loss: 0.000\n",
            "[epoch : 4, i :   102] loss: 0.000\n",
            "[epoch : 4, i :   104] loss: 0.000\n",
            "[epoch : 4, i :   106] loss: 0.000\n",
            "[epoch : 4, i :   108] loss: 0.000\n",
            "[epoch : 4, i :   110] loss: 0.000\n",
            "[epoch : 4, i :   112] loss: 0.000\n",
            "[epoch : 4, i :   114] loss: 0.000\n",
            "[epoch : 4, i :   116] loss: 0.000\n",
            "[epoch : 4, i :   118] loss: 0.001\n",
            "[epoch : 4, i :   120] loss: 0.000\n",
            "[epoch : 4, i :   122] loss: 0.000\n",
            "[epoch : 4, i :   124] loss: 0.000\n",
            "[epoch : 4, i :   126] loss: 0.000\n",
            "[epoch : 4, i :   128] loss: 0.000\n",
            "[epoch : 4, i :   130] loss: 0.000\n",
            "[epoch : 4, i :   132] loss: 0.000\n",
            "[epoch : 4, i :   134] loss: 0.000\n",
            "[epoch : 4, i :   136] loss: 0.000\n",
            "[epoch : 4, i :   138] loss: 0.001\n",
            "[epoch : 4, i :   140] loss: 0.000\n",
            "[epoch : 4, i :   142] loss: 0.000\n",
            "[epoch : 4, i :   144] loss: 0.000\n",
            "[epoch : 4, i :   146] loss: 0.000\n",
            "[epoch : 4, i :   148] loss: 0.000\n",
            "[epoch : 4, i :   150] loss: 0.000\n",
            "[epoch : 4, i :   152] loss: 0.000\n",
            "[epoch : 4, i :   154] loss: 0.000\n",
            "[epoch : 4, i :   156] loss: 0.000\n",
            "[epoch : 4, i :   158] loss: 0.000\n",
            "[epoch : 4, i :   160] loss: 0.000\n",
            "[epoch : 4, i :   162] loss: 0.000\n",
            "[epoch : 4, i :   164] loss: 0.000\n",
            "[epoch : 4, i :   166] loss: 0.003\n",
            "[epoch : 4, i :   168] loss: 0.000\n",
            "[epoch : 4, i :   170] loss: 0.000\n",
            "[epoch : 4, i :   172] loss: 0.000\n",
            "[epoch : 4, i :   174] loss: 0.000\n",
            "[epoch : 4, i :   176] loss: 0.000\n",
            "[epoch : 4, i :   178] loss: 0.000\n",
            "[epoch : 4, i :   180] loss: 0.000\n",
            "[epoch : 4, i :   182] loss: 0.000\n",
            "[epoch : 4, i :   184] loss: 0.000\n",
            "[epoch : 4, i :   186] loss: 0.000\n",
            "[epoch : 4, i :   188] loss: 0.000\n",
            "[epoch : 4, i :   190] loss: 0.000\n",
            "[epoch : 4, i :   192] loss: 0.000\n",
            "[epoch : 4, i :   194] loss: 0.000\n",
            "[epoch : 4, i :   196] loss: 0.000\n",
            "[epoch : 4, i :   198] loss: 0.002\n",
            "[epoch : 4, i :   200] loss: 0.000\n",
            "[epoch : 4, i :   202] loss: 0.000\n",
            "[epoch : 4, i :   204] loss: 0.000\n",
            "[epoch : 4, i :   206] loss: 0.003\n",
            "[epoch : 4, i :   208] loss: 0.000\n",
            "[epoch : 4, i :   210] loss: 0.000\n",
            "[epoch : 4, i :   212] loss: 0.000\n",
            "[epoch : 4, i :   214] loss: 0.000\n",
            "[epoch : 4, i :   216] loss: 0.000\n",
            "[epoch : 4, i :   218] loss: 0.000\n",
            "[epoch : 4, i :   220] loss: 0.000\n",
            "[epoch : 4, i :   222] loss: 0.000\n",
            "[epoch : 4, i :   224] loss: 0.000\n",
            "[epoch : 4, i :   226] loss: 0.000\n",
            "[epoch : 4, i :   228] loss: 0.000\n",
            "[epoch : 4, i :   230] loss: 0.001\n",
            "[epoch : 4, i :   232] loss: 0.000\n",
            "[epoch : 4, i :   234] loss: 0.000\n",
            "[epoch : 4, i :   236] loss: 0.000\n",
            "[epoch : 4, i :   238] loss: 0.000\n",
            "[epoch : 4, i :   240] loss: 0.000\n",
            "[epoch : 4, i :   242] loss: 0.000\n",
            "[epoch : 4, i :   244] loss: 0.000\n",
            "[epoch : 4, i :   246] loss: 0.000\n",
            "[epoch : 4, i :   248] loss: 0.000\n",
            "[epoch : 4, i :   250] loss: 0.000\n",
            "[epoch : 4, i :   252] loss: 0.000\n",
            "[epoch : 4, i :   254] loss: 0.000\n",
            "[epoch : 4, i :   256] loss: 0.000\n",
            "[epoch : 4, i :   258] loss: 0.000\n",
            "[epoch : 4, i :   260] loss: 0.000\n",
            "[epoch : 4, i :   262] loss: 0.000\n",
            "[epoch : 4, i :   264] loss: 0.000\n",
            "[epoch : 4, i :   266] loss: 0.000\n",
            "[epoch : 4, i :   268] loss: 0.000\n",
            "[epoch : 4, i :   270] loss: 0.000\n",
            "[epoch : 4, i :   272] loss: 0.000\n",
            "[epoch : 4, i :   274] loss: 0.000\n",
            "[epoch : 4, i :   276] loss: 0.000\n",
            "[epoch : 4, i :   278] loss: 0.000\n",
            "[epoch : 4, i :   280] loss: 0.000\n",
            "[epoch : 4, i :   282] loss: 0.000\n",
            "[epoch : 4, i :   284] loss: 0.000\n",
            "[epoch : 4, i :   286] loss: 0.000\n",
            "[epoch : 4, i :   288] loss: 0.000\n",
            "[epoch : 4, i :   290] loss: 0.000\n",
            "[epoch : 4, i :   292] loss: 0.000\n",
            "[epoch : 4, i :   294] loss: 0.000\n",
            "[epoch : 4, i :   296] loss: 0.000\n",
            "[epoch : 4, i :   298] loss: 0.000\n",
            "[epoch : 4, i :   300] loss: 0.000\n",
            "[epoch : 4, i :   302] loss: 0.000\n",
            "[epoch : 4, i :   304] loss: 0.000\n",
            "[epoch : 4, i :   306] loss: 0.000\n",
            "[epoch : 4, i :   308] loss: 0.000\n",
            "[epoch : 4, i :   310] loss: 0.000\n",
            "[epoch : 4, i :   312] loss: 0.000\n",
            "[epoch : 4, i :   314] loss: 0.000\n",
            "[epoch : 4, i :   316] loss: 0.000\n",
            "[epoch : 4, i :   318] loss: 0.000\n",
            "[epoch : 4, i :   320] loss: 0.000\n",
            "[epoch : 4, i :   322] loss: 0.000\n",
            "[epoch : 4, i :   324] loss: 0.000\n",
            "[epoch : 4, i :   326] loss: 0.000\n",
            "[epoch : 4, i :   328] loss: 0.000\n",
            "[epoch : 4, i :   330] loss: 0.000\n",
            "[epoch : 4, i :   332] loss: 0.000\n",
            "[epoch : 4, i :   334] loss: 0.000\n",
            "[epoch : 4, i :   336] loss: 0.000\n",
            "[epoch : 4, i :   338] loss: 0.000\n",
            "[epoch : 4, i :   340] loss: 0.000\n",
            "[epoch : 4, i :   342] loss: 0.000\n",
            "[epoch : 4, i :   344] loss: 0.000\n",
            "[epoch : 4, i :   346] loss: 0.000\n",
            "[epoch : 4, i :   348] loss: 0.001\n",
            "[epoch : 4, i :   350] loss: 0.000\n",
            "[epoch : 4, i :   352] loss: 0.000\n",
            "[epoch : 4, i :   354] loss: 0.000\n",
            "[epoch : 4, i :   356] loss: 0.000\n",
            "[epoch : 4, i :   358] loss: 0.000\n",
            "[epoch : 4, i :   360] loss: 0.000\n",
            "[epoch : 4, i :   362] loss: 0.000\n",
            "[epoch : 4, i :   364] loss: 0.000\n",
            "[epoch : 4, i :   366] loss: 0.000\n",
            "[epoch : 4, i :   368] loss: 0.000\n",
            "[epoch : 4, i :   370] loss: 0.000\n",
            "[epoch : 4, i :   372] loss: 0.000\n",
            "[epoch : 5, i :     2] loss: 0.000\n",
            "[epoch : 5, i :     4] loss: 0.000\n",
            "[epoch : 5, i :     6] loss: 0.000\n",
            "[epoch : 5, i :     8] loss: 0.000\n",
            "[epoch : 5, i :    10] loss: 0.000\n",
            "[epoch : 5, i :    12] loss: 0.000\n",
            "[epoch : 5, i :    14] loss: 0.000\n",
            "[epoch : 5, i :    16] loss: 0.000\n",
            "[epoch : 5, i :    18] loss: 0.000\n",
            "[epoch : 5, i :    20] loss: 0.000\n",
            "[epoch : 5, i :    22] loss: 0.000\n",
            "[epoch : 5, i :    24] loss: 0.000\n",
            "[epoch : 5, i :    26] loss: 0.000\n",
            "[epoch : 5, i :    28] loss: 0.000\n",
            "[epoch : 5, i :    30] loss: 0.000\n",
            "[epoch : 5, i :    32] loss: 0.000\n",
            "[epoch : 5, i :    34] loss: 0.000\n",
            "[epoch : 5, i :    36] loss: 0.000\n",
            "[epoch : 5, i :    38] loss: 0.000\n",
            "[epoch : 5, i :    40] loss: 0.000\n",
            "[epoch : 5, i :    42] loss: 0.000\n",
            "[epoch : 5, i :    44] loss: 0.000\n",
            "[epoch : 5, i :    46] loss: 0.000\n",
            "[epoch : 5, i :    48] loss: 0.000\n",
            "[epoch : 5, i :    50] loss: 0.000\n",
            "[epoch : 5, i :    52] loss: 0.000\n",
            "[epoch : 5, i :    54] loss: 0.000\n",
            "[epoch : 5, i :    56] loss: 0.000\n",
            "[epoch : 5, i :    58] loss: 0.000\n",
            "[epoch : 5, i :    60] loss: 0.000\n",
            "[epoch : 5, i :    62] loss: 0.000\n",
            "[epoch : 5, i :    64] loss: 0.000\n",
            "[epoch : 5, i :    66] loss: 0.000\n",
            "[epoch : 5, i :    68] loss: 0.000\n",
            "[epoch : 5, i :    70] loss: 0.000\n",
            "[epoch : 5, i :    72] loss: 0.000\n",
            "[epoch : 5, i :    74] loss: 0.000\n",
            "[epoch : 5, i :    76] loss: 0.000\n",
            "[epoch : 5, i :    78] loss: 0.000\n",
            "[epoch : 5, i :    80] loss: 0.000\n",
            "[epoch : 5, i :    82] loss: 0.000\n",
            "[epoch : 5, i :    84] loss: 0.000\n",
            "[epoch : 5, i :    86] loss: 0.000\n",
            "[epoch : 5, i :    88] loss: 0.000\n",
            "[epoch : 5, i :    90] loss: 0.000\n",
            "[epoch : 5, i :    92] loss: 0.000\n",
            "[epoch : 5, i :    94] loss: 0.000\n",
            "[epoch : 5, i :    96] loss: 0.000\n",
            "[epoch : 5, i :    98] loss: 0.000\n",
            "[epoch : 5, i :   100] loss: 0.000\n",
            "[epoch : 5, i :   102] loss: 0.000\n",
            "[epoch : 5, i :   104] loss: 0.000\n",
            "[epoch : 5, i :   106] loss: 0.000\n",
            "[epoch : 5, i :   108] loss: 0.000\n",
            "[epoch : 5, i :   110] loss: 0.000\n",
            "[epoch : 5, i :   112] loss: 0.000\n",
            "[epoch : 5, i :   114] loss: 0.000\n",
            "[epoch : 5, i :   116] loss: 0.000\n",
            "[epoch : 5, i :   118] loss: 0.000\n",
            "[epoch : 5, i :   120] loss: 0.000\n",
            "[epoch : 5, i :   122] loss: 0.000\n",
            "[epoch : 5, i :   124] loss: 0.000\n",
            "[epoch : 5, i :   126] loss: 0.000\n",
            "[epoch : 5, i :   128] loss: 0.000\n",
            "[epoch : 5, i :   130] loss: 0.000\n",
            "[epoch : 5, i :   132] loss: 0.000\n",
            "[epoch : 5, i :   134] loss: 0.000\n",
            "[epoch : 5, i :   136] loss: 0.000\n",
            "[epoch : 5, i :   138] loss: 0.000\n",
            "[epoch : 5, i :   140] loss: 0.000\n",
            "[epoch : 5, i :   142] loss: 0.000\n",
            "[epoch : 5, i :   144] loss: 0.000\n",
            "[epoch : 5, i :   146] loss: 0.000\n",
            "[epoch : 5, i :   148] loss: 0.000\n",
            "[epoch : 5, i :   150] loss: 0.000\n",
            "[epoch : 5, i :   152] loss: 0.000\n",
            "[epoch : 5, i :   154] loss: 0.000\n",
            "[epoch : 5, i :   156] loss: 0.000\n",
            "[epoch : 5, i :   158] loss: 0.000\n",
            "[epoch : 5, i :   160] loss: 0.001\n",
            "[epoch : 5, i :   162] loss: 0.000\n",
            "[epoch : 5, i :   164] loss: 0.000\n",
            "[epoch : 5, i :   166] loss: 0.000\n",
            "[epoch : 5, i :   168] loss: 0.000\n",
            "[epoch : 5, i :   170] loss: 0.000\n",
            "[epoch : 5, i :   172] loss: 0.000\n",
            "[epoch : 5, i :   174] loss: 0.000\n",
            "[epoch : 5, i :   176] loss: 0.001\n",
            "[epoch : 5, i :   178] loss: 0.000\n",
            "[epoch : 5, i :   180] loss: 0.000\n",
            "[epoch : 5, i :   182] loss: 0.000\n",
            "[epoch : 5, i :   184] loss: 0.000\n",
            "[epoch : 5, i :   186] loss: 0.000\n",
            "[epoch : 5, i :   188] loss: 0.000\n",
            "[epoch : 5, i :   190] loss: 0.000\n",
            "[epoch : 5, i :   192] loss: 0.000\n",
            "[epoch : 5, i :   194] loss: 0.000\n",
            "[epoch : 5, i :   196] loss: 0.000\n",
            "[epoch : 5, i :   198] loss: 0.000\n",
            "[epoch : 5, i :   200] loss: 0.000\n",
            "[epoch : 5, i :   202] loss: 0.000\n",
            "[epoch : 5, i :   204] loss: 0.000\n",
            "[epoch : 5, i :   206] loss: 0.000\n",
            "[epoch : 5, i :   208] loss: 0.000\n",
            "[epoch : 5, i :   210] loss: 0.000\n",
            "[epoch : 5, i :   212] loss: 0.000\n",
            "[epoch : 5, i :   214] loss: 0.000\n",
            "[epoch : 5, i :   216] loss: 0.000\n",
            "[epoch : 5, i :   218] loss: 0.000\n",
            "[epoch : 5, i :   220] loss: 0.000\n",
            "[epoch : 5, i :   222] loss: 0.000\n",
            "[epoch : 5, i :   224] loss: 0.000\n",
            "[epoch : 5, i :   226] loss: 0.000\n",
            "[epoch : 5, i :   228] loss: 0.000\n",
            "[epoch : 5, i :   230] loss: 0.000\n",
            "[epoch : 5, i :   232] loss: 0.000\n",
            "[epoch : 5, i :   234] loss: 0.000\n",
            "[epoch : 5, i :   236] loss: 0.000\n",
            "[epoch : 5, i :   238] loss: 0.000\n",
            "[epoch : 5, i :   240] loss: 0.000\n",
            "[epoch : 5, i :   242] loss: 0.000\n",
            "[epoch : 5, i :   244] loss: 0.000\n",
            "[epoch : 5, i :   246] loss: 0.000\n",
            "[epoch : 5, i :   248] loss: 0.000\n",
            "[epoch : 5, i :   250] loss: 0.000\n",
            "[epoch : 5, i :   252] loss: 0.000\n",
            "[epoch : 5, i :   254] loss: 0.000\n",
            "[epoch : 5, i :   256] loss: 0.000\n",
            "[epoch : 5, i :   258] loss: 0.000\n",
            "[epoch : 5, i :   260] loss: 0.000\n",
            "[epoch : 5, i :   262] loss: 0.000\n",
            "[epoch : 5, i :   264] loss: 0.000\n",
            "[epoch : 5, i :   266] loss: 0.000\n",
            "[epoch : 5, i :   268] loss: 0.000\n",
            "[epoch : 5, i :   270] loss: 0.000\n",
            "[epoch : 5, i :   272] loss: 0.000\n",
            "[epoch : 5, i :   274] loss: 0.000\n",
            "[epoch : 5, i :   276] loss: 0.000\n",
            "[epoch : 5, i :   278] loss: 0.000\n",
            "[epoch : 5, i :   280] loss: 0.000\n",
            "[epoch : 5, i :   282] loss: 0.000\n",
            "[epoch : 5, i :   284] loss: 0.000\n",
            "[epoch : 5, i :   286] loss: 0.000\n",
            "[epoch : 5, i :   288] loss: 0.000\n",
            "[epoch : 5, i :   290] loss: 0.000\n",
            "[epoch : 5, i :   292] loss: 0.000\n",
            "[epoch : 5, i :   294] loss: 0.000\n",
            "[epoch : 5, i :   296] loss: 0.000\n",
            "[epoch : 5, i :   298] loss: 0.000\n",
            "[epoch : 5, i :   300] loss: 0.000\n",
            "[epoch : 5, i :   302] loss: 0.000\n",
            "[epoch : 5, i :   304] loss: 0.000\n",
            "[epoch : 5, i :   306] loss: 0.000\n",
            "[epoch : 5, i :   308] loss: 0.000\n",
            "[epoch : 5, i :   310] loss: 0.000\n",
            "[epoch : 5, i :   312] loss: 0.000\n",
            "[epoch : 5, i :   314] loss: 0.000\n",
            "[epoch : 5, i :   316] loss: 0.000\n",
            "[epoch : 5, i :   318] loss: 0.000\n",
            "[epoch : 5, i :   320] loss: 0.000\n",
            "[epoch : 5, i :   322] loss: 0.000\n",
            "[epoch : 5, i :   324] loss: 0.000\n",
            "[epoch : 5, i :   326] loss: 0.000\n",
            "[epoch : 5, i :   328] loss: 0.000\n",
            "[epoch : 5, i :   330] loss: 0.000\n",
            "[epoch : 5, i :   332] loss: 0.000\n",
            "[epoch : 5, i :   334] loss: 0.001\n",
            "[epoch : 5, i :   336] loss: 0.000\n",
            "[epoch : 5, i :   338] loss: 0.000\n",
            "[epoch : 5, i :   340] loss: 0.000\n",
            "[epoch : 5, i :   342] loss: 0.000\n",
            "[epoch : 5, i :   344] loss: 0.000\n",
            "[epoch : 5, i :   346] loss: 0.000\n",
            "[epoch : 5, i :   348] loss: 0.000\n",
            "[epoch : 5, i :   350] loss: 0.000\n",
            "[epoch : 5, i :   352] loss: 0.000\n",
            "[epoch : 5, i :   354] loss: 0.000\n",
            "[epoch : 5, i :   356] loss: 0.000\n",
            "[epoch : 5, i :   358] loss: 0.000\n",
            "[epoch : 5, i :   360] loss: 0.000\n",
            "[epoch : 5, i :   362] loss: 0.000\n",
            "[epoch : 5, i :   364] loss: 0.000\n",
            "[epoch : 5, i :   366] loss: 0.000\n",
            "[epoch : 5, i :   368] loss: 0.000\n",
            "[epoch : 5, i :   370] loss: 0.000\n",
            "[epoch : 5, i :   372] loss: 0.000\n",
            "[epoch : 6, i :     2] loss: 0.000\n",
            "[epoch : 6, i :     4] loss: 0.000\n",
            "[epoch : 6, i :     6] loss: 0.000\n",
            "[epoch : 6, i :     8] loss: 0.000\n",
            "[epoch : 6, i :    10] loss: 0.000\n",
            "[epoch : 6, i :    12] loss: 0.000\n",
            "[epoch : 6, i :    14] loss: 0.000\n",
            "[epoch : 6, i :    16] loss: 0.000\n",
            "[epoch : 6, i :    18] loss: 0.000\n",
            "[epoch : 6, i :    20] loss: 0.000\n",
            "[epoch : 6, i :    22] loss: 0.000\n",
            "[epoch : 6, i :    24] loss: 0.000\n",
            "[epoch : 6, i :    26] loss: 0.000\n",
            "[epoch : 6, i :    28] loss: 0.000\n",
            "[epoch : 6, i :    30] loss: 0.000\n",
            "[epoch : 6, i :    32] loss: 0.000\n",
            "[epoch : 6, i :    34] loss: 0.000\n",
            "[epoch : 6, i :    36] loss: 0.000\n",
            "[epoch : 6, i :    38] loss: 0.000\n",
            "[epoch : 6, i :    40] loss: 0.000\n",
            "[epoch : 6, i :    42] loss: 0.000\n",
            "[epoch : 6, i :    44] loss: 0.001\n",
            "[epoch : 6, i :    46] loss: 0.000\n",
            "[epoch : 6, i :    48] loss: 0.000\n",
            "[epoch : 6, i :    50] loss: 0.000\n",
            "[epoch : 6, i :    52] loss: 0.000\n",
            "[epoch : 6, i :    54] loss: 0.000\n",
            "[epoch : 6, i :    56] loss: 0.000\n",
            "[epoch : 6, i :    58] loss: 0.000\n",
            "[epoch : 6, i :    60] loss: 0.000\n",
            "[epoch : 6, i :    62] loss: 0.000\n",
            "[epoch : 6, i :    64] loss: 0.000\n",
            "[epoch : 6, i :    66] loss: 0.000\n",
            "[epoch : 6, i :    68] loss: 0.000\n",
            "[epoch : 6, i :    70] loss: 0.000\n",
            "[epoch : 6, i :    72] loss: 0.000\n",
            "[epoch : 6, i :    74] loss: 0.000\n",
            "[epoch : 6, i :    76] loss: 0.000\n",
            "[epoch : 6, i :    78] loss: 0.000\n",
            "[epoch : 6, i :    80] loss: 0.000\n",
            "[epoch : 6, i :    82] loss: 0.000\n",
            "[epoch : 6, i :    84] loss: 0.000\n",
            "[epoch : 6, i :    86] loss: 0.000\n",
            "[epoch : 6, i :    88] loss: 0.000\n",
            "[epoch : 6, i :    90] loss: 0.000\n",
            "[epoch : 6, i :    92] loss: 0.000\n",
            "[epoch : 6, i :    94] loss: 0.000\n",
            "[epoch : 6, i :    96] loss: 0.000\n",
            "[epoch : 6, i :    98] loss: 0.000\n",
            "[epoch : 6, i :   100] loss: 0.000\n",
            "[epoch : 6, i :   102] loss: 0.000\n",
            "[epoch : 6, i :   104] loss: 0.000\n",
            "[epoch : 6, i :   106] loss: 0.000\n",
            "[epoch : 6, i :   108] loss: 0.000\n",
            "[epoch : 6, i :   110] loss: 0.000\n",
            "[epoch : 6, i :   112] loss: 0.000\n",
            "[epoch : 6, i :   114] loss: 0.000\n",
            "[epoch : 6, i :   116] loss: 0.000\n",
            "[epoch : 6, i :   118] loss: 0.000\n",
            "[epoch : 6, i :   120] loss: 0.000\n",
            "[epoch : 6, i :   122] loss: 0.000\n",
            "[epoch : 6, i :   124] loss: 0.000\n",
            "[epoch : 6, i :   126] loss: 0.000\n",
            "[epoch : 6, i :   128] loss: 0.000\n",
            "[epoch : 6, i :   130] loss: 0.000\n",
            "[epoch : 6, i :   132] loss: 0.000\n",
            "[epoch : 6, i :   134] loss: 0.000\n",
            "[epoch : 6, i :   136] loss: 0.000\n",
            "[epoch : 6, i :   138] loss: 0.000\n",
            "[epoch : 6, i :   140] loss: 0.000\n",
            "[epoch : 6, i :   142] loss: 0.000\n",
            "[epoch : 6, i :   144] loss: 0.000\n",
            "[epoch : 6, i :   146] loss: 0.000\n",
            "[epoch : 6, i :   148] loss: 0.000\n",
            "[epoch : 6, i :   150] loss: 0.000\n",
            "[epoch : 6, i :   152] loss: 0.000\n",
            "[epoch : 6, i :   154] loss: 0.000\n",
            "[epoch : 6, i :   156] loss: 0.000\n",
            "[epoch : 6, i :   158] loss: 0.000\n",
            "[epoch : 6, i :   160] loss: 0.000\n",
            "[epoch : 6, i :   162] loss: 0.000\n",
            "[epoch : 6, i :   164] loss: 0.000\n",
            "[epoch : 6, i :   166] loss: 0.000\n",
            "[epoch : 6, i :   168] loss: 0.000\n",
            "[epoch : 6, i :   170] loss: 0.000\n",
            "[epoch : 6, i :   172] loss: 0.000\n",
            "[epoch : 6, i :   174] loss: 0.000\n",
            "[epoch : 6, i :   176] loss: 0.000\n",
            "[epoch : 6, i :   178] loss: 0.000\n",
            "[epoch : 6, i :   180] loss: 0.000\n",
            "[epoch : 6, i :   182] loss: 0.000\n",
            "[epoch : 6, i :   184] loss: 0.000\n",
            "[epoch : 6, i :   186] loss: 0.000\n",
            "[epoch : 6, i :   188] loss: 0.000\n",
            "[epoch : 6, i :   190] loss: 0.000\n",
            "[epoch : 6, i :   192] loss: 0.000\n",
            "[epoch : 6, i :   194] loss: 0.000\n",
            "[epoch : 6, i :   196] loss: 0.000\n",
            "[epoch : 6, i :   198] loss: 0.000\n",
            "[epoch : 6, i :   200] loss: 0.000\n",
            "[epoch : 6, i :   202] loss: 0.000\n",
            "[epoch : 6, i :   204] loss: 0.000\n",
            "[epoch : 6, i :   206] loss: 0.000\n",
            "[epoch : 6, i :   208] loss: 0.000\n",
            "[epoch : 6, i :   210] loss: 0.000\n",
            "[epoch : 6, i :   212] loss: 0.000\n",
            "[epoch : 6, i :   214] loss: 0.000\n",
            "[epoch : 6, i :   216] loss: 0.000\n",
            "[epoch : 6, i :   218] loss: 0.000\n",
            "[epoch : 6, i :   220] loss: 0.000\n",
            "[epoch : 6, i :   222] loss: 0.000\n",
            "[epoch : 6, i :   224] loss: 0.000\n",
            "[epoch : 6, i :   226] loss: 0.000\n",
            "[epoch : 6, i :   228] loss: 0.000\n",
            "[epoch : 6, i :   230] loss: 0.000\n",
            "[epoch : 6, i :   232] loss: 0.000\n",
            "[epoch : 6, i :   234] loss: 0.000\n",
            "[epoch : 6, i :   236] loss: 0.000\n",
            "[epoch : 6, i :   238] loss: 0.000\n",
            "[epoch : 6, i :   240] loss: 0.000\n",
            "[epoch : 6, i :   242] loss: 0.000\n",
            "[epoch : 6, i :   244] loss: 0.000\n",
            "[epoch : 6, i :   246] loss: 0.000\n",
            "[epoch : 6, i :   248] loss: 0.000\n",
            "[epoch : 6, i :   250] loss: 0.000\n",
            "[epoch : 6, i :   252] loss: 0.000\n",
            "[epoch : 6, i :   254] loss: 0.000\n",
            "[epoch : 6, i :   256] loss: 0.000\n",
            "[epoch : 6, i :   258] loss: 0.000\n",
            "[epoch : 6, i :   260] loss: 0.000\n",
            "[epoch : 6, i :   262] loss: 0.000\n",
            "[epoch : 6, i :   264] loss: 0.000\n",
            "[epoch : 6, i :   266] loss: 0.000\n",
            "[epoch : 6, i :   268] loss: 0.000\n",
            "[epoch : 6, i :   270] loss: 0.000\n",
            "[epoch : 6, i :   272] loss: 0.000\n",
            "[epoch : 6, i :   274] loss: 0.000\n",
            "[epoch : 6, i :   276] loss: 0.000\n",
            "[epoch : 6, i :   278] loss: 0.000\n",
            "[epoch : 6, i :   280] loss: 0.000\n",
            "[epoch : 6, i :   282] loss: 0.000\n",
            "[epoch : 6, i :   284] loss: 0.000\n",
            "[epoch : 6, i :   286] loss: 0.000\n",
            "[epoch : 6, i :   288] loss: 0.000\n",
            "[epoch : 6, i :   290] loss: 0.000\n",
            "[epoch : 6, i :   292] loss: 0.000\n",
            "[epoch : 6, i :   294] loss: 0.000\n",
            "[epoch : 6, i :   296] loss: 0.000\n",
            "[epoch : 6, i :   298] loss: 0.000\n",
            "[epoch : 6, i :   300] loss: 0.000\n",
            "[epoch : 6, i :   302] loss: 0.000\n",
            "[epoch : 6, i :   304] loss: 0.000\n",
            "[epoch : 6, i :   306] loss: 0.000\n",
            "[epoch : 6, i :   308] loss: 0.000\n",
            "[epoch : 6, i :   310] loss: 0.000\n",
            "[epoch : 6, i :   312] loss: 0.000\n",
            "[epoch : 6, i :   314] loss: 0.000\n",
            "[epoch : 6, i :   316] loss: 0.000\n",
            "[epoch : 6, i :   318] loss: 0.000\n",
            "[epoch : 6, i :   320] loss: 0.000\n",
            "[epoch : 6, i :   322] loss: 0.000\n",
            "[epoch : 6, i :   324] loss: 0.000\n",
            "[epoch : 6, i :   326] loss: 0.000\n",
            "[epoch : 6, i :   328] loss: 0.000\n",
            "[epoch : 6, i :   330] loss: 0.000\n",
            "[epoch : 6, i :   332] loss: 0.000\n",
            "[epoch : 6, i :   334] loss: 0.000\n",
            "[epoch : 6, i :   336] loss: 0.000\n",
            "[epoch : 6, i :   338] loss: 0.000\n",
            "[epoch : 6, i :   340] loss: 0.000\n",
            "[epoch : 6, i :   342] loss: 0.000\n",
            "[epoch : 6, i :   344] loss: 0.000\n",
            "[epoch : 6, i :   346] loss: 0.000\n",
            "[epoch : 6, i :   348] loss: 0.000\n",
            "[epoch : 6, i :   350] loss: 0.000\n",
            "[epoch : 6, i :   352] loss: 0.000\n",
            "[epoch : 6, i :   354] loss: 0.000\n",
            "[epoch : 6, i :   356] loss: 0.000\n",
            "[epoch : 6, i :   358] loss: 0.000\n",
            "[epoch : 6, i :   360] loss: 0.000\n",
            "[epoch : 6, i :   362] loss: 0.000\n",
            "[epoch : 6, i :   364] loss: 0.000\n",
            "[epoch : 6, i :   366] loss: 0.000\n",
            "[epoch : 6, i :   368] loss: 0.000\n",
            "[epoch : 6, i :   370] loss: 0.000\n",
            "[epoch : 6, i :   372] loss: 0.000\n",
            "[epoch : 7, i :     2] loss: 0.000\n",
            "[epoch : 7, i :     4] loss: 0.000\n",
            "[epoch : 7, i :     6] loss: 0.000\n",
            "[epoch : 7, i :     8] loss: 0.000\n",
            "[epoch : 7, i :    10] loss: 0.000\n",
            "[epoch : 7, i :    12] loss: 0.000\n",
            "[epoch : 7, i :    14] loss: 0.000\n",
            "[epoch : 7, i :    16] loss: 0.000\n",
            "[epoch : 7, i :    18] loss: 0.000\n",
            "[epoch : 7, i :    20] loss: 0.000\n",
            "[epoch : 7, i :    22] loss: 0.000\n",
            "[epoch : 7, i :    24] loss: 0.000\n",
            "[epoch : 7, i :    26] loss: 0.000\n",
            "[epoch : 7, i :    28] loss: 0.000\n",
            "[epoch : 7, i :    30] loss: 0.000\n",
            "[epoch : 7, i :    32] loss: 0.000\n",
            "[epoch : 7, i :    34] loss: 0.000\n",
            "[epoch : 7, i :    36] loss: 0.000\n",
            "[epoch : 7, i :    38] loss: 0.000\n",
            "[epoch : 7, i :    40] loss: 0.000\n",
            "[epoch : 7, i :    42] loss: 0.000\n",
            "[epoch : 7, i :    44] loss: 0.000\n",
            "[epoch : 7, i :    46] loss: 0.000\n",
            "[epoch : 7, i :    48] loss: 0.000\n",
            "[epoch : 7, i :    50] loss: 0.000\n",
            "[epoch : 7, i :    52] loss: 0.000\n",
            "[epoch : 7, i :    54] loss: 0.000\n",
            "[epoch : 7, i :    56] loss: 0.000\n",
            "[epoch : 7, i :    58] loss: 0.000\n",
            "[epoch : 7, i :    60] loss: 0.000\n",
            "[epoch : 7, i :    62] loss: 0.000\n",
            "[epoch : 7, i :    64] loss: 0.000\n",
            "[epoch : 7, i :    66] loss: 0.000\n",
            "[epoch : 7, i :    68] loss: 0.000\n",
            "[epoch : 7, i :    70] loss: 0.000\n",
            "[epoch : 7, i :    72] loss: 0.000\n",
            "[epoch : 7, i :    74] loss: 0.000\n",
            "[epoch : 7, i :    76] loss: 0.000\n",
            "[epoch : 7, i :    78] loss: 0.000\n",
            "[epoch : 7, i :    80] loss: 0.000\n",
            "[epoch : 7, i :    82] loss: 0.000\n",
            "[epoch : 7, i :    84] loss: 0.000\n",
            "[epoch : 7, i :    86] loss: 0.000\n",
            "[epoch : 7, i :    88] loss: 0.000\n",
            "[epoch : 7, i :    90] loss: 0.000\n",
            "[epoch : 7, i :    92] loss: 0.000\n",
            "[epoch : 7, i :    94] loss: 0.000\n",
            "[epoch : 7, i :    96] loss: 0.000\n",
            "[epoch : 7, i :    98] loss: 0.000\n",
            "[epoch : 7, i :   100] loss: 0.000\n",
            "[epoch : 7, i :   102] loss: 0.000\n",
            "[epoch : 7, i :   104] loss: 0.000\n",
            "[epoch : 7, i :   106] loss: 0.000\n",
            "[epoch : 7, i :   108] loss: 0.000\n",
            "[epoch : 7, i :   110] loss: 0.000\n",
            "[epoch : 7, i :   112] loss: 0.000\n",
            "[epoch : 7, i :   114] loss: 0.000\n",
            "[epoch : 7, i :   116] loss: 0.000\n",
            "[epoch : 7, i :   118] loss: 0.000\n",
            "[epoch : 7, i :   120] loss: 0.000\n",
            "[epoch : 7, i :   122] loss: 0.000\n",
            "[epoch : 7, i :   124] loss: 0.000\n",
            "[epoch : 7, i :   126] loss: 0.000\n",
            "[epoch : 7, i :   128] loss: 0.000\n",
            "[epoch : 7, i :   130] loss: 0.000\n",
            "[epoch : 7, i :   132] loss: 0.000\n",
            "[epoch : 7, i :   134] loss: 0.000\n",
            "[epoch : 7, i :   136] loss: 0.000\n",
            "[epoch : 7, i :   138] loss: 0.000\n",
            "[epoch : 7, i :   140] loss: 0.000\n",
            "[epoch : 7, i :   142] loss: 0.000\n",
            "[epoch : 7, i :   144] loss: 0.000\n",
            "[epoch : 7, i :   146] loss: 0.000\n",
            "[epoch : 7, i :   148] loss: 0.000\n",
            "[epoch : 7, i :   150] loss: 0.000\n",
            "[epoch : 7, i :   152] loss: 0.000\n",
            "[epoch : 7, i :   154] loss: 0.000\n",
            "[epoch : 7, i :   156] loss: 0.000\n",
            "[epoch : 7, i :   158] loss: 0.000\n",
            "[epoch : 7, i :   160] loss: 0.000\n",
            "[epoch : 7, i :   162] loss: 0.000\n",
            "[epoch : 7, i :   164] loss: 0.000\n",
            "[epoch : 7, i :   166] loss: 0.000\n",
            "[epoch : 7, i :   168] loss: 0.000\n",
            "[epoch : 7, i :   170] loss: 0.000\n",
            "[epoch : 7, i :   172] loss: 0.000\n",
            "[epoch : 7, i :   174] loss: 0.000\n",
            "[epoch : 7, i :   176] loss: 0.000\n",
            "[epoch : 7, i :   178] loss: 0.000\n",
            "[epoch : 7, i :   180] loss: 0.000\n",
            "[epoch : 7, i :   182] loss: 0.000\n",
            "[epoch : 7, i :   184] loss: 0.000\n",
            "[epoch : 7, i :   186] loss: 0.000\n",
            "[epoch : 7, i :   188] loss: 0.000\n",
            "[epoch : 7, i :   190] loss: 0.000\n",
            "[epoch : 7, i :   192] loss: 0.000\n",
            "[epoch : 7, i :   194] loss: 0.000\n",
            "[epoch : 7, i :   196] loss: 0.000\n",
            "[epoch : 7, i :   198] loss: 0.000\n",
            "[epoch : 7, i :   200] loss: 0.000\n",
            "[epoch : 7, i :   202] loss: 0.000\n",
            "[epoch : 7, i :   204] loss: 0.000\n",
            "[epoch : 7, i :   206] loss: 0.000\n",
            "[epoch : 7, i :   208] loss: 0.000\n",
            "[epoch : 7, i :   210] loss: 0.000\n",
            "[epoch : 7, i :   212] loss: 0.000\n",
            "[epoch : 7, i :   214] loss: 0.000\n",
            "[epoch : 7, i :   216] loss: 0.000\n",
            "[epoch : 7, i :   218] loss: 0.000\n",
            "[epoch : 7, i :   220] loss: 0.000\n",
            "[epoch : 7, i :   222] loss: 0.000\n",
            "[epoch : 7, i :   224] loss: 0.000\n",
            "[epoch : 7, i :   226] loss: 0.000\n",
            "[epoch : 7, i :   228] loss: 0.000\n",
            "[epoch : 7, i :   230] loss: 0.000\n",
            "[epoch : 7, i :   232] loss: 0.000\n",
            "[epoch : 7, i :   234] loss: 0.000\n",
            "[epoch : 7, i :   236] loss: 0.000\n",
            "[epoch : 7, i :   238] loss: 0.000\n",
            "[epoch : 7, i :   240] loss: 0.000\n",
            "[epoch : 7, i :   242] loss: 0.000\n",
            "[epoch : 7, i :   244] loss: 0.000\n",
            "[epoch : 7, i :   246] loss: 0.000\n",
            "[epoch : 7, i :   248] loss: 0.000\n",
            "[epoch : 7, i :   250] loss: 0.000\n",
            "[epoch : 7, i :   252] loss: 0.000\n",
            "[epoch : 7, i :   254] loss: 0.000\n",
            "[epoch : 7, i :   256] loss: 0.000\n",
            "[epoch : 7, i :   258] loss: 0.000\n",
            "[epoch : 7, i :   260] loss: 0.000\n",
            "[epoch : 7, i :   262] loss: 0.000\n",
            "[epoch : 7, i :   264] loss: 0.000\n",
            "[epoch : 7, i :   266] loss: 0.000\n",
            "[epoch : 7, i :   268] loss: 0.000\n",
            "[epoch : 7, i :   270] loss: 0.000\n",
            "[epoch : 7, i :   272] loss: 0.000\n",
            "[epoch : 7, i :   274] loss: 0.000\n",
            "[epoch : 7, i :   276] loss: 0.000\n",
            "[epoch : 7, i :   278] loss: 0.000\n",
            "[epoch : 7, i :   280] loss: 0.000\n",
            "[epoch : 7, i :   282] loss: 0.000\n",
            "[epoch : 7, i :   284] loss: 0.000\n",
            "[epoch : 7, i :   286] loss: 0.000\n",
            "[epoch : 7, i :   288] loss: 0.000\n",
            "[epoch : 7, i :   290] loss: 0.000\n",
            "[epoch : 7, i :   292] loss: 0.000\n",
            "[epoch : 7, i :   294] loss: 0.000\n",
            "[epoch : 7, i :   296] loss: 0.000\n",
            "[epoch : 7, i :   298] loss: 0.000\n",
            "[epoch : 7, i :   300] loss: 0.000\n",
            "[epoch : 7, i :   302] loss: 0.000\n",
            "[epoch : 7, i :   304] loss: 0.000\n",
            "[epoch : 7, i :   306] loss: 0.000\n",
            "[epoch : 7, i :   308] loss: 0.000\n",
            "[epoch : 7, i :   310] loss: 0.000\n",
            "[epoch : 7, i :   312] loss: 0.000\n",
            "[epoch : 7, i :   314] loss: 0.000\n",
            "[epoch : 7, i :   316] loss: 0.000\n",
            "[epoch : 7, i :   318] loss: 0.000\n",
            "[epoch : 7, i :   320] loss: 0.000\n",
            "[epoch : 7, i :   322] loss: 0.000\n",
            "[epoch : 7, i :   324] loss: 0.000\n",
            "[epoch : 7, i :   326] loss: 0.000\n",
            "[epoch : 7, i :   328] loss: 0.000\n",
            "[epoch : 7, i :   330] loss: 0.000\n",
            "[epoch : 7, i :   332] loss: 0.000\n",
            "[epoch : 7, i :   334] loss: 0.000\n",
            "[epoch : 7, i :   336] loss: 0.000\n",
            "[epoch : 7, i :   338] loss: 0.000\n",
            "[epoch : 7, i :   340] loss: 0.000\n",
            "[epoch : 7, i :   342] loss: 0.000\n",
            "[epoch : 7, i :   344] loss: 0.000\n",
            "[epoch : 7, i :   346] loss: 0.000\n",
            "[epoch : 7, i :   348] loss: 0.000\n",
            "[epoch : 7, i :   350] loss: 0.000\n",
            "[epoch : 7, i :   352] loss: 0.000\n",
            "[epoch : 7, i :   354] loss: 0.000\n",
            "[epoch : 7, i :   356] loss: 0.000\n",
            "[epoch : 7, i :   358] loss: 0.000\n",
            "[epoch : 7, i :   360] loss: 0.000\n",
            "[epoch : 7, i :   362] loss: 0.000\n",
            "[epoch : 7, i :   364] loss: 0.000\n",
            "[epoch : 7, i :   366] loss: 0.000\n",
            "[epoch : 7, i :   368] loss: 0.000\n",
            "[epoch : 7, i :   370] loss: 0.000\n",
            "[epoch : 7, i :   372] loss: 0.000\n",
            "[epoch : 8, i :     2] loss: 0.000\n",
            "[epoch : 8, i :     4] loss: 0.000\n",
            "[epoch : 8, i :     6] loss: 0.000\n",
            "[epoch : 8, i :     8] loss: 0.000\n",
            "[epoch : 8, i :    10] loss: 0.000\n",
            "[epoch : 8, i :    12] loss: 0.000\n",
            "[epoch : 8, i :    14] loss: 0.000\n",
            "[epoch : 8, i :    16] loss: 0.000\n",
            "[epoch : 8, i :    18] loss: 0.000\n",
            "[epoch : 8, i :    20] loss: 0.000\n",
            "[epoch : 8, i :    22] loss: 0.000\n",
            "[epoch : 8, i :    24] loss: 0.000\n",
            "[epoch : 8, i :    26] loss: 0.000\n",
            "[epoch : 8, i :    28] loss: 0.000\n",
            "[epoch : 8, i :    30] loss: 0.000\n",
            "[epoch : 8, i :    32] loss: 0.000\n",
            "[epoch : 8, i :    34] loss: 0.000\n",
            "[epoch : 8, i :    36] loss: 0.000\n",
            "[epoch : 8, i :    38] loss: 0.000\n",
            "[epoch : 8, i :    40] loss: 0.000\n",
            "[epoch : 8, i :    42] loss: 0.000\n",
            "[epoch : 8, i :    44] loss: 0.000\n",
            "[epoch : 8, i :    46] loss: 0.000\n",
            "[epoch : 8, i :    48] loss: 0.000\n",
            "[epoch : 8, i :    50] loss: 0.000\n",
            "[epoch : 8, i :    52] loss: 0.000\n",
            "[epoch : 8, i :    54] loss: 0.000\n",
            "[epoch : 8, i :    56] loss: 0.000\n",
            "[epoch : 8, i :    58] loss: 0.000\n",
            "[epoch : 8, i :    60] loss: 0.000\n",
            "[epoch : 8, i :    62] loss: 0.000\n",
            "[epoch : 8, i :    64] loss: 0.000\n",
            "[epoch : 8, i :    66] loss: 0.000\n",
            "[epoch : 8, i :    68] loss: 0.000\n",
            "[epoch : 8, i :    70] loss: 0.000\n",
            "[epoch : 8, i :    72] loss: 0.000\n",
            "[epoch : 8, i :    74] loss: 0.000\n",
            "[epoch : 8, i :    76] loss: 0.000\n",
            "[epoch : 8, i :    78] loss: 0.000\n",
            "[epoch : 8, i :    80] loss: 0.000\n",
            "[epoch : 8, i :    82] loss: 0.000\n",
            "[epoch : 8, i :    84] loss: 0.000\n",
            "[epoch : 8, i :    86] loss: 0.000\n",
            "[epoch : 8, i :    88] loss: 0.000\n",
            "[epoch : 8, i :    90] loss: 0.000\n",
            "[epoch : 8, i :    92] loss: 0.000\n",
            "[epoch : 8, i :    94] loss: 0.000\n",
            "[epoch : 8, i :    96] loss: 0.000\n",
            "[epoch : 8, i :    98] loss: 0.000\n",
            "[epoch : 8, i :   100] loss: 0.000\n",
            "[epoch : 8, i :   102] loss: 0.000\n",
            "[epoch : 8, i :   104] loss: 0.000\n",
            "[epoch : 8, i :   106] loss: 0.000\n",
            "[epoch : 8, i :   108] loss: 0.000\n",
            "[epoch : 8, i :   110] loss: 0.000\n",
            "[epoch : 8, i :   112] loss: 0.000\n",
            "[epoch : 8, i :   114] loss: 0.000\n",
            "[epoch : 8, i :   116] loss: 0.000\n",
            "[epoch : 8, i :   118] loss: 0.000\n",
            "[epoch : 8, i :   120] loss: 0.000\n",
            "[epoch : 8, i :   122] loss: 0.000\n",
            "[epoch : 8, i :   124] loss: 0.000\n",
            "[epoch : 8, i :   126] loss: 0.000\n",
            "[epoch : 8, i :   128] loss: 0.000\n",
            "[epoch : 8, i :   130] loss: 0.000\n",
            "[epoch : 8, i :   132] loss: 0.000\n",
            "[epoch : 8, i :   134] loss: 0.000\n",
            "[epoch : 8, i :   136] loss: 0.000\n",
            "[epoch : 8, i :   138] loss: 0.000\n",
            "[epoch : 8, i :   140] loss: 0.000\n",
            "[epoch : 8, i :   142] loss: 0.000\n",
            "[epoch : 8, i :   144] loss: 0.000\n",
            "[epoch : 8, i :   146] loss: 0.000\n",
            "[epoch : 8, i :   148] loss: 0.000\n",
            "[epoch : 8, i :   150] loss: 0.000\n",
            "[epoch : 8, i :   152] loss: 0.000\n",
            "[epoch : 8, i :   154] loss: 0.000\n",
            "[epoch : 8, i :   156] loss: 0.000\n",
            "[epoch : 8, i :   158] loss: 0.000\n",
            "[epoch : 8, i :   160] loss: 0.000\n",
            "[epoch : 8, i :   162] loss: 0.000\n",
            "[epoch : 8, i :   164] loss: 0.000\n",
            "[epoch : 8, i :   166] loss: 0.000\n",
            "[epoch : 8, i :   168] loss: 0.000\n",
            "[epoch : 8, i :   170] loss: 0.000\n",
            "[epoch : 8, i :   172] loss: 0.000\n",
            "[epoch : 8, i :   174] loss: 0.000\n",
            "[epoch : 8, i :   176] loss: 0.000\n",
            "[epoch : 8, i :   178] loss: 0.000\n",
            "[epoch : 8, i :   180] loss: 0.000\n",
            "[epoch : 8, i :   182] loss: 0.000\n",
            "[epoch : 8, i :   184] loss: 0.000\n",
            "[epoch : 8, i :   186] loss: 0.000\n",
            "[epoch : 8, i :   188] loss: 0.000\n",
            "[epoch : 8, i :   190] loss: 0.000\n",
            "[epoch : 8, i :   192] loss: 0.000\n",
            "[epoch : 8, i :   194] loss: 0.000\n",
            "[epoch : 8, i :   196] loss: 0.000\n",
            "[epoch : 8, i :   198] loss: 0.000\n",
            "[epoch : 8, i :   200] loss: 0.000\n",
            "[epoch : 8, i :   202] loss: 0.000\n",
            "[epoch : 8, i :   204] loss: 0.000\n",
            "[epoch : 8, i :   206] loss: 0.000\n",
            "[epoch : 8, i :   208] loss: 0.000\n",
            "[epoch : 8, i :   210] loss: 0.000\n",
            "[epoch : 8, i :   212] loss: 0.000\n",
            "[epoch : 8, i :   214] loss: 0.000\n",
            "[epoch : 8, i :   216] loss: 0.000\n",
            "[epoch : 8, i :   218] loss: 0.000\n",
            "[epoch : 8, i :   220] loss: 0.000\n",
            "[epoch : 8, i :   222] loss: 0.000\n",
            "[epoch : 8, i :   224] loss: 0.000\n",
            "[epoch : 8, i :   226] loss: 0.000\n",
            "[epoch : 8, i :   228] loss: 0.000\n",
            "[epoch : 8, i :   230] loss: 0.000\n",
            "[epoch : 8, i :   232] loss: 0.000\n",
            "[epoch : 8, i :   234] loss: 0.000\n",
            "[epoch : 8, i :   236] loss: 0.000\n",
            "[epoch : 8, i :   238] loss: 0.000\n",
            "[epoch : 8, i :   240] loss: 0.000\n",
            "[epoch : 8, i :   242] loss: 0.000\n",
            "[epoch : 8, i :   244] loss: 0.000\n",
            "[epoch : 8, i :   246] loss: 0.000\n",
            "[epoch : 8, i :   248] loss: 0.000\n",
            "[epoch : 8, i :   250] loss: 0.000\n",
            "[epoch : 8, i :   252] loss: 0.000\n",
            "[epoch : 8, i :   254] loss: 0.000\n",
            "[epoch : 8, i :   256] loss: 0.000\n",
            "[epoch : 8, i :   258] loss: 0.000\n",
            "[epoch : 8, i :   260] loss: 0.000\n",
            "[epoch : 8, i :   262] loss: 0.000\n",
            "[epoch : 8, i :   264] loss: 0.000\n",
            "[epoch : 8, i :   266] loss: 0.000\n",
            "[epoch : 8, i :   268] loss: 0.000\n",
            "[epoch : 8, i :   270] loss: 0.000\n",
            "[epoch : 8, i :   272] loss: 0.000\n",
            "[epoch : 8, i :   274] loss: 0.000\n",
            "[epoch : 8, i :   276] loss: 0.000\n",
            "[epoch : 8, i :   278] loss: 0.000\n",
            "[epoch : 8, i :   280] loss: 0.000\n",
            "[epoch : 8, i :   282] loss: 0.000\n",
            "[epoch : 8, i :   284] loss: 0.000\n",
            "[epoch : 8, i :   286] loss: 0.000\n",
            "[epoch : 8, i :   288] loss: 0.000\n",
            "[epoch : 8, i :   290] loss: 0.000\n",
            "[epoch : 8, i :   292] loss: 0.000\n",
            "[epoch : 8, i :   294] loss: 0.000\n",
            "[epoch : 8, i :   296] loss: 0.000\n",
            "[epoch : 8, i :   298] loss: 0.000\n",
            "[epoch : 8, i :   300] loss: 0.000\n",
            "[epoch : 8, i :   302] loss: 0.000\n",
            "[epoch : 8, i :   304] loss: 0.000\n",
            "[epoch : 8, i :   306] loss: 0.000\n",
            "[epoch : 8, i :   308] loss: 0.000\n",
            "[epoch : 8, i :   310] loss: 0.000\n",
            "[epoch : 8, i :   312] loss: 0.000\n",
            "[epoch : 8, i :   314] loss: 0.000\n",
            "[epoch : 8, i :   316] loss: 0.000\n",
            "[epoch : 8, i :   318] loss: 0.000\n",
            "[epoch : 8, i :   320] loss: 0.000\n",
            "[epoch : 8, i :   322] loss: 0.000\n",
            "[epoch : 8, i :   324] loss: 0.000\n",
            "[epoch : 8, i :   326] loss: 0.000\n",
            "[epoch : 8, i :   328] loss: 0.000\n",
            "[epoch : 8, i :   330] loss: 0.000\n",
            "[epoch : 8, i :   332] loss: 0.000\n",
            "[epoch : 8, i :   334] loss: 0.000\n",
            "[epoch : 8, i :   336] loss: 0.000\n",
            "[epoch : 8, i :   338] loss: 0.000\n",
            "[epoch : 8, i :   340] loss: 0.000\n",
            "[epoch : 8, i :   342] loss: 0.000\n",
            "[epoch : 8, i :   344] loss: 0.000\n",
            "[epoch : 8, i :   346] loss: 0.000\n",
            "[epoch : 8, i :   348] loss: 0.000\n",
            "[epoch : 8, i :   350] loss: 0.000\n",
            "[epoch : 8, i :   352] loss: 0.000\n",
            "[epoch : 8, i :   354] loss: 0.000\n",
            "[epoch : 8, i :   356] loss: 0.000\n",
            "[epoch : 8, i :   358] loss: 0.000\n",
            "[epoch : 8, i :   360] loss: 0.000\n",
            "[epoch : 8, i :   362] loss: 0.000\n",
            "[epoch : 8, i :   364] loss: 0.000\n",
            "[epoch : 8, i :   366] loss: 0.000\n",
            "[epoch : 8, i :   368] loss: 0.000\n",
            "[epoch : 8, i :   370] loss: 0.000\n",
            "[epoch : 8, i :   372] loss: 0.000\n",
            "[epoch : 9, i :     2] loss: 0.000\n",
            "[epoch : 9, i :     4] loss: 0.000\n",
            "[epoch : 9, i :     6] loss: 0.000\n",
            "[epoch : 9, i :     8] loss: 0.000\n",
            "[epoch : 9, i :    10] loss: 0.000\n",
            "[epoch : 9, i :    12] loss: 0.000\n",
            "[epoch : 9, i :    14] loss: 0.000\n",
            "[epoch : 9, i :    16] loss: 0.000\n",
            "[epoch : 9, i :    18] loss: 0.000\n",
            "[epoch : 9, i :    20] loss: 0.000\n",
            "[epoch : 9, i :    22] loss: 0.000\n",
            "[epoch : 9, i :    24] loss: 0.000\n",
            "[epoch : 9, i :    26] loss: 0.000\n",
            "[epoch : 9, i :    28] loss: 0.000\n",
            "[epoch : 9, i :    30] loss: 0.000\n",
            "[epoch : 9, i :    32] loss: 0.000\n",
            "[epoch : 9, i :    34] loss: 0.000\n",
            "[epoch : 9, i :    36] loss: 0.000\n",
            "[epoch : 9, i :    38] loss: 0.000\n",
            "[epoch : 9, i :    40] loss: 0.000\n",
            "[epoch : 9, i :    42] loss: 0.000\n",
            "[epoch : 9, i :    44] loss: 0.000\n",
            "[epoch : 9, i :    46] loss: 0.000\n",
            "[epoch : 9, i :    48] loss: 0.000\n",
            "[epoch : 9, i :    50] loss: 0.000\n",
            "[epoch : 9, i :    52] loss: 0.000\n",
            "[epoch : 9, i :    54] loss: 0.000\n",
            "[epoch : 9, i :    56] loss: 0.000\n",
            "[epoch : 9, i :    58] loss: 0.000\n",
            "[epoch : 9, i :    60] loss: 0.000\n",
            "[epoch : 9, i :    62] loss: 0.000\n",
            "[epoch : 9, i :    64] loss: 0.000\n",
            "[epoch : 9, i :    66] loss: 0.000\n",
            "[epoch : 9, i :    68] loss: 0.000\n",
            "[epoch : 9, i :    70] loss: 0.000\n",
            "[epoch : 9, i :    72] loss: 0.000\n",
            "[epoch : 9, i :    74] loss: 0.000\n",
            "[epoch : 9, i :    76] loss: 0.000\n",
            "[epoch : 9, i :    78] loss: 0.000\n",
            "[epoch : 9, i :    80] loss: 0.000\n",
            "[epoch : 9, i :    82] loss: 0.000\n",
            "[epoch : 9, i :    84] loss: 0.000\n",
            "[epoch : 9, i :    86] loss: 0.000\n",
            "[epoch : 9, i :    88] loss: 0.000\n",
            "[epoch : 9, i :    90] loss: 0.000\n",
            "[epoch : 9, i :    92] loss: 0.000\n",
            "[epoch : 9, i :    94] loss: 0.000\n",
            "[epoch : 9, i :    96] loss: 0.000\n",
            "[epoch : 9, i :    98] loss: 0.000\n",
            "[epoch : 9, i :   100] loss: 0.000\n",
            "[epoch : 9, i :   102] loss: 0.000\n",
            "[epoch : 9, i :   104] loss: 0.000\n",
            "[epoch : 9, i :   106] loss: 0.000\n",
            "[epoch : 9, i :   108] loss: 0.000\n",
            "[epoch : 9, i :   110] loss: 0.000\n",
            "[epoch : 9, i :   112] loss: 0.000\n",
            "[epoch : 9, i :   114] loss: 0.000\n",
            "[epoch : 9, i :   116] loss: 0.000\n",
            "[epoch : 9, i :   118] loss: 0.000\n",
            "[epoch : 9, i :   120] loss: 0.000\n",
            "[epoch : 9, i :   122] loss: 0.000\n",
            "[epoch : 9, i :   124] loss: 0.000\n",
            "[epoch : 9, i :   126] loss: 0.000\n",
            "[epoch : 9, i :   128] loss: 0.000\n",
            "[epoch : 9, i :   130] loss: 0.000\n",
            "[epoch : 9, i :   132] loss: 0.000\n",
            "[epoch : 9, i :   134] loss: 0.000\n",
            "[epoch : 9, i :   136] loss: 0.000\n",
            "[epoch : 9, i :   138] loss: 0.000\n",
            "[epoch : 9, i :   140] loss: 0.000\n",
            "[epoch : 9, i :   142] loss: 0.000\n",
            "[epoch : 9, i :   144] loss: 0.000\n",
            "[epoch : 9, i :   146] loss: 0.000\n",
            "[epoch : 9, i :   148] loss: 0.000\n",
            "[epoch : 9, i :   150] loss: 0.000\n",
            "[epoch : 9, i :   152] loss: 0.000\n",
            "[epoch : 9, i :   154] loss: 0.000\n",
            "[epoch : 9, i :   156] loss: 0.000\n",
            "[epoch : 9, i :   158] loss: 0.000\n",
            "[epoch : 9, i :   160] loss: 0.000\n",
            "[epoch : 9, i :   162] loss: 0.000\n",
            "[epoch : 9, i :   164] loss: 0.000\n",
            "[epoch : 9, i :   166] loss: 0.000\n",
            "[epoch : 9, i :   168] loss: 0.000\n",
            "[epoch : 9, i :   170] loss: 0.000\n",
            "[epoch : 9, i :   172] loss: 0.000\n",
            "[epoch : 9, i :   174] loss: 0.000\n",
            "[epoch : 9, i :   176] loss: 0.000\n",
            "[epoch : 9, i :   178] loss: 0.000\n",
            "[epoch : 9, i :   180] loss: 0.000\n",
            "[epoch : 9, i :   182] loss: 0.000\n",
            "[epoch : 9, i :   184] loss: 0.000\n",
            "[epoch : 9, i :   186] loss: 0.000\n",
            "[epoch : 9, i :   188] loss: 0.000\n",
            "[epoch : 9, i :   190] loss: 0.000\n",
            "[epoch : 9, i :   192] loss: 0.000\n",
            "[epoch : 9, i :   194] loss: 0.000\n",
            "[epoch : 9, i :   196] loss: 0.000\n",
            "[epoch : 9, i :   198] loss: 0.000\n",
            "[epoch : 9, i :   200] loss: 0.000\n",
            "[epoch : 9, i :   202] loss: 0.000\n",
            "[epoch : 9, i :   204] loss: 0.000\n",
            "[epoch : 9, i :   206] loss: 0.000\n",
            "[epoch : 9, i :   208] loss: 0.000\n",
            "[epoch : 9, i :   210] loss: 0.000\n",
            "[epoch : 9, i :   212] loss: 0.000\n",
            "[epoch : 9, i :   214] loss: 0.000\n",
            "[epoch : 9, i :   216] loss: 0.000\n",
            "[epoch : 9, i :   218] loss: 0.000\n",
            "[epoch : 9, i :   220] loss: 0.000\n",
            "[epoch : 9, i :   222] loss: 0.000\n",
            "[epoch : 9, i :   224] loss: 0.000\n",
            "[epoch : 9, i :   226] loss: 0.000\n",
            "[epoch : 9, i :   228] loss: 0.000\n",
            "[epoch : 9, i :   230] loss: 0.000\n",
            "[epoch : 9, i :   232] loss: 0.000\n",
            "[epoch : 9, i :   234] loss: 0.000\n",
            "[epoch : 9, i :   236] loss: 0.000\n",
            "[epoch : 9, i :   238] loss: 0.000\n",
            "[epoch : 9, i :   240] loss: 0.000\n",
            "[epoch : 9, i :   242] loss: 0.000\n",
            "[epoch : 9, i :   244] loss: 0.000\n",
            "[epoch : 9, i :   246] loss: 0.000\n",
            "[epoch : 9, i :   248] loss: 0.000\n",
            "[epoch : 9, i :   250] loss: 0.000\n",
            "[epoch : 9, i :   252] loss: 0.000\n",
            "[epoch : 9, i :   254] loss: 0.000\n",
            "[epoch : 9, i :   256] loss: 0.000\n",
            "[epoch : 9, i :   258] loss: 0.000\n",
            "[epoch : 9, i :   260] loss: 0.000\n",
            "[epoch : 9, i :   262] loss: 0.000\n",
            "[epoch : 9, i :   264] loss: 0.000\n",
            "[epoch : 9, i :   266] loss: 0.000\n",
            "[epoch : 9, i :   268] loss: 0.000\n",
            "[epoch : 9, i :   270] loss: 0.000\n",
            "[epoch : 9, i :   272] loss: 0.000\n",
            "[epoch : 9, i :   274] loss: 0.000\n",
            "[epoch : 9, i :   276] loss: 0.000\n",
            "[epoch : 9, i :   278] loss: 0.000\n",
            "[epoch : 9, i :   280] loss: 0.000\n",
            "[epoch : 9, i :   282] loss: 0.000\n",
            "[epoch : 9, i :   284] loss: 0.000\n",
            "[epoch : 9, i :   286] loss: 0.000\n",
            "[epoch : 9, i :   288] loss: 0.000\n",
            "[epoch : 9, i :   290] loss: 0.000\n",
            "[epoch : 9, i :   292] loss: 0.000\n",
            "[epoch : 9, i :   294] loss: 0.000\n",
            "[epoch : 9, i :   296] loss: 0.000\n",
            "[epoch : 9, i :   298] loss: 0.000\n",
            "[epoch : 9, i :   300] loss: 0.000\n",
            "[epoch : 9, i :   302] loss: 0.000\n",
            "[epoch : 9, i :   304] loss: 0.000\n",
            "[epoch : 9, i :   306] loss: 0.000\n",
            "[epoch : 9, i :   308] loss: 0.000\n",
            "[epoch : 9, i :   310] loss: 0.000\n",
            "[epoch : 9, i :   312] loss: 0.000\n",
            "[epoch : 9, i :   314] loss: 0.000\n",
            "[epoch : 9, i :   316] loss: 0.000\n",
            "[epoch : 9, i :   318] loss: 0.000\n",
            "[epoch : 9, i :   320] loss: 0.000\n",
            "[epoch : 9, i :   322] loss: 0.000\n",
            "[epoch : 9, i :   324] loss: 0.000\n",
            "[epoch : 9, i :   326] loss: 0.000\n",
            "[epoch : 9, i :   328] loss: 0.000\n",
            "[epoch : 9, i :   330] loss: 0.000\n",
            "[epoch : 9, i :   332] loss: 0.000\n",
            "[epoch : 9, i :   334] loss: 0.000\n",
            "[epoch : 9, i :   336] loss: 0.000\n",
            "[epoch : 9, i :   338] loss: 0.000\n",
            "[epoch : 9, i :   340] loss: 0.000\n",
            "[epoch : 9, i :   342] loss: 0.000\n",
            "[epoch : 9, i :   344] loss: 0.000\n",
            "[epoch : 9, i :   346] loss: 0.000\n",
            "[epoch : 9, i :   348] loss: 0.000\n",
            "[epoch : 9, i :   350] loss: 0.000\n",
            "[epoch : 9, i :   352] loss: 0.000\n",
            "[epoch : 9, i :   354] loss: 0.000\n",
            "[epoch : 9, i :   356] loss: 0.000\n",
            "[epoch : 9, i :   358] loss: 0.000\n",
            "[epoch : 9, i :   360] loss: 0.000\n",
            "[epoch : 9, i :   362] loss: 0.000\n",
            "[epoch : 9, i :   364] loss: 0.000\n",
            "[epoch : 9, i :   366] loss: 0.000\n",
            "[epoch : 9, i :   368] loss: 0.000\n",
            "[epoch : 9, i :   370] loss: 0.000\n",
            "[epoch : 9, i :   372] loss: 0.000\n",
            "[epoch : 10, i :     2] loss: 0.000\n",
            "[epoch : 10, i :     4] loss: 0.000\n",
            "[epoch : 10, i :     6] loss: 0.000\n",
            "[epoch : 10, i :     8] loss: 0.000\n",
            "[epoch : 10, i :    10] loss: 0.000\n",
            "[epoch : 10, i :    12] loss: 0.000\n",
            "[epoch : 10, i :    14] loss: 0.000\n",
            "[epoch : 10, i :    16] loss: 0.000\n",
            "[epoch : 10, i :    18] loss: 0.000\n",
            "[epoch : 10, i :    20] loss: 0.000\n",
            "[epoch : 10, i :    22] loss: 0.000\n",
            "[epoch : 10, i :    24] loss: 0.000\n",
            "[epoch : 10, i :    26] loss: 0.000\n",
            "[epoch : 10, i :    28] loss: 0.000\n",
            "[epoch : 10, i :    30] loss: 0.000\n",
            "[epoch : 10, i :    32] loss: 0.000\n",
            "[epoch : 10, i :    34] loss: 0.000\n",
            "[epoch : 10, i :    36] loss: 0.000\n",
            "[epoch : 10, i :    38] loss: 0.000\n",
            "[epoch : 10, i :    40] loss: 0.000\n",
            "[epoch : 10, i :    42] loss: 0.000\n",
            "[epoch : 10, i :    44] loss: 0.000\n",
            "[epoch : 10, i :    46] loss: 0.000\n",
            "[epoch : 10, i :    48] loss: 0.000\n",
            "[epoch : 10, i :    50] loss: 0.000\n",
            "[epoch : 10, i :    52] loss: 0.000\n",
            "[epoch : 10, i :    54] loss: 0.000\n",
            "[epoch : 10, i :    56] loss: 0.000\n",
            "[epoch : 10, i :    58] loss: 0.000\n",
            "[epoch : 10, i :    60] loss: 0.000\n",
            "[epoch : 10, i :    62] loss: 0.000\n",
            "[epoch : 10, i :    64] loss: 0.000\n",
            "[epoch : 10, i :    66] loss: 0.000\n",
            "[epoch : 10, i :    68] loss: 0.000\n",
            "[epoch : 10, i :    70] loss: 0.000\n",
            "[epoch : 10, i :    72] loss: 0.000\n",
            "[epoch : 10, i :    74] loss: 0.000\n",
            "[epoch : 10, i :    76] loss: 0.000\n",
            "[epoch : 10, i :    78] loss: 0.000\n",
            "[epoch : 10, i :    80] loss: 0.000\n",
            "[epoch : 10, i :    82] loss: 0.000\n",
            "[epoch : 10, i :    84] loss: 0.000\n",
            "[epoch : 10, i :    86] loss: 0.000\n",
            "[epoch : 10, i :    88] loss: 0.000\n",
            "[epoch : 10, i :    90] loss: 0.000\n",
            "[epoch : 10, i :    92] loss: 0.000\n",
            "[epoch : 10, i :    94] loss: 0.000\n",
            "[epoch : 10, i :    96] loss: 0.000\n",
            "[epoch : 10, i :    98] loss: 0.000\n",
            "[epoch : 10, i :   100] loss: 0.000\n",
            "[epoch : 10, i :   102] loss: 0.000\n",
            "[epoch : 10, i :   104] loss: 0.000\n",
            "[epoch : 10, i :   106] loss: 0.000\n",
            "[epoch : 10, i :   108] loss: 0.000\n",
            "[epoch : 10, i :   110] loss: 0.000\n",
            "[epoch : 10, i :   112] loss: 0.000\n",
            "[epoch : 10, i :   114] loss: 0.000\n",
            "[epoch : 10, i :   116] loss: 0.000\n",
            "[epoch : 10, i :   118] loss: 0.000\n",
            "[epoch : 10, i :   120] loss: 0.000\n",
            "[epoch : 10, i :   122] loss: 0.000\n",
            "[epoch : 10, i :   124] loss: 0.000\n",
            "[epoch : 10, i :   126] loss: 0.000\n",
            "[epoch : 10, i :   128] loss: 0.000\n",
            "[epoch : 10, i :   130] loss: 0.000\n",
            "[epoch : 10, i :   132] loss: 0.000\n",
            "[epoch : 10, i :   134] loss: 0.000\n",
            "[epoch : 10, i :   136] loss: 0.000\n",
            "[epoch : 10, i :   138] loss: 0.000\n",
            "[epoch : 10, i :   140] loss: 0.000\n",
            "[epoch : 10, i :   142] loss: 0.000\n",
            "[epoch : 10, i :   144] loss: 0.000\n",
            "[epoch : 10, i :   146] loss: 0.000\n",
            "[epoch : 10, i :   148] loss: 0.000\n",
            "[epoch : 10, i :   150] loss: 0.000\n",
            "[epoch : 10, i :   152] loss: 0.000\n",
            "[epoch : 10, i :   154] loss: 0.000\n",
            "[epoch : 10, i :   156] loss: 0.000\n",
            "[epoch : 10, i :   158] loss: 0.000\n",
            "[epoch : 10, i :   160] loss: 0.000\n",
            "[epoch : 10, i :   162] loss: 0.000\n",
            "[epoch : 10, i :   164] loss: 0.000\n",
            "[epoch : 10, i :   166] loss: 0.000\n",
            "[epoch : 10, i :   168] loss: 0.000\n",
            "[epoch : 10, i :   170] loss: 0.000\n",
            "[epoch : 10, i :   172] loss: 0.000\n",
            "[epoch : 10, i :   174] loss: 0.000\n",
            "[epoch : 10, i :   176] loss: 0.000\n",
            "[epoch : 10, i :   178] loss: 0.000\n",
            "[epoch : 10, i :   180] loss: 0.000\n",
            "[epoch : 10, i :   182] loss: 0.000\n",
            "[epoch : 10, i :   184] loss: 0.000\n",
            "[epoch : 10, i :   186] loss: 0.000\n",
            "[epoch : 10, i :   188] loss: 0.000\n",
            "[epoch : 10, i :   190] loss: 0.000\n",
            "[epoch : 10, i :   192] loss: 0.000\n",
            "[epoch : 10, i :   194] loss: 0.000\n",
            "[epoch : 10, i :   196] loss: 0.000\n",
            "[epoch : 10, i :   198] loss: 0.000\n",
            "[epoch : 10, i :   200] loss: 0.000\n",
            "[epoch : 10, i :   202] loss: 0.000\n",
            "[epoch : 10, i :   204] loss: 0.000\n",
            "[epoch : 10, i :   206] loss: 0.000\n",
            "[epoch : 10, i :   208] loss: 0.000\n",
            "[epoch : 10, i :   210] loss: 0.000\n",
            "[epoch : 10, i :   212] loss: 0.000\n",
            "[epoch : 10, i :   214] loss: 0.000\n",
            "[epoch : 10, i :   216] loss: 0.000\n",
            "[epoch : 10, i :   218] loss: 0.000\n",
            "[epoch : 10, i :   220] loss: 0.000\n",
            "[epoch : 10, i :   222] loss: 0.000\n",
            "[epoch : 10, i :   224] loss: 0.000\n",
            "[epoch : 10, i :   226] loss: 0.000\n",
            "[epoch : 10, i :   228] loss: 0.000\n",
            "[epoch : 10, i :   230] loss: 0.000\n",
            "[epoch : 10, i :   232] loss: 0.000\n",
            "[epoch : 10, i :   234] loss: 0.000\n",
            "[epoch : 10, i :   236] loss: 0.000\n",
            "[epoch : 10, i :   238] loss: 0.000\n",
            "[epoch : 10, i :   240] loss: 0.000\n",
            "[epoch : 10, i :   242] loss: 0.000\n",
            "[epoch : 10, i :   244] loss: 0.000\n",
            "[epoch : 10, i :   246] loss: 0.000\n",
            "[epoch : 10, i :   248] loss: 0.000\n",
            "[epoch : 10, i :   250] loss: 0.000\n",
            "[epoch : 10, i :   252] loss: 0.000\n",
            "[epoch : 10, i :   254] loss: 0.000\n",
            "[epoch : 10, i :   256] loss: 0.000\n",
            "[epoch : 10, i :   258] loss: 0.000\n",
            "[epoch : 10, i :   260] loss: 0.000\n",
            "[epoch : 10, i :   262] loss: 0.000\n",
            "[epoch : 10, i :   264] loss: 0.000\n",
            "[epoch : 10, i :   266] loss: 0.000\n",
            "[epoch : 10, i :   268] loss: 0.000\n",
            "[epoch : 10, i :   270] loss: 0.000\n",
            "[epoch : 10, i :   272] loss: 0.000\n",
            "[epoch : 10, i :   274] loss: 0.000\n",
            "[epoch : 10, i :   276] loss: 0.000\n",
            "[epoch : 10, i :   278] loss: 0.000\n",
            "[epoch : 10, i :   280] loss: 0.000\n",
            "[epoch : 10, i :   282] loss: 0.000\n",
            "[epoch : 10, i :   284] loss: 0.000\n",
            "[epoch : 10, i :   286] loss: 0.000\n",
            "[epoch : 10, i :   288] loss: 0.000\n",
            "[epoch : 10, i :   290] loss: 0.000\n",
            "[epoch : 10, i :   292] loss: 0.000\n",
            "[epoch : 10, i :   294] loss: 0.000\n",
            "[epoch : 10, i :   296] loss: 0.000\n",
            "[epoch : 10, i :   298] loss: 0.000\n",
            "[epoch : 10, i :   300] loss: 0.000\n",
            "[epoch : 10, i :   302] loss: 0.000\n",
            "[epoch : 10, i :   304] loss: 0.000\n",
            "[epoch : 10, i :   306] loss: 0.000\n",
            "[epoch : 10, i :   308] loss: 0.000\n",
            "[epoch : 10, i :   310] loss: 0.000\n",
            "[epoch : 10, i :   312] loss: 0.000\n",
            "[epoch : 10, i :   314] loss: 0.000\n",
            "[epoch : 10, i :   316] loss: 0.000\n",
            "[epoch : 10, i :   318] loss: 0.000\n",
            "[epoch : 10, i :   320] loss: 0.000\n",
            "[epoch : 10, i :   322] loss: 0.000\n",
            "[epoch : 10, i :   324] loss: 0.000\n",
            "[epoch : 10, i :   326] loss: 0.000\n",
            "[epoch : 10, i :   328] loss: 0.000\n",
            "[epoch : 10, i :   330] loss: 0.000\n",
            "[epoch : 10, i :   332] loss: 0.000\n",
            "[epoch : 10, i :   334] loss: 0.000\n",
            "[epoch : 10, i :   336] loss: 0.000\n",
            "[epoch : 10, i :   338] loss: 0.000\n",
            "[epoch : 10, i :   340] loss: 0.000\n",
            "[epoch : 10, i :   342] loss: 0.000\n",
            "[epoch : 10, i :   344] loss: 0.000\n",
            "[epoch : 10, i :   346] loss: 0.000\n",
            "[epoch : 10, i :   348] loss: 0.000\n",
            "[epoch : 10, i :   350] loss: 0.000\n",
            "[epoch : 10, i :   352] loss: 0.000\n",
            "[epoch : 10, i :   354] loss: 0.000\n",
            "[epoch : 10, i :   356] loss: 0.000\n",
            "[epoch : 10, i :   358] loss: 0.000\n",
            "[epoch : 10, i :   360] loss: 0.000\n",
            "[epoch : 10, i :   362] loss: 0.000\n",
            "[epoch : 10, i :   364] loss: 0.000\n",
            "[epoch : 10, i :   366] loss: 0.000\n",
            "[epoch : 10, i :   368] loss: 0.000\n",
            "[epoch : 10, i :   370] loss: 0.000\n",
            "[epoch : 10, i :   372] loss: 0.000\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noycj9NS1rZ3"
      },
      "id": "noycj9NS1rZ3",
      "execution_count": 204,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}